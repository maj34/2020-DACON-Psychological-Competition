{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color = \"#CC3D3D\"><p>\n",
    "- Features\n",
    "    - [Data load](#Data-load)\n",
    "    - [EDA](#EDA)\n",
    "- Feature Engineering\n",
    "    - [Continuous features](#Continuous-features)\n",
    "    - [One-hot encoding(categorical features)](#One-hot-encoding(categorical-features))\n",
    "- Feature Extraction\n",
    "    - [PCA](#PCA)\n",
    "    - [Scaling(Normalization, Standardization)](#Scaling(Normalization,-Standardization))\n",
    "- Feature Selection\n",
    "    - [Feature selection](#Feature-selection)\n",
    "- Modeling\n",
    "    - [Modeling with bayes_opt](#Modeling-with-bayes_opt)\n",
    "    - [Logistic Regression](#Logistic-Regression)\n",
    "    - [Random Forest](#Random-Forest)\n",
    "    - [XGB](#XGB)\n",
    "    - [LGBM](#LGBM)\n",
    "    - [Extra Tree](#Extra-Tree)\n",
    "    - [GBM](#GBM)\n",
    "    - [Adaboost](#Adaboost)\n",
    "- Ensemble\n",
    "    - [Stacking](#Stacking)\n",
    "    - [meta model optimizing](#meta-model-optimizing)    \n",
    "    - [ensemble](#ensemble)    \n",
    "- Submission\n",
    "    - [predict & submission](#predict-&-submission)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr = pd.read_csv('train.csv')\n",
    "ts = pd.read_csv('test_x.csv')\n",
    "submission=pd.read_csv('sample_submission.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train, test, target\n",
    "target = tr.voted\n",
    "tr.drop('voted', axis = 1, inplace = True)\n",
    "tr_shape = tr.shape\n",
    "ts_shape = ts.shape\n",
    "df = pd.concat([tr, ts], ignore_index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자형 피처) age_group, gender, race, religion (4개) -> 원핫인코딩\n",
    "\n",
    "# 범주형(숫자형) 피처) education, engnat, hand, married, urban, wr_(01~13) wf_(01~03) (6개)\n",
    "# 연속형(숫자형) 피처) Q_A Q_E (a~t), familysize, tp__(01~07) (3개)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = []\n",
    "features_te = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = train.groupby('CLNT_ID').agg({\n",
    "    'CLAC3_NM': [('구매상품수(소)', lambda x: x.nunique())],\n",
    "    'CLAC2_NM': [('구매상품수(중)', lambda x: x.nunique())],\n",
    "    'CLAC1_NM': [('구매상품수(대)', lambda x: x.nunique())]\n",
    "}).reset_index()\n",
    "f.columns = drop_column_level(f)\n",
    "features.append(f); display(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame({'CLNT_ID': train.CLNT_ID.unique()})\n",
    "for f in features :\n",
    "    data = pd.merge(data, f, how='left')\n",
    "    \n",
    "data = data.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Continuous features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QaA</th>\n",
       "      <th>QaE</th>\n",
       "      <th>QbA</th>\n",
       "      <th>QbE</th>\n",
       "      <th>QcA</th>\n",
       "      <th>QcE</th>\n",
       "      <th>QdA</th>\n",
       "      <th>QdE</th>\n",
       "      <th>QeA</th>\n",
       "      <th>QeE</th>\n",
       "      <th>...</th>\n",
       "      <th>QpA</th>\n",
       "      <th>QpE</th>\n",
       "      <th>QqA</th>\n",
       "      <th>QqE</th>\n",
       "      <th>QrA</th>\n",
       "      <th>QrE</th>\n",
       "      <th>QsA</th>\n",
       "      <th>QsE</th>\n",
       "      <th>QtA</th>\n",
       "      <th>QtE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>363</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1370</td>\n",
       "      <td>5.0</td>\n",
       "      <td>997</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1024</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1577</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>924</td>\n",
       "      <td>2.0</td>\n",
       "      <td>366</td>\n",
       "      <td>2.0</td>\n",
       "      <td>876</td>\n",
       "      <td>2.0</td>\n",
       "      <td>633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>647</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1313</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3387</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4320</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2414</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1356</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3039</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4304</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1623</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1480</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1021</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3374</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1333</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1131</td>\n",
       "      <td>5.0</td>\n",
       "      <td>937</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1327</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1170</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>504</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2311</td>\n",
       "      <td>4.0</td>\n",
       "      <td>992</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3245</td>\n",
       "      <td>1.0</td>\n",
       "      <td>357</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>23868</td>\n",
       "      <td>3.0</td>\n",
       "      <td>581</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8830</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2392</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>707</td>\n",
       "      <td>5.0</td>\n",
       "      <td>556</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1062</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1014</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1140</td>\n",
       "      <td>5.0</td>\n",
       "      <td>323</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>583</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>5.0</td>\n",
       "      <td>427</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1066</td>\n",
       "      <td>5.0</td>\n",
       "      <td>588</td>\n",
       "      <td>1.0</td>\n",
       "      <td>560</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1110</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>736</td>\n",
       "      <td>4.0</td>\n",
       "      <td>828</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1053</td>\n",
       "      <td>2.0</td>\n",
       "      <td>537</td>\n",
       "      <td>4.0</td>\n",
       "      <td>595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>1.0</td>\n",
       "      <td>314</td>\n",
       "      <td>5.0</td>\n",
       "      <td>554</td>\n",
       "      <td>5.0</td>\n",
       "      <td>230</td>\n",
       "      <td>1.0</td>\n",
       "      <td>956</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1173</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>505</td>\n",
       "      <td>3.0</td>\n",
       "      <td>554</td>\n",
       "      <td>1.0</td>\n",
       "      <td>600</td>\n",
       "      <td>5.0</td>\n",
       "      <td>307</td>\n",
       "      <td>4.0</td>\n",
       "      <td>722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>1.0</td>\n",
       "      <td>627</td>\n",
       "      <td>2.0</td>\n",
       "      <td>799</td>\n",
       "      <td>1.0</td>\n",
       "      <td>739</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>829</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>623</td>\n",
       "      <td>2.0</td>\n",
       "      <td>648</td>\n",
       "      <td>2.0</td>\n",
       "      <td>713</td>\n",
       "      <td>4.0</td>\n",
       "      <td>347</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>2.0</td>\n",
       "      <td>539</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2090</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4642</td>\n",
       "      <td>1.0</td>\n",
       "      <td>673</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1185</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>878</td>\n",
       "      <td>4.0</td>\n",
       "      <td>515</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4406</td>\n",
       "      <td>4.0</td>\n",
       "      <td>471</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>2.0</td>\n",
       "      <td>541</td>\n",
       "      <td>4.0</td>\n",
       "      <td>900</td>\n",
       "      <td>5.0</td>\n",
       "      <td>691</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1951</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2317</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>456</td>\n",
       "      <td>2.0</td>\n",
       "      <td>841</td>\n",
       "      <td>4.0</td>\n",
       "      <td>839</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3172</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       QaA   QaE  QbA   QbE  QcA   QcE  QdA   QdE  QeA   QeE  ...  QpA    QpE  \\\n",
       "0      3.0   363  4.0  1370  5.0   997  1.0  1024  2.0  1577  ...  2.0    924   \n",
       "1      5.0   647  5.0  1313  3.0  3387  5.0  2969  1.0  4320  ...  5.0   2414   \n",
       "2      4.0  1623  1.0  1480  1.0  1021  4.0  3374  5.0  1333  ...  1.0   1131   \n",
       "3      3.0   504  3.0  2311  4.0   992  3.0  3245  1.0   357  ...  4.0  23868   \n",
       "4      1.0   927  1.0   707  5.0   556  2.0  1062  1.0  1014  ...  4.0   1140   \n",
       "...    ...   ...  ...   ...  ...   ...  ...   ...  ...   ...  ...  ...    ...   \n",
       "56910  5.0   427  5.0  1066  5.0   588  1.0   560  2.0  1110  ...  2.0    736   \n",
       "56911  1.0   314  5.0   554  5.0   230  1.0   956  2.0  1173  ...  5.0    505   \n",
       "56912  1.0   627  2.0   799  1.0   739  2.0  1123  1.0   829  ...  2.0    623   \n",
       "56913  2.0   539  1.0  2090  2.0  4642  1.0   673  2.0  1185  ...  1.0    878   \n",
       "56914  2.0   541  4.0   900  5.0   691  2.0  1951  1.0  2317  ...  4.0    456   \n",
       "\n",
       "       QqA   QqE  QrA   QrE  QsA   QsE  QtA   QtE  \n",
       "0      2.0   366  2.0   876  2.0   633  1.0  1115  \n",
       "1      5.0  1356  1.0  3039  4.0  4304  1.0  1346  \n",
       "2      5.0   937  4.0  1327  1.0  1170  1.0  1409  \n",
       "3      3.0   581  4.0  8830  4.0  2392  5.0  1312  \n",
       "4      5.0   323  5.0  1070  1.0   583  2.0  1889  \n",
       "...    ...   ...  ...   ...  ...   ...  ...   ...  \n",
       "56910  4.0   828  2.0  1053  2.0   537  4.0   595  \n",
       "56911  3.0   554  1.0   600  5.0   307  4.0   722  \n",
       "56912  2.0   648  2.0   713  4.0   347  2.0  1171  \n",
       "56913  4.0   515  2.0  4406  4.0   471  2.0  1870  \n",
       "56914  2.0   841  4.0   839  4.0  3172  4.0  3372  \n",
       "\n",
       "[56915 rows x 40 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1 = df.loc[:, 'QaA':'QtE'] ; f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot encoding(categorical features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>+70s</th>\n",
       "      <th>10s</th>\n",
       "      <th>20s</th>\n",
       "      <th>30s</th>\n",
       "      <th>40s</th>\n",
       "      <th>50s</th>\n",
       "      <th>60s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       +70s  10s  20s  30s  40s  50s  60s\n",
       "0         0    0    0    1    0    0    0\n",
       "1         0    0    1    0    0    0    0\n",
       "2         0    0    0    1    0    0    0\n",
       "3         0    0    1    0    0    0    0\n",
       "4         0    0    1    0    0    0    0\n",
       "...     ...  ...  ...  ...  ...  ...  ...\n",
       "56910     0    0    1    0    0    0    0\n",
       "56911     0    1    0    0    0    0    0\n",
       "56912     0    0    0    1    0    0    0\n",
       "56913     0    0    0    0    1    0    0\n",
       "56914     0    0    1    0    0    0    0\n",
       "\n",
       "[56915 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f2 = pd.get_dummies(df.age_group) ; f2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>edu_0</th>\n",
       "      <th>edu_1</th>\n",
       "      <th>edu_2</th>\n",
       "      <th>edu_3</th>\n",
       "      <th>edu_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       edu_0  edu_1  edu_2  edu_3  edu_4\n",
       "0          0      0      1      0      0\n",
       "1          0      0      0      0      1\n",
       "2          0      0      0      1      0\n",
       "3          0      0      0      0      1\n",
       "4          0      0      0      1      0\n",
       "...      ...    ...    ...    ...    ...\n",
       "56910      0      0      0      1      0\n",
       "56911      0      0      1      0      0\n",
       "56912      0      0      0      0      1\n",
       "56913      0      0      1      0      0\n",
       "56914      0      0      0      0      1\n",
       "\n",
       "[56915 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f3 = pd.get_dummies(df.education)\n",
    "f3.columns = ['edu_'+str(i) for i in f3.columns] ; f3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0.0\n",
       "1        1.0\n",
       "2        0.0\n",
       "3        1.0\n",
       "4        0.0\n",
       "        ... \n",
       "56910    1.0\n",
       "56911    1.0\n",
       "56912    0.0\n",
       "56913    0.0\n",
       "56914    1.0\n",
       "Name: engnat, Length: 56915, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 영어가 모국어인 사람 1=Yes, 2=No, 0=무응답\n",
    "f4 = (df.engnat - 1).apply(lambda x : np.nan if x == -1 else x)\n",
    "\n",
    "f4.fillna(f4.mean(), inplace = True) ; f4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        4\n",
       "1        3\n",
       "2        3\n",
       "3        0\n",
       "4        2\n",
       "        ..\n",
       "56910    3\n",
       "56911    1\n",
       "56912    4\n",
       "56913    3\n",
       "56914    2\n",
       "Name: familysize, Length: 56915, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this is not categorical features\n",
    "f5 = df.familysize ; f5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        1\n",
       "2        0\n",
       "3        1\n",
       "4        0\n",
       "        ..\n",
       "56910    1\n",
       "56911    1\n",
       "56912    0\n",
       "56913    1\n",
       "56914    1\n",
       "Name: gender, Length: 56915, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f6 = df.gender.apply(lambda x : 0 if x == 'Male' else 1) ; f6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hand_0</th>\n",
       "      <th>hand_1</th>\n",
       "      <th>hand_2</th>\n",
       "      <th>hand_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       hand_0  hand_1  hand_2  hand_3\n",
       "0           0       1       0       0\n",
       "1           0       1       0       0\n",
       "2           0       1       0       0\n",
       "3           0       1       0       0\n",
       "4           0       1       0       0\n",
       "...       ...     ...     ...     ...\n",
       "56910       0       1       0       0\n",
       "56911       0       1       0       0\n",
       "56912       0       1       0       0\n",
       "56913       0       1       0       0\n",
       "56914       0       1       0       0\n",
       "\n",
       "[56915 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f7 = pd.get_dummies(df.hand)\n",
    "f7.columns =['hand_'+str(i) for i in f7.columns] ; f7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>married_0</th>\n",
       "      <th>married_1</th>\n",
       "      <th>married_2</th>\n",
       "      <th>married_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       married_0  married_1  married_2  married_3\n",
       "0              0          0          0          1\n",
       "1              0          1          0          0\n",
       "2              0          0          1          0\n",
       "3              0          1          0          0\n",
       "4              0          0          1          0\n",
       "...          ...        ...        ...        ...\n",
       "56910          0          1          0          0\n",
       "56911          0          1          0          0\n",
       "56912          0          0          1          0\n",
       "56913          0          0          1          0\n",
       "56914          0          1          0          0\n",
       "\n",
       "[56915 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f8 = pd.get_dummies(df.married)\n",
    "f8.columns = ['married_'+str(i) for i in f8.columns] ; f8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Arab</th>\n",
       "      <th>Asian</th>\n",
       "      <th>Black</th>\n",
       "      <th>Indigenous Australian</th>\n",
       "      <th>Native American</th>\n",
       "      <th>Other</th>\n",
       "      <th>White</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Arab  Asian  Black  Indigenous Australian  Native American  Other  \\\n",
       "0         0      0      0                      0                0      0   \n",
       "1         0      1      0                      0                0      0   \n",
       "2         0      0      0                      0                0      0   \n",
       "3         0      1      0                      0                0      0   \n",
       "4         0      0      0                      0                0      0   \n",
       "...     ...    ...    ...                    ...              ...    ...   \n",
       "56910     0      0      0                      0                0      1   \n",
       "56911     0      1      0                      0                0      0   \n",
       "56912     0      0      0                      0                0      0   \n",
       "56913     0      0      0                      0                0      0   \n",
       "56914     0      1      0                      0                0      0   \n",
       "\n",
       "       White  \n",
       "0          1  \n",
       "1          0  \n",
       "2          1  \n",
       "3          0  \n",
       "4          1  \n",
       "...      ...  \n",
       "56910      0  \n",
       "56911      0  \n",
       "56912      1  \n",
       "56913      1  \n",
       "56914      0  \n",
       "\n",
       "[56915 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f9 = pd.get_dummies(df.race) ; f9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Agnostic</th>\n",
       "      <th>Atheist</th>\n",
       "      <th>Buddhist</th>\n",
       "      <th>Christian_Catholic</th>\n",
       "      <th>Christian_Mormon</th>\n",
       "      <th>Christian_Other</th>\n",
       "      <th>Christian_Protestant</th>\n",
       "      <th>Hindu</th>\n",
       "      <th>Jewish</th>\n",
       "      <th>Muslim</th>\n",
       "      <th>Other</th>\n",
       "      <th>Sikh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Agnostic  Atheist  Buddhist  Christian_Catholic  Christian_Mormon  \\\n",
       "0             0        0         0                   0                 0   \n",
       "1             0        0         0                   0                 0   \n",
       "2             0        0         0                   0                 0   \n",
       "3             0        0         0                   0                 0   \n",
       "4             1        0         0                   0                 0   \n",
       "...         ...      ...       ...                 ...               ...   \n",
       "56910         0        0         0                   1                 0   \n",
       "56911         1        0         0                   0                 0   \n",
       "56912         0        1         0                   0                 0   \n",
       "56913         0        1         0                   0                 0   \n",
       "56914         0        0         0                   0                 0   \n",
       "\n",
       "       Christian_Other  Christian_Protestant  Hindu  Jewish  Muslim  Other  \\\n",
       "0                    0                     0      0       0       0      1   \n",
       "1                    0                     0      1       0       0      0   \n",
       "2                    0                     0      0       0       0      1   \n",
       "3                    0                     0      1       0       0      0   \n",
       "4                    0                     0      0       0       0      0   \n",
       "...                ...                   ...    ...     ...     ...    ...   \n",
       "56910                0                     0      0       0       0      0   \n",
       "56911                0                     0      0       0       0      0   \n",
       "56912                0                     0      0       0       0      0   \n",
       "56913                0                     0      0       0       0      0   \n",
       "56914                1                     0      0       0       0      0   \n",
       "\n",
       "       Sikh  \n",
       "0         0  \n",
       "1         0  \n",
       "2         0  \n",
       "3         0  \n",
       "4         0  \n",
       "...     ...  \n",
       "56910     0  \n",
       "56911     0  \n",
       "56912     0  \n",
       "56913     0  \n",
       "56914     0  \n",
       "\n",
       "[56915 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f10 = pd.get_dummies(df.religion) ; f10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tp01</th>\n",
       "      <th>tp02</th>\n",
       "      <th>tp03</th>\n",
       "      <th>tp04</th>\n",
       "      <th>tp05</th>\n",
       "      <th>tp06</th>\n",
       "      <th>tp07</th>\n",
       "      <th>tp08</th>\n",
       "      <th>tp09</th>\n",
       "      <th>tp10</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tp01  tp02  tp03  tp04  tp05  tp06  tp07  tp08  tp09  tp10\n",
       "0         2     2     2     1     2     1     7     4     4     3\n",
       "1         1     1     0     0     1     2     3     4     0     4\n",
       "2         2     3     1     5     3     4     2     6     1     3\n",
       "3         2     4     1     1     1     3     1     3     1     3\n",
       "4         1     1     1     6     0     2     0     6     2     6\n",
       "...     ...   ...   ...   ...   ...   ...   ...   ...   ...   ...\n",
       "56910     1     0     0     3     0     4     1     0     4     5\n",
       "56911     2     0     2     0     0     6     0     0     6     4\n",
       "56912     4     2     1     6     1     2     1     6     0     5\n",
       "56913     4     6     1     6     0     2     1     6     1     5\n",
       "56914     2     2     2     0     0     1     0     5     5     6\n",
       "\n",
       "[56915 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# is this categorical features?\n",
    "f11 = df.loc[:, \"tp01\" : 'tp10'] ; f11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urban_0</th>\n",
       "      <th>urban_1</th>\n",
       "      <th>urban_2</th>\n",
       "      <th>urban_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       urban_0  urban_1  urban_2  urban_3\n",
       "0            0        1        0        0\n",
       "1            0        0        0        1\n",
       "2            0        0        1        0\n",
       "3            0        0        0        1\n",
       "4            0        1        0        0\n",
       "...        ...      ...      ...      ...\n",
       "56910        1        0        0        0\n",
       "56911        0        0        1        0\n",
       "56912        0        1        0        0\n",
       "56913        0        0        1        0\n",
       "56914        0        0        0        1\n",
       "\n",
       "[56915 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f12 = pd.get_dummies(df.urban) ; f12\n",
    "f12.columns = ['urban_'+str(i) for i in f12.columns] ; f12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>wf_01</th>\n",
       "      <th>wf_02</th>\n",
       "      <th>wf_03</th>\n",
       "      <th>wr_01</th>\n",
       "      <th>wr_02</th>\n",
       "      <th>wr_03</th>\n",
       "      <th>wr_04</th>\n",
       "      <th>wr_05</th>\n",
       "      <th>wr_06</th>\n",
       "      <th>wr_07</th>\n",
       "      <th>wr_08</th>\n",
       "      <th>wr_09</th>\n",
       "      <th>wr_10</th>\n",
       "      <th>wr_11</th>\n",
       "      <th>wr_12</th>\n",
       "      <th>wr_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56910</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56911</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56912</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56913</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56914</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>56915 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       wf_01  wf_02  wf_03  wr_01  wr_02  wr_03  wr_04  wr_05  wr_06  wr_07  \\\n",
       "0          0      0      0      0      1      0      0      1      0      1   \n",
       "1          0      0      0      0      1      0      1      1      0      1   \n",
       "2          0      0      1      1      1      0      1      1      0      1   \n",
       "3          0      0      0      0      1      0      0      0      0      0   \n",
       "4          0      1      0      1      1      0      1      1      1      1   \n",
       "...      ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "56910      0      0      0      1      1      0      1      1      0      1   \n",
       "56911      0      1      1      1      1      1      1      1      1      1   \n",
       "56912      0      1      1      1      1      1      1      1      0      1   \n",
       "56913      0      0      0      1      1      0      1      0      0      1   \n",
       "56914      0      0      0      0      0      0      0      0      1      0   \n",
       "\n",
       "       wr_08  wr_09  wr_10  wr_11  wr_12  wr_13  \n",
       "0          1      0      1      0      1      1  \n",
       "1          1      0      1      0      1      1  \n",
       "2          1      1      1      0      1      1  \n",
       "3          1      0      1      0      1      1  \n",
       "4          1      0      1      1      1      1  \n",
       "...      ...    ...    ...    ...    ...    ...  \n",
       "56910      1      0      1      0      1      1  \n",
       "56911      1      1      1      1      1      1  \n",
       "56912      1      0      1      0      1      1  \n",
       "56913      1      0      1      1      1      0  \n",
       "56914      1      0      0      1      0      0  \n",
       "\n",
       "[56915 rows x 16 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f13 = df.loc[:, 'wf_01' : 'wr_13'] ; f13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def pca_df(df):\n",
    "    max_col = df.shape[1] # 차원축소하려는 데이터의 column의 개수\n",
    "    pca = PCA(n_components=max_col, random_state=0).fit(df)\n",
    "\n",
    "    cumsum = np.cumsum(pca.explained_variance_ratio_) # 분산의 설명량을 누적합\n",
    "    num_col = np.argmax(cumsum >= 0.99) + 1 # 분산의 설명량이 99%이상 되는 차원의 수\n",
    "\n",
    "    # 차원축소\n",
    "    pca = PCA(n_components = num_col, random_state=0).fit_transform(df)\n",
    "    pca_f = pd.DataFrame(pca)\n",
    "    return pca_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문자형, 범주형 변수에만 PCA 가능\n",
    "\n",
    "f2 = pca_df(f2) # age_group\n",
    "f3 = pca_df(f3) # education\n",
    "f7 = pca_df(f7) # hand\n",
    "f8 = pca_df(f8) # married\n",
    "f9 = pca_df(f9) # race\n",
    "f10 = pca_df(f10) # religion\n",
    "f12 = pca_df(f12) # urban\n",
    "f13 = pca_df(f13) # wf, wr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge data\n",
    "foo = pd.concat([f1, f2, f3, f4, f5, f6, f7, f8, f9, f10, f11, f12, f13], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = foo[:45532]\n",
    "test_x = foo[45532:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(45532, 100) (11383, 100) (45532,)\n"
     ]
    }
   ],
   "source": [
    "# check data shape\n",
    "print(train_x.shape, test_x.shape, target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling(Normalization, Standardization)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "ss = StandardScaler()\n",
    "\n",
    "# 정규화\n",
    "train_x = mms.fit_transform(train_x)\n",
    "test_x = mms.transform(test_x)\n",
    "\n",
    "# 표준화\n",
    "train_x = ss.fit_transform(train_x)\n",
    "test_x = ss.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to dataframe\n",
    "train_x = pd.DataFrame(train_x, columns = [str(i) for i in range(train_x.shape[1])])\n",
    "test_x = pd.DataFrame(test_x, columns = [str(i) for i in range(test_x.shape[1])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(train_x, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train) # "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6889220767811649"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_valid, lr.predict(x_valid)) # 실제값, 예측값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2827586 , 0.7172414 ],\n",
       "       [0.14543521, 0.85456479],\n",
       "       [0.56348669, 0.43651331],\n",
       "       ...,\n",
       "       [0.76211563, 0.23788437],\n",
       "       [0.59470882, 0.40529118],\n",
       "       [0.3642082 , 0.6357918 ]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = lr.predict_proba(test_x) ; pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>voted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.717241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.854565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.436513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.151281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.799323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>11378</td>\n",
       "      <td>1.326168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>11379</td>\n",
       "      <td>1.819626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>11380</td>\n",
       "      <td>1.237884</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>11381</td>\n",
       "      <td>1.405291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>11382</td>\n",
       "      <td>1.635792</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11383 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     voted\n",
       "0          0  1.717241\n",
       "1          1  1.854565\n",
       "2          2  1.436513\n",
       "3          3  1.151281\n",
       "4          4  1.799323\n",
       "...      ...       ...\n",
       "11378  11378  1.326168\n",
       "11379  11379  1.819626\n",
       "11380  11380  1.237884\n",
       "11381  11381  1.405291\n",
       "11382  11382  1.635792\n",
       "\n",
       "[11383 rows x 2 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission.voted = pred_y[:,0] + pred_y[:,1]*2 ; submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.700330\n",
       "1        1.848006\n",
       "2        1.429785\n",
       "3        1.166449\n",
       "4        1.788305\n",
       "           ...   \n",
       "11378    1.347221\n",
       "11379    1.833227\n",
       "11380    1.232748\n",
       "11381    1.385200\n",
       "11382    1.639488\n",
       "Name: voted, Length: 11383, dtype: float64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = submission['voted'] ;a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "score = cross_val_score(rf, x_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = np.mean(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.25, 0.75],\n",
       "       [0.17, 0.83],\n",
       "       [0.49, 0.51],\n",
       "       ...,\n",
       "       [0.78, 0.22],\n",
       "       [0.55, 0.45],\n",
       "       [0.41, 0.59]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = rf.predict_proba(test_x) ;pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.75, 1.83, 1.51, ..., 1.22, 1.45, 1.59])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = pred_y[:,0] + pred_y[:,1]*2 ; b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1.71\n",
       "1        1.87\n",
       "2        1.48\n",
       "3        1.19\n",
       "4        1.82\n",
       "         ... \n",
       "11378    1.50\n",
       "11379    1.84\n",
       "11380    1.32\n",
       "11381    1.37\n",
       "11382    1.64\n",
       "Name: voted, Length: 11383, dtype: float64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = submission['voted'] ;b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.voted = (a+b)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('maj34(8).csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = pd.Timestamp.now()\n",
    "fname = f\"submission_{t.month:02}{t.day:02}{t.hour:02}{t.minute:02}.csv\"\n",
    "submission['voted']=pred_dnn+1\n",
    "submission.to_csv(fname, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 80.00%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0352\n",
       "                \n",
       "                    &plusmn; 0.0015\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                40\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 84.90%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0235\n",
       "                \n",
       "                    &plusmn; 0.0012\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                47\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.74%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0196\n",
       "                \n",
       "                    &plusmn; 0.0013\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                41\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 86.93%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0191\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                57\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.84%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0051\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                42\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 94.98%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0049\n",
       "                \n",
       "                    &plusmn; 0.0009\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                45\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.40%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0030\n",
       "                \n",
       "                    &plusmn; 0.0005\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                58\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.52%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0029\n",
       "                \n",
       "                    &plusmn; 0.0021\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                46\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 96.73%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0026\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                43\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(120, 100.00%, 97.11%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0.0022\n",
       "                \n",
       "                    &plusmn; 0.0011\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                66\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "        \n",
       "            <tr style=\"background-color: hsl(120, 100.00%, 97.11%); border: none;\">\n",
       "                <td colspan=\"2\" style=\"padding: 0 0.5em 0 0.5em; text-align: center; border: none; white-space: nowrap;\">\n",
       "                    <i>&hellip; 90 more &hellip;</i>\n",
       "                </td>\n",
       "            </tr>\n",
       "        \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "from eli5.sklearn import PermutationImportance\n",
    "import eli5\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "meta = CalibratedClassifierCV(LogisticRegression(random_state=0))\n",
    "perm = PermutationImportance(meta.fit(train_x, target)).fit(train_x, target)\n",
    "\n",
    "eli5.show_weights(perm, \n",
    "                  feature_names = train_x.columns.tolist(), \n",
    "                  top=(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>weight</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>0.000755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>47</td>\n",
       "      <td>0.023539</td>\n",
       "      <td>0.000599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0.019560</td>\n",
       "      <td>0.000674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>0.019147</td>\n",
       "      <td>0.000453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0.005082</td>\n",
       "      <td>0.000530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>45</td>\n",
       "      <td>0.004880</td>\n",
       "      <td>0.000455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>58</td>\n",
       "      <td>0.003040</td>\n",
       "      <td>0.000250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>46</td>\n",
       "      <td>0.002890</td>\n",
       "      <td>0.001038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>43</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>0.000529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>66</td>\n",
       "      <td>0.002223</td>\n",
       "      <td>0.000573</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  feature    weight       std\n",
       "0      40  0.035166  0.000755\n",
       "1      47  0.023539  0.000599\n",
       "2      41  0.019560  0.000674\n",
       "3      57  0.019147  0.000453\n",
       "4      42  0.005082  0.000530\n",
       "5      45  0.004880  0.000455\n",
       "6      58  0.003040  0.000250\n",
       "7      46  0.002890  0.001038\n",
       "8      43  0.002644  0.000529\n",
       "9      66  0.002223  0.000573"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "perm_features_df = eli5.explain_weights_df(perm, feature_names = train_x.columns.tolist())\n",
    "display(perm_features_df.head(10))\n",
    "perm_features = perm_features_df.loc[perm_features_df['weight'] >= 0.001]['feature'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 95/95 [00:43<00:00,  2.21it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "\n",
    "model = LogisticRegression(random_state=0)\n",
    "\n",
    "# 각 특성과 타깃(class) 사이에 유의한 통계적 관계가 있는지 계산하여 특성을 선택하는 방법 \n",
    "cv_scores = []\n",
    "\n",
    "\n",
    "########### cv 바꿔줌 ###############\n",
    "sscv = StratifiedKFold(n_splits = 5, random_state = 0)\n",
    "\n",
    "for p in tqdm(range(5,100,1)):\n",
    "    nf = int(perm_features_df.shape[0] * p * 0.01)\n",
    "    features_selected = perm_features_df.iloc[:nf].feature\n",
    "    X_new = train_x[features_selected]\n",
    "    cv_score = cross_val_score(model, X_new, target, scoring='roc_auc', cv=sscv).mean()\n",
    "    cv_scores.append((p,cv_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48, 0.7613599526293553)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the best percentile\n",
    "best_score = cv_scores[np.argmax([score for _, score in cv_scores])]\n",
    "print(best_score)\n",
    "\n",
    "# Plot the performance change with p\n",
    "plt.plot([k for k, _ in cv_scores], [score for _, score in cv_scores])\n",
    "plt.xlabel('Percent of features')\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 과적합을 피하기 위해 최적의 p값 주변의 값을 선택하는게 더 나은 결과를 얻을 수 있다. \n",
    "nf = int(perm_features_df.shape[0] * best_score[0] * 0.01)\n",
    "features_selected = perm_features_df.iloc[:nf].feature\n",
    "train_x_sel = train_x[features_selected]\n",
    "test_x_sel = test_x[features_selected]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling with bayes_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting bayesian-optimization\n",
      "  Downloading bayesian-optimization-1.2.0.tar.gz (14 kB)\n",
      "Requirement already satisfied: numpy>=1.9.0 in d:\\anaconda\\lib\\site-packages (from bayesian-optimization) (1.19.1)\n",
      "Requirement already satisfied: scipy>=0.14.0 in d:\\anaconda\\lib\\site-packages (from bayesian-optimization) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18.0 in d:\\anaconda\\lib\\site-packages (from bayesian-optimization) (0.23.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda\\lib\\site-packages (from scikit-learn>=0.18.0->bayesian-optimization) (0.16.0)\n",
      "Building wheels for collected packages: bayesian-optimization\n",
      "  Building wheel for bayesian-optimization (setup.py): started\n",
      "  Building wheel for bayesian-optimization (setup.py): finished with status 'done'\n",
      "  Created wheel for bayesian-optimization: filename=bayesian_optimization-1.2.0-py3-none-any.whl size=11690 sha256=7e89b69d1b8cbcd41c49325613460df85f4c0b69177e6e8c70022f6569724c32\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\fd\\9b\\71\\f127d694e02eb40bcf18c7ae9613b88a6be4470f57a8528c5b\n",
      "Successfully built bayesian-optimization\n",
      "Installing collected packages: bayesian-optimization\n",
      "Successfully installed bayesian-optimization-1.2.0\n",
      "Requirement already satisfied: lightgbm in d:\\anaconda\\lib\\site-packages (3.0.0)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn!=0.22.0 in d:\\anaconda\\lib\\site-packages (from lightgbm) (0.23.2)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from lightgbm) (1.19.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda\\lib\\site-packages (from scikit-learn!=0.22.0->lightgbm) (0.16.0)\n",
      "Collecting xgboost\n",
      "  Downloading xgboost-1.2.0-py3-none-win_amd64.whl (86.5 MB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.19.1)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from xgboost) (1.5.2)\n",
      "Installing collected packages: xgboost\n",
      "Successfully installed xgboost-1.2.0\n"
     ]
    }
   ],
   "source": [
    "!pip install bayesian-optimization\n",
    "!pip install lightgbm\n",
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold, cross_val_score, train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data (train, validation)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train_x, target, test_size = 0.3, random_state = 0, stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "BO_tuned_clfs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 범위\n",
    "\n",
    "pbounds = { 'C': (0.1,1),}\n",
    "\n",
    "\n",
    "def logreg_opt(C):\n",
    "    \n",
    "    params = {\n",
    "        'C' : C\n",
    "    }\n",
    "\n",
    "    logreg = LogisticRegression(**params, n_jobs=-1, random_state=50)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "    \n",
    "    score = cross_val_score(logreg, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "BO_logreg = BayesianOptimization(f = logreg_opt, pbounds = pbounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.5939  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.7437  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.6425  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7604  \u001b[0m | \u001b[95m 0.5904  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7604  \u001b[0m | \u001b[95m 0.4813  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.6813  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.4938  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.9026  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.9673  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.7604  \u001b[0m | \u001b[95m 0.4451  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.8126  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.576   \u001b[0m |\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cache\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0m_hashable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: (0.6112401049845391,)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-143-955c63877435>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mBO_logreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmaximize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minit_points\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mmaximize\u001b[1;34m(self, init_points, n_iter, acq, kappa, kappa_decay, kappa_decay_delay, xi, **gp_params)\u001b[0m\n\u001b[0;32m    183\u001b[0m                 \u001b[0miteration\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 185\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_probe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlazy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    186\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_bounds_transformer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\bayes_opt\\bayesian_optimization.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params, lazy)\u001b[0m\n\u001b[0;32m    114\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 116\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_space\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprobe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOPTIMIZATION_STEP\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\bayes_opt\\target_space.py\u001b[0m in \u001b[0;36mprobe\u001b[1;34m(self, params)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m             \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m             \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget_func\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-142-5d8a434e5ba0>\u001b[0m in \u001b[0;36mlogreg_opt\u001b[1;34m(C)\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mskf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStratifiedKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogreg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'roc_auc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mskf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    404\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 406\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    407\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    408\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    246\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    247\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 248\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    250\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1040\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1042\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1043\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1044\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'supports_timeout'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[1;34m(future, timeout)\u001b[0m\n\u001b[0;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[0;32m    541\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 542\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    543\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    544\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\concurrent\\futures\\_base.py\u001b[0m in \u001b[0;36mresult\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    428\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Anaconda\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m    \u001b[1;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m                 \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "BO_logreg.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_params = BO_logreg.max['params']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76079701 0.75963418 0.75603947 0.76846599]\n",
      "최대성능: 0.7684659889925252\n",
      "평균성능: 0.7612341621598808\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "logreg_clf = LogisticRegression(**max_params,  n_jobs=-1, random_state=50)\n",
    "\n",
    "scores = cross_val_score(logreg_clf, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\n",
    "\n",
    "BO_tuned_clfs.append((logreg_clf.__class__.__name__, logreg_clf, max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 범위\n",
    "\n",
    "pbounds = { 'n_estimators': (10,250),\n",
    "            'max_depth': (5,15), \n",
    "            'max_features': (0.8,0.95),\n",
    "            'min_samples_leaf': (1, 5)}\n",
    "\n",
    "def rf_opt(n_estimators, max_depth, max_features, min_samples_leaf):\n",
    "    \n",
    "    params = {\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth' : int(round(max_depth)),\n",
    "        'min_samples_leaf' : int(round(min_samples_leaf))\n",
    "    }\n",
    "\n",
    "    rf = RandomForestClassifier(**params, n_jobs=-1, random_state=50)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "    \n",
    "    score = cross_val_score(rf, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "BO_rf = BayesianOptimization(f = rf_opt, pbounds = pbounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 10.49   \u001b[0m | \u001b[0m 0.9073  \u001b[0m | \u001b[0m 3.411   \u001b[0m | \u001b[0m 140.8   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 9.237   \u001b[0m | \u001b[0m 0.8969  \u001b[0m | \u001b[0m 2.75    \u001b[0m | \u001b[0m 224.0   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 14.64   \u001b[0m | \u001b[0m 0.8575  \u001b[0m | \u001b[0m 4.167   \u001b[0m | \u001b[0m 136.9   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 0.9388  \u001b[0m | \u001b[0m 1.284   \u001b[0m | \u001b[0m 30.91   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 5.202   \u001b[0m | \u001b[0m 0.9249  \u001b[0m | \u001b[0m 4.113   \u001b[0m | \u001b[0m 218.8   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 14.79   \u001b[0m | \u001b[0m 0.9199  \u001b[0m | \u001b[0m 2.846   \u001b[0m | \u001b[0m 197.3   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7628  \u001b[0m | \u001b[0m 6.183   \u001b[0m | \u001b[0m 0.896   \u001b[0m | \u001b[0m 1.573   \u001b[0m | \u001b[0m 236.7   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 10.22   \u001b[0m | \u001b[0m 0.8622  \u001b[0m | \u001b[0m 2.058   \u001b[0m | \u001b[0m 195.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 9.562   \u001b[0m | \u001b[0m 0.8853  \u001b[0m | \u001b[0m 1.075   \u001b[0m | \u001b[0m 158.2   \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.765   \u001b[0m | \u001b[95m 11.12   \u001b[0m | \u001b[95m 0.8925  \u001b[0m | \u001b[95m 4.775   \u001b[0m | \u001b[95m 173.6   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7622  \u001b[0m | \u001b[0m 8.595   \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 3.791   \u001b[0m | \u001b[0m 24.45   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7592  \u001b[0m | \u001b[0m 11.67   \u001b[0m | \u001b[0m 0.9006  \u001b[0m | \u001b[0m 1.842   \u001b[0m | \u001b[0m 40.94   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 8.154   \u001b[0m | \u001b[0m 0.8546  \u001b[0m | \u001b[0m 3.281   \u001b[0m | \u001b[0m 115.3   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7593  \u001b[0m | \u001b[0m 14.88   \u001b[0m | \u001b[0m 0.8153  \u001b[0m | \u001b[0m 1.836   \u001b[0m | \u001b[0m 48.71   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 11.53   \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 2.865   \u001b[0m | \u001b[0m 68.66   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 6.59    \u001b[0m | \u001b[0m 0.8166  \u001b[0m | \u001b[0m 3.625   \u001b[0m | \u001b[0m 43.16   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7621  \u001b[0m | \u001b[0m 6.966   \u001b[0m | \u001b[0m 0.8553  \u001b[0m | \u001b[0m 4.284   \u001b[0m | \u001b[0m 33.3    \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 13.38   \u001b[0m | \u001b[0m 0.8144  \u001b[0m | \u001b[0m 4.906   \u001b[0m | \u001b[0m 122.5   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7519  \u001b[0m | \u001b[0m 14.77   \u001b[0m | \u001b[0m 0.8907  \u001b[0m | \u001b[0m 3.957   \u001b[0m | \u001b[0m 19.41   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 7.828   \u001b[0m | \u001b[0m 0.818   \u001b[0m | \u001b[0m 2.185   \u001b[0m | \u001b[0m 38.49   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 8.18    \u001b[0m | \u001b[0m 0.8621  \u001b[0m | \u001b[0m 1.257   \u001b[0m | \u001b[0m 176.2   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 10.67   \u001b[0m | \u001b[0m 0.8398  \u001b[0m | \u001b[0m 3.093   \u001b[0m | \u001b[0m 32.55   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 10.76   \u001b[0m | \u001b[0m 0.9394  \u001b[0m | \u001b[0m 2.274   \u001b[0m | \u001b[0m 170.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 6.318   \u001b[0m | \u001b[0m 0.9074  \u001b[0m | \u001b[0m 2.158   \u001b[0m | \u001b[0m 53.97   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7501  \u001b[0m | \u001b[0m 10.87   \u001b[0m | \u001b[0m 0.803   \u001b[0m | \u001b[0m 4.316   \u001b[0m | \u001b[0m 11.13   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 11.78   \u001b[0m | \u001b[0m 0.8405  \u001b[0m | \u001b[0m 3.941   \u001b[0m | \u001b[0m 240.9   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 7.488   \u001b[0m | \u001b[0m 0.8864  \u001b[0m | \u001b[0m 3.368   \u001b[0m | \u001b[0m 147.3   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 7.231   \u001b[0m | \u001b[0m 0.9429  \u001b[0m | \u001b[0m 2.789   \u001b[0m | \u001b[0m 213.1   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 11.99   \u001b[0m | \u001b[0m 0.8446  \u001b[0m | \u001b[0m 4.255   \u001b[0m | \u001b[0m 105.2   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 13.81   \u001b[0m | \u001b[0m 0.8872  \u001b[0m | \u001b[0m 4.527   \u001b[0m | \u001b[0m 176.2   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 12.25   \u001b[0m | \u001b[0m 0.8752  \u001b[0m | \u001b[0m 4.824   \u001b[0m | \u001b[0m 164.6   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 9.239   \u001b[0m | \u001b[0m 0.891   \u001b[0m | \u001b[0m 1.077   \u001b[0m | \u001b[0m 82.38   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 11.6    \u001b[0m | \u001b[0m 0.8435  \u001b[0m | \u001b[0m 3.472   \u001b[0m | \u001b[0m 112.9   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7628  \u001b[0m | \u001b[0m 6.355   \u001b[0m | \u001b[0m 0.8447  \u001b[0m | \u001b[0m 3.28    \u001b[0m | \u001b[0m 151.8   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 10.74   \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 3.608   \u001b[0m | \u001b[0m 113.5   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7643  \u001b[0m | \u001b[0m 13.97   \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 2.743   \u001b[0m | \u001b[0m 224.1   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 13.06   \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 1.401   \u001b[0m | \u001b[0m 230.7   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 12.14   \u001b[0m | \u001b[0m 0.9498  \u001b[0m | \u001b[0m 1.598   \u001b[0m | \u001b[0m 218.4   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 6.625   \u001b[0m | \u001b[0m 0.8923  \u001b[0m | \u001b[0m 1.495   \u001b[0m | \u001b[0m 213.5   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 13.07   \u001b[0m | \u001b[0m 0.8854  \u001b[0m | \u001b[0m 2.629   \u001b[0m | \u001b[0m 26.6    \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 11.97   \u001b[0m | \u001b[0m 0.868   \u001b[0m | \u001b[0m 3.888   \u001b[0m | \u001b[0m 217.9   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 14.76   \u001b[0m | \u001b[0m 0.9284  \u001b[0m | \u001b[0m 1.047   \u001b[0m | \u001b[0m 96.39   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7568  \u001b[0m | \u001b[0m 12.3    \u001b[0m | \u001b[0m 0.8257  \u001b[0m | \u001b[0m 3.084   \u001b[0m | \u001b[0m 23.04   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 0.8028  \u001b[0m | \u001b[0m 4.175   \u001b[0m | \u001b[0m 63.74   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 8.454   \u001b[0m | \u001b[0m 0.9392  \u001b[0m | \u001b[0m 3.818   \u001b[0m | \u001b[0m 17.64   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 6.647   \u001b[0m | \u001b[0m 0.8932  \u001b[0m | \u001b[0m 3.309   \u001b[0m | \u001b[0m 67.09   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 14.34   \u001b[0m | \u001b[0m 0.8921  \u001b[0m | \u001b[0m 3.143   \u001b[0m | \u001b[0m 151.6   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7622  \u001b[0m | \u001b[0m 12.3    \u001b[0m | \u001b[0m 0.8468  \u001b[0m | \u001b[0m 2.593   \u001b[0m | \u001b[0m 60.36   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 6.862   \u001b[0m | \u001b[0m 0.9417  \u001b[0m | \u001b[0m 3.958   \u001b[0m | \u001b[0m 127.7   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7634  \u001b[0m | \u001b[0m 7.274   \u001b[0m | \u001b[0m 0.8382  \u001b[0m | \u001b[0m 1.232   \u001b[0m | \u001b[0m 114.3   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 14.16   \u001b[0m | \u001b[0m 0.9089  \u001b[0m | \u001b[0m 2.781   \u001b[0m | \u001b[0m 249.9   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 203.3   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 9.734   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 187.2   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 5.228   \u001b[0m | \u001b[0m 0.9455  \u001b[0m | \u001b[0m 1.693   \u001b[0m | \u001b[0m 249.5   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 14.51   \u001b[0m | \u001b[0m 0.9144  \u001b[0m | \u001b[0m 1.003   \u001b[0m | \u001b[0m 189.3   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 166.7   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 188.6   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 120.5   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 5.041   \u001b[0m | \u001b[0m 0.8317  \u001b[0m | \u001b[0m 2.206   \u001b[0m | \u001b[0m 136.9   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 14.96   \u001b[0m | \u001b[0m 0.8086  \u001b[0m | \u001b[0m 1.668   \u001b[0m | \u001b[0m 209.4   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7626  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 160.2   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 14.9    \u001b[0m | \u001b[0m 0.8036  \u001b[0m | \u001b[0m 1.794   \u001b[0m | \u001b[0m 144.0   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 89.36   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 78.3    \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7634  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 243.7   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 76.16   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7619  \u001b[0m | \u001b[0m 14.87   \u001b[0m | \u001b[0m 0.9341  \u001b[0m | \u001b[0m 1.325   \u001b[0m | \u001b[0m 117.1   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7621  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 128.3   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 10.31   \u001b[0m | \u001b[0m 0.9105  \u001b[0m | \u001b[0m 4.824   \u001b[0m | \u001b[0m 181.9   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7599  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 21.51   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 7.958   \u001b[0m | \u001b[0m 0.8772  \u001b[0m | \u001b[0m 4.951   \u001b[0m | \u001b[0m 230.3   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 14.89   \u001b[0m | \u001b[0m 0.8271  \u001b[0m | \u001b[0m 4.51    \u001b[0m | \u001b[0m 235.9   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 14.88   \u001b[0m | \u001b[0m 0.9299  \u001b[0m | \u001b[0m 4.795   \u001b[0m | \u001b[0m 170.1   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 179.8   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 14.94   \u001b[0m | \u001b[0m 0.9446  \u001b[0m | \u001b[0m 4.914   \u001b[0m | \u001b[0m 183.6   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7611  \u001b[0m | \u001b[0m 5.204   \u001b[0m | \u001b[0m 0.842   \u001b[0m | \u001b[0m 1.13    \u001b[0m | \u001b[0m 227.1   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 203.9   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 12.44   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 180.3   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 11.45   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 192.6   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 12.86   \u001b[0m | \u001b[0m 0.9315  \u001b[0m | \u001b[0m 4.876   \u001b[0m | \u001b[0m 228.2   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 213.8   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7615  \u001b[0m | \u001b[0m 14.81   \u001b[0m | \u001b[0m 0.8218  \u001b[0m | \u001b[0m 1.406   \u001b[0m | \u001b[0m 109.2   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 107.6   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 6.341   \u001b[0m | \u001b[0m 0.9341  \u001b[0m | \u001b[0m 4.98    \u001b[0m | \u001b[0m 194.3   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 14.32   \u001b[0m | \u001b[0m 0.8702  \u001b[0m | \u001b[0m 1.035   \u001b[0m | \u001b[0m 87.07   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 11.33   \u001b[0m | \u001b[0m 0.8783  \u001b[0m | \u001b[0m 4.802   \u001b[0m | \u001b[0m 157.6   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 5.785   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 158.7   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 13.03   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 173.8   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 11.36   \u001b[0m | \u001b[0m 0.8127  \u001b[0m | \u001b[0m 4.884   \u001b[0m | \u001b[0m 246.8   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 5.961   \u001b[0m | \u001b[0m 0.8063  \u001b[0m | \u001b[0m 4.913   \u001b[0m | \u001b[0m 243.5   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 245.5   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 10.62   \u001b[0m | \u001b[0m 0.8484  \u001b[0m | \u001b[0m 4.968   \u001b[0m | \u001b[0m 236.1   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.764   \u001b[0m | \u001b[0m 11.77   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 144.9   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7628  \u001b[0m | \u001b[0m 5.514   \u001b[0m | \u001b[0m 0.9013  \u001b[0m | \u001b[0m 1.553   \u001b[0m | \u001b[0m 97.72   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 9.365   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 164.0   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 10.47   \u001b[0m | \u001b[0m 0.9236  \u001b[0m | \u001b[0m 4.775   \u001b[0m | \u001b[0m 199.6   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 11.42   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 222.9   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 10.17   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 207.1   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 11.21   \u001b[0m | \u001b[0m 0.9196  \u001b[0m | \u001b[0m 1.018   \u001b[0m | \u001b[0m 202.7   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 10.03   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 209.1   \u001b[0m |\n",
      "=========================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_rf.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 11,\n",
       " 'max_features': 0.8925400995312135,\n",
       " 'min_samples_leaf': 5,\n",
       " 'n_estimators': 174}"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_rf.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['min_samples_leaf'] = int(round(max_params['min_samples_leaf']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76018477 0.75944439 0.75530185 0.76501509]\n",
      "최대성능: 0.7650150856851279\n",
      "평균성능: 0.7599865239758122\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'BO_tuned_clfs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-147-cf4b4482f2df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mBO_tuned_clfs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrf_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrf_clf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'BO_tuned_clfs' is not defined"
     ]
    }
   ],
   "source": [
    "rf_clf = RandomForestClassifier(**max_params,  n_jobs=-1, random_state=50)\n",
    "\n",
    "scores = cross_val_score(rf_clf, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\n",
    "\n",
    "#BO_tuned_clfs.append((rf_clf.__class__.__name__, rf_clf, max(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=11, max_features=0.8925400995312135,\n",
       "                       min_samples_leaf=5, n_estimators=174, n_jobs=-1,\n",
       "                       random_state=50)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36233222, 0.63766778],\n",
       "       [0.1192966 , 0.8807034 ],\n",
       "       [0.46299194, 0.53700806],\n",
       "       ...,\n",
       "       [0.77421041, 0.22578959],\n",
       "       [0.62124815, 0.37875185],\n",
       "       [0.30680197, 0.69319803]])"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = rf_clf.predict_proba(test_x) ;pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.63766778, 1.8807034 , 1.53700806, ..., 1.22578959, 1.37875185,\n",
       "       1.69319803])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_y = pred_y[:,0] + pred_y[:,1]*2 ; pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>voted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.637668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.880703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1.537008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.237163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.759827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11378</th>\n",
       "      <td>11378</td>\n",
       "      <td>1.563642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11379</th>\n",
       "      <td>11379</td>\n",
       "      <td>1.891256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11380</th>\n",
       "      <td>11380</td>\n",
       "      <td>1.225790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11381</th>\n",
       "      <td>11381</td>\n",
       "      <td>1.378752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11382</th>\n",
       "      <td>11382</td>\n",
       "      <td>1.693198</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11383 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       index     voted\n",
       "0          0  1.637668\n",
       "1          1  1.880703\n",
       "2          2  1.537008\n",
       "3          3  1.237163\n",
       "4          4  1.759827\n",
       "...      ...       ...\n",
       "11378  11378  1.563642\n",
       "11379  11379  1.891256\n",
       "11380  11380  1.225790\n",
       "11381  11381  1.378752\n",
       "11382  11382  1.693198\n",
       "\n",
       "[11383 rows x 2 columns]"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission['voted'] = pred_y; submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "f1 = pd.read_csv('maj347.csv')\n",
    "f2 = pd.read_csv('maj34(8).csv')\n",
    "f3 = pd.read_csv('maj34(9).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = f1.voted\n",
    "f2 = f2.voted\n",
    "f3 = f3.voted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.voted = (f1+f3)/2\n",
    "submission.to_csv('ensemble_1.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 범위\n",
    "\n",
    "pbounds = { 'learning_rate': (0.05, 1.5),\n",
    "            'n_estimators': (50, 500),\n",
    "            'max_depth': (5,15),   \n",
    "            'subsample': (0.8,0.95),  \n",
    "            'colsample': (0.75,0.95),   \n",
    "            'gamma': (0, 5)}\n",
    "\n",
    "def xgb_opt(learning_rate, n_estimators, max_depth, subsample, colsample, gamma):\n",
    "    \n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth' : int(round(max_depth)),\n",
    "        'subsample': subsample,\n",
    "        'colsample': colsample,   \n",
    "        'gamma': gamma,\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "    \n",
    "    xgb = XGBClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(xgb, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_xgb = BayesianOptimization(f = xgb_opt, pbounds = pbounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsample |   gamma   | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7001  \u001b[0m | \u001b[0m 0.8598  \u001b[0m | \u001b[0m 3.576   \u001b[0m | \u001b[0m 0.924   \u001b[0m | \u001b[0m 10.45   \u001b[0m | \u001b[0m 240.6   \u001b[0m | \u001b[0m 0.8969  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6796  \u001b[0m | \u001b[0m 0.8375  \u001b[0m | \u001b[0m 4.459   \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 8.834   \u001b[0m | \u001b[0m 406.3   \u001b[0m | \u001b[0m 0.8793  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7634  \u001b[0m | \u001b[95m 0.8636  \u001b[0m | \u001b[95m 4.628   \u001b[0m | \u001b[95m 0.153   \u001b[0m | \u001b[95m 5.871   \u001b[0m | \u001b[95m 59.1    \u001b[0m | \u001b[95m 0.9249  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6801  \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 4.35    \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 12.99   \u001b[0m | \u001b[0m 257.7   \u001b[0m | \u001b[0m 0.9171  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7341  \u001b[0m | \u001b[0m 0.7737  \u001b[0m | \u001b[0m 3.2     \u001b[0m | \u001b[0m 0.2579  \u001b[0m | \u001b[0m 14.45   \u001b[0m | \u001b[0m 284.8   \u001b[0m | \u001b[0m 0.8622  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7116  \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 3.871   \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 58.46   \u001b[0m | \u001b[0m 0.8926  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6804  \u001b[0m | \u001b[0m 0.8724  \u001b[0m | \u001b[0m 3.085   \u001b[0m | \u001b[0m 1.418   \u001b[0m | \u001b[0m 11.82   \u001b[0m | \u001b[0m 211.8   \u001b[0m | \u001b[0m 0.8656  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6993  \u001b[0m | \u001b[0m 0.8895  \u001b[0m | \u001b[0m 0.3011  \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 11.71   \u001b[0m | \u001b[0m 144.7   \u001b[0m | \u001b[0m 0.8193  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6961  \u001b[0m | \u001b[0m 0.8131  \u001b[0m | \u001b[0m 1.819   \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 9.386   \u001b[0m | \u001b[0m 494.8   \u001b[0m | \u001b[0m 0.8153  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.8065  \u001b[0m | \u001b[0m 0.997   \u001b[0m | \u001b[0m 7.533   \u001b[0m | \u001b[0m 259.8   \u001b[0m | \u001b[0m 0.8367  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.6951  \u001b[0m | \u001b[0m 0.7818  \u001b[0m | \u001b[0m 0.5519  \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 6.382   \u001b[0m | \u001b[0m 138.5   \u001b[0m | \u001b[0m 0.8553  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6903  \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.4855  \u001b[0m | \u001b[0m 1.265   \u001b[0m | \u001b[0m 5.961   \u001b[0m | \u001b[0m 489.4   \u001b[0m | \u001b[0m 0.8703  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6898  \u001b[0m | \u001b[0m 0.9454  \u001b[0m | \u001b[0m 3.024   \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 5.392   \u001b[0m | \u001b[0m 177.3   \u001b[0m | \u001b[0m 0.818   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7205  \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 0.5936  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 9.143   \u001b[0m | \u001b[0m 78.87   \u001b[0m | \u001b[0m 0.9039  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7041  \u001b[0m | \u001b[0m 0.8633  \u001b[0m | \u001b[0m 1.327   \u001b[0m | \u001b[0m 0.8087  \u001b[0m | \u001b[0m 5.939   \u001b[0m | \u001b[0m 309.2   \u001b[0m | \u001b[0m 0.9394  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7343  \u001b[0m | \u001b[0m 0.8137  \u001b[0m | \u001b[0m 3.337   \u001b[0m | \u001b[0m 0.2411  \u001b[0m | \u001b[0m 12.16   \u001b[0m | \u001b[0m 180.2   \u001b[0m | \u001b[0m 0.8275  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6843  \u001b[0m | \u001b[0m 0.8673  \u001b[0m | \u001b[0m 0.1005  \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 5.047   \u001b[0m | \u001b[0m 355.0   \u001b[0m | \u001b[0m 0.8405  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7253  \u001b[0m | \u001b[0m 0.897   \u001b[0m | \u001b[0m 4.811   \u001b[0m | \u001b[0m 0.4107  \u001b[0m | \u001b[0m 10.76   \u001b[0m | \u001b[0m 316.4   \u001b[0m | \u001b[0m 0.8858  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7062  \u001b[0m | \u001b[0m 0.7946  \u001b[0m | \u001b[0m 4.764   \u001b[0m | \u001b[0m 0.6983  \u001b[0m | \u001b[0m 13.46   \u001b[0m | \u001b[0m 364.8   \u001b[0m | \u001b[0m 0.8446  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6891  \u001b[0m | \u001b[0m 0.9128  \u001b[0m | \u001b[0m 1.983   \u001b[0m | \u001b[0m 1.328   \u001b[0m | \u001b[0m 10.81   \u001b[0m | \u001b[0m 446.8   \u001b[0m | \u001b[0m 0.9039  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6807  \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 2.507   \u001b[0m | \u001b[0m 1.436   \u001b[0m | \u001b[0m 11.44   \u001b[0m | \u001b[0m 240.7   \u001b[0m | \u001b[0m 0.891   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6968  \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 1.508   \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 7.901   \u001b[0m | \u001b[0m 328.1   \u001b[0m | \u001b[0m 0.8643  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7069  \u001b[0m | \u001b[0m 0.7771  \u001b[0m | \u001b[0m 1.491   \u001b[0m | \u001b[0m 0.8764  \u001b[0m | \u001b[0m 10.91   \u001b[0m | \u001b[0m 308.4   \u001b[0m | \u001b[0m 0.898   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6861  \u001b[0m | \u001b[0m 0.8804  \u001b[0m | \u001b[0m 2.157   \u001b[0m | \u001b[0m 1.35    \u001b[0m | \u001b[0m 8.676   \u001b[0m | \u001b[0m 246.1   \u001b[0m | \u001b[0m 0.9338  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7436  \u001b[0m | \u001b[0m 0.9112  \u001b[0m | \u001b[0m 3.519   \u001b[0m | \u001b[0m 0.1953  \u001b[0m | \u001b[0m 14.19   \u001b[0m | \u001b[0m 371.4   \u001b[0m | \u001b[0m 0.9498  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7406  \u001b[0m | \u001b[0m 0.7799  \u001b[0m | \u001b[0m 4.341   \u001b[0m | \u001b[0m 0.2856  \u001b[0m | \u001b[0m 11.16   \u001b[0m | \u001b[0m 105.7   \u001b[0m | \u001b[0m 0.9272  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.712   \u001b[0m | \u001b[0m 0.9115  \u001b[0m | \u001b[0m 2.846   \u001b[0m | \u001b[0m 0.6404  \u001b[0m | \u001b[0m 5.692   \u001b[0m | \u001b[0m 363.8   \u001b[0m | \u001b[0m 0.868   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6727  \u001b[0m | \u001b[0m 0.8944  \u001b[0m | \u001b[0m 4.332   \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 13.56   \u001b[0m | \u001b[0m 55.27   \u001b[0m | \u001b[0m 0.854   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.6995  \u001b[0m | \u001b[0m 0.896   \u001b[0m | \u001b[0m 0.8581  \u001b[0m | \u001b[0m 0.8055  \u001b[0m | \u001b[0m 5.543   \u001b[0m | \u001b[0m 140.0   \u001b[0m | \u001b[0m 0.8028  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.719   \u001b[0m | \u001b[0m 0.9087  \u001b[0m | \u001b[0m 1.12    \u001b[0m | \u001b[0m 0.5508  \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 367.0   \u001b[0m | \u001b[0m 0.8048  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.699   \u001b[0m | \u001b[0m 0.7829  \u001b[0m | \u001b[0m 3.107   \u001b[0m | \u001b[0m 0.887   \u001b[0m | \u001b[0m 7.379   \u001b[0m | \u001b[0m 470.4   \u001b[0m | \u001b[0m 0.8921  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6873  \u001b[0m | \u001b[0m 0.8571  \u001b[0m | \u001b[0m 2.95    \u001b[0m | \u001b[0m 1.109   \u001b[0m | \u001b[0m 8.119   \u001b[0m | \u001b[0m 229.2   \u001b[0m | \u001b[0m 0.8315  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6864  \u001b[0m | \u001b[0m 0.7872  \u001b[0m | \u001b[0m 4.722   \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 9.905   \u001b[0m | \u001b[0m 152.3   \u001b[0m | \u001b[0m 0.8382  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7175  \u001b[0m | \u001b[0m 0.7616  \u001b[0m | \u001b[0m 2.172   \u001b[0m | \u001b[0m 0.5021  \u001b[0m | \u001b[0m 11.96   \u001b[0m | \u001b[0m 220.0   \u001b[0m | \u001b[0m 0.8269  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7057  \u001b[0m | \u001b[0m 0.7549  \u001b[0m | \u001b[0m 0.3362  \u001b[0m | \u001b[0m 1.035   \u001b[0m | \u001b[0m 9.537   \u001b[0m | \u001b[0m 291.5   \u001b[0m | \u001b[0m 0.9345  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.6962  \u001b[0m | \u001b[0m 0.9481  \u001b[0m | \u001b[0m 1.084   \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 7.633   \u001b[0m | \u001b[0m 59.29   \u001b[0m | \u001b[0m 0.9138  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7032  \u001b[0m | \u001b[0m 0.814   \u001b[0m | \u001b[0m 1.917   \u001b[0m | \u001b[0m 0.9031  \u001b[0m | \u001b[0m 13.31   \u001b[0m | \u001b[0m 333.0   \u001b[0m | \u001b[0m 0.9309  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7282  \u001b[0m | \u001b[0m 0.8047  \u001b[0m | \u001b[0m 3.99    \u001b[0m | \u001b[0m 0.3192  \u001b[0m | \u001b[0m 14.53   \u001b[0m | \u001b[0m 359.4   \u001b[0m | \u001b[0m 0.8323  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7241  \u001b[0m | \u001b[0m 0.9395  \u001b[0m | \u001b[0m 3.654   \u001b[0m | \u001b[0m 0.4182  \u001b[0m | \u001b[0m 7.133   \u001b[0m | \u001b[0m 283.2   \u001b[0m | \u001b[0m 0.8038  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7134  \u001b[0m | \u001b[0m 0.7915  \u001b[0m | \u001b[0m 2.123   \u001b[0m | \u001b[0m 0.5925  \u001b[0m | \u001b[0m 9.636   \u001b[0m | \u001b[0m 174.9   \u001b[0m | \u001b[0m 0.888   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7062  \u001b[0m | \u001b[0m 0.9228  \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 0.8002  \u001b[0m | \u001b[0m 6.321   \u001b[0m | \u001b[0m 372.6   \u001b[0m | \u001b[0m 0.8594  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7358  \u001b[0m | \u001b[0m 0.8631  \u001b[0m | \u001b[0m 0.9164  \u001b[0m | \u001b[0m 0.26    \u001b[0m | \u001b[0m 9.881   \u001b[0m | \u001b[0m 210.0   \u001b[0m | \u001b[0m 0.9411  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6834  \u001b[0m | \u001b[0m 0.9031  \u001b[0m | \u001b[0m 3.743   \u001b[0m | \u001b[0m 1.36    \u001b[0m | \u001b[0m 5.834   \u001b[0m | \u001b[0m 298.5   \u001b[0m | \u001b[0m 0.8877  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7438  \u001b[0m | \u001b[0m 0.9424  \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.3992  \u001b[0m | \u001b[0m 6.003   \u001b[0m | \u001b[0m 57.39   \u001b[0m | \u001b[0m 0.9394  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7237  \u001b[0m | \u001b[0m 0.884   \u001b[0m | \u001b[0m 3.926   \u001b[0m | \u001b[0m 0.4585  \u001b[0m | \u001b[0m 10.86   \u001b[0m | \u001b[0m 78.78   \u001b[0m | \u001b[0m 0.8728  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7214  \u001b[0m | \u001b[0m 0.9455  \u001b[0m | \u001b[0m 4.383   \u001b[0m | \u001b[0m 0.5403  \u001b[0m | \u001b[0m 14.62   \u001b[0m | \u001b[0m 154.3   \u001b[0m | \u001b[0m 0.9424  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7037  \u001b[0m | \u001b[0m 0.9383  \u001b[0m | \u001b[0m 3.996   \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 13.74   \u001b[0m | \u001b[0m 181.9   \u001b[0m | \u001b[0m 0.9273  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7137  \u001b[0m | \u001b[0m 0.8736  \u001b[0m | \u001b[0m 0.06618 \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 6.481   \u001b[0m | \u001b[0m 491.8   \u001b[0m | \u001b[0m 0.8718  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7101  \u001b[0m | \u001b[0m 0.8495  \u001b[0m | \u001b[0m 3.197   \u001b[0m | \u001b[0m 0.5844  \u001b[0m | \u001b[0m 6.369   \u001b[0m | \u001b[0m 420.0   \u001b[0m | \u001b[0m 0.8285  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7427  \u001b[0m | \u001b[0m 0.8523  \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 0.1919  \u001b[0m | \u001b[0m 13.62   \u001b[0m | \u001b[0m 487.8   \u001b[0m | \u001b[0m 0.9441  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7165  \u001b[0m | \u001b[0m 0.9463  \u001b[0m | \u001b[0m 3.72    \u001b[0m | \u001b[0m 0.7695  \u001b[0m | \u001b[0m 7.105   \u001b[0m | \u001b[0m 58.37   \u001b[0m | \u001b[0m 0.9432  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7262  \u001b[0m | \u001b[0m 0.8361  \u001b[0m | \u001b[0m 4.805   \u001b[0m | \u001b[0m 0.7673  \u001b[0m | \u001b[0m 6.181   \u001b[0m | \u001b[0m 58.73   \u001b[0m | \u001b[0m 0.8961  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7278  \u001b[0m | \u001b[0m 0.9309  \u001b[0m | \u001b[0m 1.693   \u001b[0m | \u001b[0m 0.3905  \u001b[0m | \u001b[0m 13.61   \u001b[0m | \u001b[0m 487.5   \u001b[0m | \u001b[0m 0.8709  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7301  \u001b[0m | \u001b[0m 0.925   \u001b[0m | \u001b[0m 4.845   \u001b[0m | \u001b[0m 0.7935  \u001b[0m | \u001b[0m 5.302   \u001b[0m | \u001b[0m 59.56   \u001b[0m | \u001b[0m 0.872   \u001b[0m |\n",
      "| \u001b[95m 55      \u001b[0m | \u001b[95m 0.7659  \u001b[0m | \u001b[95m 0.9314  \u001b[0m | \u001b[95m 4.007   \u001b[0m | \u001b[95m 0.07291 \u001b[0m | \u001b[95m 5.207   \u001b[0m | \u001b[95m 58.7    \u001b[0m | \u001b[95m 0.871   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 3.832   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.705   \u001b[0m | \u001b[0m 59.28   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 0.9207  \u001b[0m | \u001b[0m 3.493   \u001b[0m | \u001b[0m 0.1826  \u001b[0m | \u001b[0m 5.082   \u001b[0m | \u001b[0m 57.14   \u001b[0m | \u001b[0m 0.9225  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7089  \u001b[0m | \u001b[0m 0.7853  \u001b[0m | \u001b[0m 3.474   \u001b[0m | \u001b[0m 1.153   \u001b[0m | \u001b[0m 5.161   \u001b[0m | \u001b[0m 57.8    \u001b[0m | \u001b[0m 0.9108  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 3.066   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.654   \u001b[0m | \u001b[0m 57.74   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 2.467   \u001b[0m | \u001b[0m 0.3629  \u001b[0m | \u001b[0m 5.067   \u001b[0m | \u001b[0m 55.17   \u001b[0m | \u001b[0m 0.8943  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 2.908   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.9     \u001b[0m | \u001b[0m 56.28   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7553  \u001b[0m | \u001b[0m 0.7954  \u001b[0m | \u001b[0m 4.796   \u001b[0m | \u001b[0m 0.3734  \u001b[0m | \u001b[0m 5.243   \u001b[0m | \u001b[0m 54.93   \u001b[0m | \u001b[0m 0.9351  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.7571  \u001b[0m | \u001b[0m 0.8331  \u001b[0m | \u001b[0m 4.383   \u001b[0m | \u001b[0m 0.1992  \u001b[0m | \u001b[0m 6.998   \u001b[0m | \u001b[0m 54.24   \u001b[0m | \u001b[0m 0.8077  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7599  \u001b[0m | \u001b[0m 0.9249  \u001b[0m | \u001b[0m 3.229   \u001b[0m | \u001b[0m 0.1475  \u001b[0m | \u001b[0m 6.61    \u001b[0m | \u001b[0m 53.26   \u001b[0m | \u001b[0m 0.8313  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7056  \u001b[0m | \u001b[0m 0.7752  \u001b[0m | \u001b[0m 1.304   \u001b[0m | \u001b[0m 0.8034  \u001b[0m | \u001b[0m 7.167   \u001b[0m | \u001b[0m 54.09   \u001b[0m | \u001b[0m 0.843   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.6913  \u001b[0m | \u001b[0m 0.8232  \u001b[0m | \u001b[0m 3.695   \u001b[0m | \u001b[0m 1.238   \u001b[0m | \u001b[0m 5.918   \u001b[0m | \u001b[0m 52.21   \u001b[0m | \u001b[0m 0.8657  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7568  \u001b[0m | \u001b[0m 0.8464  \u001b[0m | \u001b[0m 4.895   \u001b[0m | \u001b[0m 0.2411  \u001b[0m | \u001b[0m 6.492   \u001b[0m | \u001b[0m 56.05   \u001b[0m | \u001b[0m 0.8966  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.6931  \u001b[0m | \u001b[0m 0.8691  \u001b[0m | \u001b[0m 0.8296  \u001b[0m | \u001b[0m 1.217   \u001b[0m | \u001b[0m 13.72   \u001b[0m | \u001b[0m 490.1   \u001b[0m | \u001b[0m 0.9087  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7431  \u001b[0m | \u001b[0m 0.8108  \u001b[0m | \u001b[0m 3.387   \u001b[0m | \u001b[0m 0.3594  \u001b[0m | \u001b[0m 7.327   \u001b[0m | \u001b[0m 55.29   \u001b[0m | \u001b[0m 0.9297  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 4.83    \u001b[0m | \u001b[0m 0.2395  \u001b[0m | \u001b[0m 5.413   \u001b[0m | \u001b[0m 56.93   \u001b[0m | \u001b[0m 0.8133  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7555  \u001b[0m | \u001b[0m 0.9234  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 13.47   \u001b[0m | \u001b[0m 372.9   \u001b[0m | \u001b[0m 0.8522  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.682   \u001b[0m | \u001b[0m 0.792   \u001b[0m | \u001b[0m 3.652   \u001b[0m | \u001b[0m 1.335   \u001b[0m | \u001b[0m 14.08   \u001b[0m | \u001b[0m 373.4   \u001b[0m | \u001b[0m 0.8627  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7598  \u001b[0m | \u001b[0m 0.7731  \u001b[0m | \u001b[0m 3.696   \u001b[0m | \u001b[0m 0.1826  \u001b[0m | \u001b[0m 5.772   \u001b[0m | \u001b[0m 54.36   \u001b[0m | \u001b[0m 0.8438  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7282  \u001b[0m | \u001b[0m 0.894   \u001b[0m | \u001b[0m 4.793   \u001b[0m | \u001b[0m 0.3073  \u001b[0m | \u001b[0m 13.77   \u001b[0m | \u001b[0m 371.2   \u001b[0m | \u001b[0m 0.8019  \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7524  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 12.51   \u001b[0m | \u001b[0m 487.0   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.717   \u001b[0m | \u001b[0m 0.7885  \u001b[0m | \u001b[0m 1.112   \u001b[0m | \u001b[0m 0.5754  \u001b[0m | \u001b[0m 10.58   \u001b[0m | \u001b[0m 486.6   \u001b[0m | \u001b[0m 0.8405  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7331  \u001b[0m | \u001b[0m 0.7824  \u001b[0m | \u001b[0m 4.846   \u001b[0m | \u001b[0m 0.3207  \u001b[0m | \u001b[0m 11.02   \u001b[0m | \u001b[0m 373.0   \u001b[0m | \u001b[0m 0.8547  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7533  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 2.046   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 370.2   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7634  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 3.713   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 8.269   \u001b[0m | \u001b[0m 53.06   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 9.154   \u001b[0m | \u001b[0m 52.44   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.6879  \u001b[0m | \u001b[0m 0.8057  \u001b[0m | \u001b[0m 4.41    \u001b[0m | \u001b[0m 1.091   \u001b[0m | \u001b[0m 10.07   \u001b[0m | \u001b[0m 50.97   \u001b[0m | \u001b[0m 0.8145  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7109  \u001b[0m | \u001b[0m 0.8484  \u001b[0m | \u001b[0m 1.585   \u001b[0m | \u001b[0m 0.7518  \u001b[0m | \u001b[0m 13.04   \u001b[0m | \u001b[0m 370.1   \u001b[0m | \u001b[0m 0.8534  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 0.8471  \u001b[0m | \u001b[0m 4.857   \u001b[0m | \u001b[0m 0.08218 \u001b[0m | \u001b[0m 7.371   \u001b[0m | \u001b[0m 52.38   \u001b[0m | \u001b[0m 0.8571  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7378  \u001b[0m | \u001b[0m 0.756   \u001b[0m | \u001b[0m 4.796   \u001b[0m | \u001b[0m 0.3451  \u001b[0m | \u001b[0m 10.04   \u001b[0m | \u001b[0m 53.66   \u001b[0m | \u001b[0m 0.8561  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7078  \u001b[0m | \u001b[0m 0.777   \u001b[0m | \u001b[0m 0.02716 \u001b[0m | \u001b[0m 1.299   \u001b[0m | \u001b[0m 14.7    \u001b[0m | \u001b[0m 486.3   \u001b[0m | \u001b[0m 0.881   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7137  \u001b[0m | \u001b[0m 0.8521  \u001b[0m | \u001b[0m 4.932   \u001b[0m | \u001b[0m 0.6501  \u001b[0m | \u001b[0m 8.051   \u001b[0m | \u001b[0m 53.8    \u001b[0m | \u001b[0m 0.8075  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 0.7738  \u001b[0m | \u001b[0m 4.201   \u001b[0m | \u001b[0m 0.2213  \u001b[0m | \u001b[0m 5.328   \u001b[0m | \u001b[0m 56.04   \u001b[0m | \u001b[0m 0.8282  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7162  \u001b[0m | \u001b[0m 0.8941  \u001b[0m | \u001b[0m 3.546   \u001b[0m | \u001b[0m 0.5921  \u001b[0m | \u001b[0m 13.23   \u001b[0m | \u001b[0m 105.1   \u001b[0m | \u001b[0m 0.9229  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7509  \u001b[0m | \u001b[0m 0.8589  \u001b[0m | \u001b[0m 3.255   \u001b[0m | \u001b[0m 0.2086  \u001b[0m | \u001b[0m 7.865   \u001b[0m | \u001b[0m 52.4    \u001b[0m | \u001b[0m 0.8785  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 0.9286  \u001b[0m | \u001b[0m 4.775   \u001b[0m | \u001b[0m 0.1458  \u001b[0m | \u001b[0m 7.872   \u001b[0m | \u001b[0m 50.96   \u001b[0m | \u001b[0m 0.8644  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7508  \u001b[0m | \u001b[0m 0.8609  \u001b[0m | \u001b[0m 3.678   \u001b[0m | \u001b[0m 0.1361  \u001b[0m | \u001b[0m 8.578   \u001b[0m | \u001b[0m 106.0   \u001b[0m | \u001b[0m 0.8613  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7101  \u001b[0m | \u001b[0m 0.8314  \u001b[0m | \u001b[0m 4.69    \u001b[0m | \u001b[0m 0.7679  \u001b[0m | \u001b[0m 8.838   \u001b[0m | \u001b[0m 104.4   \u001b[0m | \u001b[0m 0.9491  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 0.8132  \u001b[0m | \u001b[0m 3.297   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 9.715   \u001b[0m | \u001b[0m 107.5   \u001b[0m | \u001b[0m 0.8233  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7599  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 1.931   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 9.595   \u001b[0m | \u001b[0m 106.4   \u001b[0m | \u001b[0m 0.8386  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 2.244   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 8.098   \u001b[0m | \u001b[0m 107.5   \u001b[0m | \u001b[0m 0.8073  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.6978  \u001b[0m | \u001b[0m 0.8797  \u001b[0m | \u001b[0m 1.724   \u001b[0m | \u001b[0m 1.024   \u001b[0m | \u001b[0m 9.89    \u001b[0m | \u001b[0m 108.0   \u001b[0m | \u001b[0m 0.8706  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.743   \u001b[0m | \u001b[0m 0.8678  \u001b[0m | \u001b[0m 1.977   \u001b[0m | \u001b[0m 0.2136  \u001b[0m | \u001b[0m 7.754   \u001b[0m | \u001b[0m 106.1   \u001b[0m | \u001b[0m 0.9343  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.6964  \u001b[0m | \u001b[0m 0.8167  \u001b[0m | \u001b[0m 4.552   \u001b[0m | \u001b[0m 0.9924  \u001b[0m | \u001b[0m 7.715   \u001b[0m | \u001b[0m 108.3   \u001b[0m | \u001b[0m 0.9194  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7174  \u001b[0m | \u001b[0m 0.8349  \u001b[0m | \u001b[0m 0.9181  \u001b[0m | \u001b[0m 0.6406  \u001b[0m | \u001b[0m 9.744   \u001b[0m | \u001b[0m 104.6   \u001b[0m | \u001b[0m 0.8866  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 0.8379  \u001b[0m | \u001b[0m 4.609   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 6.596   \u001b[0m | \u001b[0m 60.87   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_xgb.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample': 0.9314364096383931,\n",
       " 'gamma': 4.007451960090947,\n",
       " 'learning_rate': 0.07290528556170314,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 59,\n",
       " 'subsample': 0.870995901642737}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_xgb.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76613591 0.76420285 0.760671   0.77277149]\n",
      "최대성능: 0.7727714903718759\n",
      "평균성능: 0.7659453123972113\n"
     ]
    }
   ],
   "source": [
    "xgb_clf = XGBClassifier(**max_params)\n",
    "\n",
    "scores = cross_val_score(xgb_clf, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\n",
    "\n",
    "BO_tuned_clfs.append((xgb_clf.__class__.__name__, xgb_clf, max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = { 'learning_rate': (0.05, 1.5),\n",
    "            'n_estimators': (50, 500),\n",
    "            'max_depth': (3,10),   \n",
    "            'subsample': (0.8,0.95), \n",
    "            'colsample_bytree': (0.75,0.9),   \n",
    "            'num_leaves': (2,10),\n",
    "            'min_child_weight': (1, 7)}\n",
    "\n",
    "\n",
    "def lgbm_opt(learning_rate, n_estimators, max_depth, subsample, colsample_bytree, num_leaves, min_child_weight):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth' : int(round(max_depth)),\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree' : colsample_bytree,\n",
    "        'num_leaves' : int(round(num_leaves)),\n",
    "        'min_child_weight' : min_child_weight,\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "    \n",
    "    lgbm = LGBMClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(lgbm, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_lgbm = BayesianOptimization(f = lgbm_opt, pbounds = pbounds, random_state=1)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7526  \u001b[0m | \u001b[0m 0.8126  \u001b[0m | \u001b[0m 1.094   \u001b[0m | \u001b[0m 3.001   \u001b[0m | \u001b[0m 2.814   \u001b[0m | \u001b[0m 116.0   \u001b[0m | \u001b[0m 2.739   \u001b[0m | \u001b[0m 0.8279  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7497  \u001b[0m | \u001b[0m 0.8018  \u001b[0m | \u001b[0m 0.6253  \u001b[0m | \u001b[0m 6.772   \u001b[0m | \u001b[0m 3.515   \u001b[0m | \u001b[0m 358.3   \u001b[0m | \u001b[0m 3.636   \u001b[0m | \u001b[0m 0.9317  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7458  \u001b[0m | \u001b[0m 0.7541  \u001b[0m | \u001b[0m 1.022   \u001b[0m | \u001b[0m 5.921   \u001b[0m | \u001b[0m 4.352   \u001b[0m | \u001b[0m 113.2   \u001b[0m | \u001b[0m 3.585   \u001b[0m | \u001b[0m 0.9201  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7584  \u001b[0m | \u001b[95m 0.8952  \u001b[0m | \u001b[95m 0.5045  \u001b[0m | \u001b[95m 7.846   \u001b[0m | \u001b[95m 6.258   \u001b[0m | \u001b[95m 452.6   \u001b[0m | \u001b[95m 2.68    \u001b[0m | \u001b[95m 0.8059  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.6984  \u001b[0m | \u001b[0m 0.7755  \u001b[0m | \u001b[0m 1.323   \u001b[0m | \u001b[0m 3.688   \u001b[0m | \u001b[0m 3.527   \u001b[0m | \u001b[0m 481.1   \u001b[0m | \u001b[0m 6.265   \u001b[0m | \u001b[0m 0.9038  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7014  \u001b[0m | \u001b[0m 0.7973  \u001b[0m | \u001b[0m 1.045   \u001b[0m | \u001b[0m 8.842   \u001b[0m | \u001b[0m 1.11    \u001b[0m | \u001b[0m 387.6   \u001b[0m | \u001b[0m 9.911   \u001b[0m | \u001b[0m 0.9122  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7186  \u001b[0m | \u001b[0m 0.7921  \u001b[0m | \u001b[0m 1.194   \u001b[0m | \u001b[0m 3.723   \u001b[0m | \u001b[0m 3.687   \u001b[0m | \u001b[0m 458.9   \u001b[0m | \u001b[0m 4.349   \u001b[0m | \u001b[0m 0.8432  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7657  \u001b[0m | \u001b[95m 0.7695  \u001b[0m | \u001b[95m 0.07808 \u001b[0m | \u001b[95m 7.752   \u001b[0m | \u001b[95m 2.27    \u001b[0m | \u001b[95m 169.5   \u001b[0m | \u001b[95m 5.933   \u001b[0m | \u001b[95m 0.808   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 0.8361  \u001b[0m | \u001b[0m 0.2628  \u001b[0m | \u001b[0m 7.125   \u001b[0m | \u001b[0m 5.199   \u001b[0m | \u001b[0m 96.05   \u001b[0m | \u001b[0m 5.312   \u001b[0m | \u001b[0m 0.9042  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7622  \u001b[0m | \u001b[0m 0.8121  \u001b[0m | \u001b[0m 0.1224  \u001b[0m | \u001b[0m 6.751   \u001b[0m | \u001b[0m 4.983   \u001b[0m | \u001b[0m 281.7   \u001b[0m | \u001b[0m 9.557   \u001b[0m | \u001b[0m 0.888   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 0.8855  \u001b[0m | \u001b[0m 0.2493  \u001b[0m | \u001b[0m 3.975   \u001b[0m | \u001b[0m 5.844   \u001b[0m | \u001b[0m 229.0   \u001b[0m | \u001b[0m 3.323   \u001b[0m | \u001b[0m 0.9391  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7018  \u001b[0m | \u001b[0m 0.8022  \u001b[0m | \u001b[0m 1.139   \u001b[0m | \u001b[0m 8.082   \u001b[0m | \u001b[0m 6.3     \u001b[0m | \u001b[0m 330.7   \u001b[0m | \u001b[0m 8.008   \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.6976  \u001b[0m | \u001b[0m 0.7905  \u001b[0m | \u001b[0m 1.349   \u001b[0m | \u001b[0m 5.997   \u001b[0m | \u001b[0m 6.789   \u001b[0m | \u001b[0m 348.5   \u001b[0m | \u001b[0m 6.974   \u001b[0m | \u001b[0m 0.8172  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7377  \u001b[0m | \u001b[0m 0.8924  \u001b[0m | \u001b[0m 0.7024  \u001b[0m | \u001b[0m 7.049   \u001b[0m | \u001b[0m 3.449   \u001b[0m | \u001b[0m 156.7   \u001b[0m | \u001b[0m 9.227   \u001b[0m | \u001b[0m 0.8861  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7216  \u001b[0m | \u001b[0m 0.7504  \u001b[0m | \u001b[0m 0.9449  \u001b[0m | \u001b[0m 5.287   \u001b[0m | \u001b[0m 4.162   \u001b[0m | \u001b[0m 448.7   \u001b[0m | \u001b[0m 4.858   \u001b[0m | \u001b[0m 0.9363  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 0.8435  \u001b[0m | \u001b[0m 0.07294 \u001b[0m | \u001b[0m 9.506   \u001b[0m | \u001b[0m 5.145   \u001b[0m | \u001b[0m 498.8   \u001b[0m | \u001b[0m 3.379   \u001b[0m | \u001b[0m 0.8206  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7168  \u001b[0m | \u001b[0m 0.8899  \u001b[0m | \u001b[0m 1.06    \u001b[0m | \u001b[0m 3.462   \u001b[0m | \u001b[0m 5.533   \u001b[0m | \u001b[0m 389.2   \u001b[0m | \u001b[0m 9.384   \u001b[0m | \u001b[0m 0.9067  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.7686  \u001b[0m | \u001b[0m 0.07883 \u001b[0m | \u001b[0m 3.183   \u001b[0m | \u001b[0m 1.17    \u001b[0m | \u001b[0m 160.8   \u001b[0m | \u001b[0m 8.88    \u001b[0m | \u001b[0m 0.8808  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6969  \u001b[0m | \u001b[0m 0.8329  \u001b[0m | \u001b[0m 1.271   \u001b[0m | \u001b[0m 3.869   \u001b[0m | \u001b[0m 2.675   \u001b[0m | \u001b[0m 313.6   \u001b[0m | \u001b[0m 9.757   \u001b[0m | \u001b[0m 0.8842  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7046  \u001b[0m | \u001b[0m 0.7528  \u001b[0m | \u001b[0m 1.211   \u001b[0m | \u001b[0m 4.631   \u001b[0m | \u001b[0m 5.843   \u001b[0m | \u001b[0m 224.5   \u001b[0m | \u001b[0m 8.908   \u001b[0m | \u001b[0m 0.9121  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.8334  \u001b[0m | \u001b[0m 0.2479  \u001b[0m | \u001b[0m 3.419   \u001b[0m | \u001b[0m 1.728   \u001b[0m | \u001b[0m 70.05   \u001b[0m | \u001b[0m 2.86    \u001b[0m | \u001b[0m 0.8339  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7191  \u001b[0m | \u001b[0m 0.8569  \u001b[0m | \u001b[0m 0.8616  \u001b[0m | \u001b[0m 3.088   \u001b[0m | \u001b[0m 1.432   \u001b[0m | \u001b[0m 485.3   \u001b[0m | \u001b[0m 6.545   \u001b[0m | \u001b[0m 0.8305  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7003  \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 1.129   \u001b[0m | \u001b[0m 4.368   \u001b[0m | \u001b[0m 4.488   \u001b[0m | \u001b[0m 486.5   \u001b[0m | \u001b[0m 8.775   \u001b[0m | \u001b[0m 0.836   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.758   \u001b[0m | \u001b[0m 0.8241  \u001b[0m | \u001b[0m 0.9489  \u001b[0m | \u001b[0m 8.803   \u001b[0m | \u001b[0m 1.941   \u001b[0m | \u001b[0m 58.36   \u001b[0m | \u001b[0m 2.56    \u001b[0m | \u001b[0m 0.873   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7333  \u001b[0m | \u001b[0m 0.8409  \u001b[0m | \u001b[0m 0.8748  \u001b[0m | \u001b[0m 5.222   \u001b[0m | \u001b[0m 6.932   \u001b[0m | \u001b[0m 310.9   \u001b[0m | \u001b[0m 5.041   \u001b[0m | \u001b[0m 0.8826  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7165  \u001b[0m | \u001b[0m 0.8618  \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m 4.854   \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 216.5   \u001b[0m | \u001b[0m 7.038   \u001b[0m | \u001b[0m 0.8315  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.8629  \u001b[0m | \u001b[0m 0.1465  \u001b[0m | \u001b[0m 4.822   \u001b[0m | \u001b[0m 5.829   \u001b[0m | \u001b[0m 137.0   \u001b[0m | \u001b[0m 7.116   \u001b[0m | \u001b[0m 0.8787  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7463  \u001b[0m | \u001b[0m 0.8887  \u001b[0m | \u001b[0m 0.4318  \u001b[0m | \u001b[0m 3.462   \u001b[0m | \u001b[0m 5.41    \u001b[0m | \u001b[0m 397.5   \u001b[0m | \u001b[0m 9.263   \u001b[0m | \u001b[0m 0.9398  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7487  \u001b[0m | \u001b[0m 0.7521  \u001b[0m | \u001b[0m 0.3898  \u001b[0m | \u001b[0m 7.317   \u001b[0m | \u001b[0m 6.694   \u001b[0m | \u001b[0m 477.6   \u001b[0m | \u001b[0m 6.453   \u001b[0m | \u001b[0m 0.9373  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7285  \u001b[0m | \u001b[0m 0.8462  \u001b[0m | \u001b[0m 0.6155  \u001b[0m | \u001b[0m 6.402   \u001b[0m | \u001b[0m 4.626   \u001b[0m | \u001b[0m 297.3   \u001b[0m | \u001b[0m 9.409   \u001b[0m | \u001b[0m 0.9378  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7237  \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 4.218   \u001b[0m | \u001b[0m 1.758   \u001b[0m | \u001b[0m 110.8   \u001b[0m | \u001b[0m 6.045   \u001b[0m | \u001b[0m 0.8032  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.8922  \u001b[0m | \u001b[0m 1.249   \u001b[0m | \u001b[0m 3.105   \u001b[0m | \u001b[0m 2.057   \u001b[0m | \u001b[0m 199.4   \u001b[0m | \u001b[0m 3.048   \u001b[0m | \u001b[0m 0.9214  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6871  \u001b[0m | \u001b[0m 0.8017  \u001b[0m | \u001b[0m 1.413   \u001b[0m | \u001b[0m 7.074   \u001b[0m | \u001b[0m 6.273   \u001b[0m | \u001b[0m 430.1   \u001b[0m | \u001b[0m 9.243   \u001b[0m | \u001b[0m 0.869   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.759   \u001b[0m | \u001b[0m 0.832   \u001b[0m | \u001b[0m 1.208   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.942   \u001b[0m | \u001b[0m 319.6   \u001b[0m | \u001b[0m 2.124   \u001b[0m | \u001b[0m 0.889   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7416  \u001b[0m | \u001b[0m 0.8151  \u001b[0m | \u001b[0m 1.221   \u001b[0m | \u001b[0m 5.207   \u001b[0m | \u001b[0m 6.357   \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.472   \u001b[0m | \u001b[0m 0.9182  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7618  \u001b[0m | \u001b[0m 0.8418  \u001b[0m | \u001b[0m 0.1282  \u001b[0m | \u001b[0m 5.941   \u001b[0m | \u001b[0m 5.074   \u001b[0m | \u001b[0m 463.4   \u001b[0m | \u001b[0m 2.003   \u001b[0m | \u001b[0m 0.9465  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6931  \u001b[0m | \u001b[0m 0.8065  \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 7.233   \u001b[0m | \u001b[0m 5.973   \u001b[0m | \u001b[0m 308.6   \u001b[0m | \u001b[0m 7.025   \u001b[0m | \u001b[0m 0.8428  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7006  \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 1.138   \u001b[0m | \u001b[0m 9.008   \u001b[0m | \u001b[0m 5.53    \u001b[0m | \u001b[0m 364.1   \u001b[0m | \u001b[0m 8.916   \u001b[0m | \u001b[0m 0.8484  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7405  \u001b[0m | \u001b[0m 0.8506  \u001b[0m | \u001b[0m 0.7038  \u001b[0m | \u001b[0m 5.675   \u001b[0m | \u001b[0m 3.465   \u001b[0m | \u001b[0m 230.7   \u001b[0m | \u001b[0m 4.539   \u001b[0m | \u001b[0m 0.8933  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 0.8145  \u001b[0m | \u001b[0m 1.462   \u001b[0m | \u001b[0m 7.745   \u001b[0m | \u001b[0m 2.191   \u001b[0m | \u001b[0m 242.0   \u001b[0m | \u001b[0m 4.747   \u001b[0m | \u001b[0m 0.9196  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7039  \u001b[0m | \u001b[0m 0.882   \u001b[0m | \u001b[0m 1.361   \u001b[0m | \u001b[0m 7.639   \u001b[0m | \u001b[0m 2.621   \u001b[0m | \u001b[0m 163.6   \u001b[0m | \u001b[0m 8.839   \u001b[0m | \u001b[0m 0.8792  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7161  \u001b[0m | \u001b[0m 0.8703  \u001b[0m | \u001b[0m 0.8801  \u001b[0m | \u001b[0m 8.132   \u001b[0m | \u001b[0m 4.114   \u001b[0m | \u001b[0m 396.9   \u001b[0m | \u001b[0m 6.551   \u001b[0m | \u001b[0m 0.8699  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.1489  \u001b[0m | \u001b[0m 5.645   \u001b[0m | \u001b[0m 1.478   \u001b[0m | \u001b[0m 492.3   \u001b[0m | \u001b[0m 3.453   \u001b[0m | \u001b[0m 0.9218  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.728   \u001b[0m | \u001b[0m 0.8812  \u001b[0m | \u001b[0m 1.048   \u001b[0m | \u001b[0m 6.986   \u001b[0m | \u001b[0m 1.966   \u001b[0m | \u001b[0m 260.1   \u001b[0m | \u001b[0m 4.761   \u001b[0m | \u001b[0m 0.8338  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 0.8389  \u001b[0m | \u001b[0m 0.5028  \u001b[0m | \u001b[0m 9.414   \u001b[0m | \u001b[0m 6.458   \u001b[0m | \u001b[0m 165.7   \u001b[0m | \u001b[0m 2.887   \u001b[0m | \u001b[0m 0.8289  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7121  \u001b[0m | \u001b[0m 0.8249  \u001b[0m | \u001b[0m 1.106   \u001b[0m | \u001b[0m 4.457   \u001b[0m | \u001b[0m 2.488   \u001b[0m | \u001b[0m 433.3   \u001b[0m | \u001b[0m 5.327   \u001b[0m | \u001b[0m 0.8925  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 0.785   \u001b[0m | \u001b[0m 0.1979  \u001b[0m | \u001b[0m 6.611   \u001b[0m | \u001b[0m 3.863   \u001b[0m | \u001b[0m 118.7   \u001b[0m | \u001b[0m 6.974   \u001b[0m | \u001b[0m 0.8816  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7571  \u001b[0m | \u001b[0m 0.8481  \u001b[0m | \u001b[0m 0.2596  \u001b[0m | \u001b[0m 8.261   \u001b[0m | \u001b[0m 2.332   \u001b[0m | \u001b[0m 283.7   \u001b[0m | \u001b[0m 8.282   \u001b[0m | \u001b[0m 0.8033  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6888  \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 1.316   \u001b[0m | \u001b[0m 8.913   \u001b[0m | \u001b[0m 4.231   \u001b[0m | \u001b[0m 440.0   \u001b[0m | \u001b[0m 9.598   \u001b[0m | \u001b[0m 0.924   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 0.1932  \u001b[0m | \u001b[0m 7.559   \u001b[0m | \u001b[0m 5.221   \u001b[0m | \u001b[0m 324.6   \u001b[0m | \u001b[0m 8.397   \u001b[0m | \u001b[0m 0.8052  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7555  \u001b[0m | \u001b[0m 0.7743  \u001b[0m | \u001b[0m 0.5953  \u001b[0m | \u001b[0m 7.896   \u001b[0m | \u001b[0m 2.865   \u001b[0m | \u001b[0m 495.9   \u001b[0m | \u001b[0m 2.668   \u001b[0m | \u001b[0m 0.8072  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7619  \u001b[0m | \u001b[0m 0.8509  \u001b[0m | \u001b[0m 0.6169  \u001b[0m | \u001b[0m 7.067   \u001b[0m | \u001b[0m 5.791   \u001b[0m | \u001b[0m 169.2   \u001b[0m | \u001b[0m 2.533   \u001b[0m | \u001b[0m 0.8984  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7461  \u001b[0m | \u001b[0m 0.7833  \u001b[0m | \u001b[0m 1.282   \u001b[0m | \u001b[0m 9.459   \u001b[0m | \u001b[0m 1.635   \u001b[0m | \u001b[0m 171.1   \u001b[0m | \u001b[0m 2.8     \u001b[0m | \u001b[0m 0.9119  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7312  \u001b[0m | \u001b[0m 0.7746  \u001b[0m | \u001b[0m 0.999   \u001b[0m | \u001b[0m 9.152   \u001b[0m | \u001b[0m 6.031   \u001b[0m | \u001b[0m 170.3   \u001b[0m | \u001b[0m 5.924   \u001b[0m | \u001b[0m 0.8418  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.8354  \u001b[0m | \u001b[0m 0.3195  \u001b[0m | \u001b[0m 5.885   \u001b[0m | \u001b[0m 3.42    \u001b[0m | \u001b[0m 167.0   \u001b[0m | \u001b[0m 2.903   \u001b[0m | \u001b[0m 0.8078  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 0.7533  \u001b[0m | \u001b[0m 0.4289  \u001b[0m | \u001b[0m 4.113   \u001b[0m | \u001b[0m 1.155   \u001b[0m | \u001b[0m 170.3   \u001b[0m | \u001b[0m 5.209   \u001b[0m | \u001b[0m 0.9489  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.8295  \u001b[0m | \u001b[0m 0.5403  \u001b[0m | \u001b[0m 5.703   \u001b[0m | \u001b[0m 1.819   \u001b[0m | \u001b[0m 65.08   \u001b[0m | \u001b[0m 2.733   \u001b[0m | \u001b[0m 0.8502  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7593  \u001b[0m | \u001b[0m 0.8617  \u001b[0m | \u001b[0m 0.7491  \u001b[0m | \u001b[0m 8.473   \u001b[0m | \u001b[0m 1.966   \u001b[0m | \u001b[0m 69.35   \u001b[0m | \u001b[0m 3.999   \u001b[0m | \u001b[0m 0.8736  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.7572  \u001b[0m | \u001b[0m 0.8714  \u001b[0m | \u001b[0m 0.5618  \u001b[0m | \u001b[0m 4.154   \u001b[0m | \u001b[0m 2.963   \u001b[0m | \u001b[0m 67.28   \u001b[0m | \u001b[0m 7.331   \u001b[0m | \u001b[0m 0.928   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 0.8839  \u001b[0m | \u001b[0m 0.257   \u001b[0m | \u001b[0m 4.975   \u001b[0m | \u001b[0m 6.532   \u001b[0m | \u001b[0m 68.92   \u001b[0m | \u001b[0m 2.668   \u001b[0m | \u001b[0m 0.855   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7617  \u001b[0m | \u001b[0m 0.8218  \u001b[0m | \u001b[0m 0.0992  \u001b[0m | \u001b[0m 8.297   \u001b[0m | \u001b[0m 6.966   \u001b[0m | \u001b[0m 468.5   \u001b[0m | \u001b[0m 2.477   \u001b[0m | \u001b[0m 0.9362  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.8839  \u001b[0m | \u001b[0m 0.3768  \u001b[0m | \u001b[0m 9.844   \u001b[0m | \u001b[0m 5.368   \u001b[0m | \u001b[0m 63.38   \u001b[0m | \u001b[0m 5.299   \u001b[0m | \u001b[0m 0.8491  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.7563  \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 0.0653  \u001b[0m | \u001b[0m 3.897   \u001b[0m | \u001b[0m 6.288   \u001b[0m | \u001b[0m 61.06   \u001b[0m | \u001b[0m 2.524   \u001b[0m | \u001b[0m 0.8692  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 0.8367  \u001b[0m | \u001b[0m 0.189   \u001b[0m | \u001b[0m 5.323   \u001b[0m | \u001b[0m 5.152   \u001b[0m | \u001b[0m 130.7   \u001b[0m | \u001b[0m 6.893   \u001b[0m | \u001b[0m 0.8792  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7376  \u001b[0m | \u001b[0m 0.7764  \u001b[0m | \u001b[0m 1.263   \u001b[0m | \u001b[0m 5.591   \u001b[0m | \u001b[0m 4.435   \u001b[0m | \u001b[0m 123.6   \u001b[0m | \u001b[0m 4.049   \u001b[0m | \u001b[0m 0.9068  \u001b[0m |\n",
      "| \u001b[95m 66      \u001b[0m | \u001b[95m 0.7663  \u001b[0m | \u001b[95m 0.7641  \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 8.878   \u001b[0m | \u001b[95m 7.0     \u001b[0m | \u001b[95m 134.1   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.8     \u001b[0m |\n",
      "| \u001b[95m 67      \u001b[0m | \u001b[95m 0.7664  \u001b[0m | \u001b[95m 0.8124  \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 6.626   \u001b[0m | \u001b[95m 1.378   \u001b[0m | \u001b[95m 134.5   \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 0.8026  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 0.776   \u001b[0m | \u001b[0m 0.1868  \u001b[0m | \u001b[0m 9.063   \u001b[0m | \u001b[0m 2.302   \u001b[0m | \u001b[0m 134.3   \u001b[0m | \u001b[0m 4.138   \u001b[0m | \u001b[0m 0.9294  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7237  \u001b[0m | \u001b[0m 0.7965  \u001b[0m | \u001b[0m 0.9401  \u001b[0m | \u001b[0m 9.225   \u001b[0m | \u001b[0m 2.941   \u001b[0m | \u001b[0m 139.8   \u001b[0m | \u001b[0m 8.971   \u001b[0m | \u001b[0m 0.8768  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7456  \u001b[0m | \u001b[0m 0.8074  \u001b[0m | \u001b[0m 0.857   \u001b[0m | \u001b[0m 3.061   \u001b[0m | \u001b[0m 1.042   \u001b[0m | \u001b[0m 133.5   \u001b[0m | \u001b[0m 6.32    \u001b[0m | \u001b[0m 0.9443  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7624  \u001b[0m | \u001b[0m 0.802   \u001b[0m | \u001b[0m 0.3494  \u001b[0m | \u001b[0m 9.919   \u001b[0m | \u001b[0m 6.722   \u001b[0m | \u001b[0m 131.1   \u001b[0m | \u001b[0m 5.301   \u001b[0m | \u001b[0m 0.8504  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7574  \u001b[0m | \u001b[0m 0.7887  \u001b[0m | \u001b[0m 0.3279  \u001b[0m | \u001b[0m 9.0     \u001b[0m | \u001b[0m 3.453   \u001b[0m | \u001b[0m 129.2   \u001b[0m | \u001b[0m 9.672   \u001b[0m | \u001b[0m 0.8678  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.745   \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 1.498   \u001b[0m | \u001b[0m 5.125   \u001b[0m | \u001b[0m 6.951   \u001b[0m | \u001b[0m 134.9   \u001b[0m | \u001b[0m 2.85    \u001b[0m | \u001b[0m 0.8017  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7615  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 158.8   \u001b[0m | \u001b[0m 3.252   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 4.012   \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 5.325   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7585  \u001b[0m | \u001b[0m 0.7975  \u001b[0m | \u001b[0m 0.1537  \u001b[0m | \u001b[0m 8.363   \u001b[0m | \u001b[0m 4.375   \u001b[0m | \u001b[0m 499.7   \u001b[0m | \u001b[0m 8.694   \u001b[0m | \u001b[0m 0.9404  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 4.456   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 162.5   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.8097  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 470.5   \u001b[0m | \u001b[0m 9.509   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.199   \u001b[0m | \u001b[0m 468.1   \u001b[0m | \u001b[0m 5.77    \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 464.1   \u001b[0m | \u001b[0m 7.14    \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7598  \u001b[0m | \u001b[0m 0.7854  \u001b[0m | \u001b[0m 0.1643  \u001b[0m | \u001b[0m 3.908   \u001b[0m | \u001b[0m 6.44    \u001b[0m | \u001b[0m 468.1   \u001b[0m | \u001b[0m 7.73    \u001b[0m | \u001b[0m 0.8453  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 133.8   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 0.8598  \u001b[0m | \u001b[0m 0.2057  \u001b[0m | \u001b[0m 7.492   \u001b[0m | \u001b[0m 6.084   \u001b[0m | \u001b[0m 88.56   \u001b[0m | \u001b[0m 6.588   \u001b[0m | \u001b[0m 0.9416  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7599  \u001b[0m | \u001b[0m 0.8056  \u001b[0m | \u001b[0m 1.315   \u001b[0m | \u001b[0m 4.909   \u001b[0m | \u001b[0m 1.003   \u001b[0m | \u001b[0m 90.5    \u001b[0m | \u001b[0m 2.146   \u001b[0m | \u001b[0m 0.8195  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7282  \u001b[0m | \u001b[0m 0.7585  \u001b[0m | \u001b[0m 1.112   \u001b[0m | \u001b[0m 3.846   \u001b[0m | \u001b[0m 3.231   \u001b[0m | \u001b[0m 90.95   \u001b[0m | \u001b[0m 9.134   \u001b[0m | \u001b[0m 0.8158  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 0.8411  \u001b[0m | \u001b[0m 0.8147  \u001b[0m | \u001b[0m 8.503   \u001b[0m | \u001b[0m 6.303   \u001b[0m | \u001b[0m 91.32   \u001b[0m | \u001b[0m 2.005   \u001b[0m | \u001b[0m 0.8173  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7585  \u001b[0m | \u001b[0m 0.7688  \u001b[0m | \u001b[0m 0.9402  \u001b[0m | \u001b[0m 9.888   \u001b[0m | \u001b[0m 5.857   \u001b[0m | \u001b[0m 82.17   \u001b[0m | \u001b[0m 3.177   \u001b[0m | \u001b[0m 0.8785  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 0.811   \u001b[0m | \u001b[0m 0.3052  \u001b[0m | \u001b[0m 3.807   \u001b[0m | \u001b[0m 5.319   \u001b[0m | \u001b[0m 76.52   \u001b[0m | \u001b[0m 6.76    \u001b[0m | \u001b[0m 0.8849  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.8298  \u001b[0m | \u001b[0m 0.2261  \u001b[0m | \u001b[0m 3.286   \u001b[0m | \u001b[0m 6.359   \u001b[0m | \u001b[0m 82.39   \u001b[0m | \u001b[0m 2.648   \u001b[0m | \u001b[0m 0.8876  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7527  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 4.65    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 78.36   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.8743  \u001b[0m | \u001b[0m 0.05336 \u001b[0m | \u001b[0m 3.276   \u001b[0m | \u001b[0m 4.532   \u001b[0m | \u001b[0m 279.2   \u001b[0m | \u001b[0m 2.628   \u001b[0m | \u001b[0m 0.8998  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 277.5   \u001b[0m | \u001b[0m 4.144   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7511  \u001b[0m | \u001b[0m 0.8049  \u001b[0m | \u001b[0m 0.3631  \u001b[0m | \u001b[0m 5.633   \u001b[0m | \u001b[0m 3.728   \u001b[0m | \u001b[0m 274.8   \u001b[0m | \u001b[0m 7.826   \u001b[0m | \u001b[0m 0.8057  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.759   \u001b[0m | \u001b[0m 0.8308  \u001b[0m | \u001b[0m 1.239   \u001b[0m | \u001b[0m 8.979   \u001b[0m | \u001b[0m 6.994   \u001b[0m | \u001b[0m 283.8   \u001b[0m | \u001b[0m 2.392   \u001b[0m | \u001b[0m 0.9245  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7578  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 278.7   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7475  \u001b[0m | \u001b[0m 0.8008  \u001b[0m | \u001b[0m 0.6296  \u001b[0m | \u001b[0m 9.757   \u001b[0m | \u001b[0m 6.631   \u001b[0m | \u001b[0m 72.57   \u001b[0m | \u001b[0m 9.934   \u001b[0m | \u001b[0m 0.9316  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7527  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 97.0    \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 0.835   \u001b[0m | \u001b[0m 0.163   \u001b[0m | \u001b[0m 9.941   \u001b[0m | \u001b[0m 6.483   \u001b[0m | \u001b[0m 56.75   \u001b[0m | \u001b[0m 9.433   \u001b[0m | \u001b[0m 0.8933  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7246  \u001b[0m | \u001b[0m 0.7504  \u001b[0m | \u001b[0m 1.26    \u001b[0m | \u001b[0m 5.654   \u001b[0m | \u001b[0m 2.276   \u001b[0m | \u001b[0m 59.11   \u001b[0m | \u001b[0m 9.972   \u001b[0m | \u001b[0m 0.8058  \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_lgbm.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.8124210338525666,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 7,\n",
       " 'min_child_weight': 1.3775741782035542,\n",
       " 'n_estimators': 135,\n",
       " 'num_leaves': 10,\n",
       " 'subsample': 0.802578631594766}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_lgbm.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76704555 0.76435784 0.76089909 0.77330857]\n",
      "최대성능: 0.7733085736865913\n",
      "평균성능: 0.7664027627819948\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(**max_params)\n",
    "\n",
    "scores = cross_val_score(lgbm_clf, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\n",
    "\n",
    "BO_tuned_clfs.append((lgbm_clf.__class__.__name__, lgbm_clf, max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = { 'n_estimators': (50, 500),\n",
    "            'max_depth': (3,10),    \n",
    "            'max_features': (0.8,0.95),\n",
    "            'min_samples_split': (2, 5),\n",
    "            'min_samples_leaf': (1, 5)\n",
    "            }\n",
    "\n",
    "def extra_opt(n_estimators, max_depth, max_features, min_samples_split, min_samples_leaf):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': int(round(n_estimators)),\n",
    "        'max_depth': int(round(max_depth)),\n",
    "        'max_features' : max_features,\n",
    "        'min_samples_leaf': int(round(min_samples_leaf)),\n",
    "        'min_samples_split': int(round(min_samples_split)),\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "    \n",
    "    extra = ExtraTreesClassifier(bootstrap = True, oob_score=True, **params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(extra, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_extra = BayesianOptimization(f = extra_opt, pbounds = pbounds, random_state=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.764   \u001b[0m | \u001b[0m 6.842   \u001b[0m | \u001b[0m 0.9073  \u001b[0m | \u001b[0m 3.411   \u001b[0m | \u001b[0m 3.635   \u001b[0m | \u001b[0m 240.6   \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.765   \u001b[0m | \u001b[95m 7.521   \u001b[0m | \u001b[95m 0.8656  \u001b[0m | \u001b[95m 4.567   \u001b[0m | \u001b[95m 4.891   \u001b[0m | \u001b[95m 222.5   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7652  \u001b[0m | \u001b[95m 8.542   \u001b[0m | \u001b[95m 0.8793  \u001b[0m | \u001b[95m 3.272   \u001b[0m | \u001b[95m 4.777   \u001b[0m | \u001b[95m 81.97   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.758   \u001b[0m | \u001b[0m 3.61    \u001b[0m | \u001b[0m 0.803   \u001b[0m | \u001b[0m 4.33    \u001b[0m | \u001b[0m 4.334   \u001b[0m | \u001b[0m 441.5   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 9.85    \u001b[0m | \u001b[0m 0.9199  \u001b[0m | \u001b[0m 2.846   \u001b[0m | \u001b[0m 4.342   \u001b[0m | \u001b[0m 103.2   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 7.479   \u001b[0m | \u001b[0m 0.8215  \u001b[0m | \u001b[0m 4.779   \u001b[0m | \u001b[0m 3.566   \u001b[0m | \u001b[0m 236.6   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 4.852   \u001b[0m | \u001b[0m 0.9161  \u001b[0m | \u001b[0m 2.825   \u001b[0m | \u001b[0m 3.705   \u001b[0m | \u001b[0m 58.46   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 7.323   \u001b[0m | \u001b[0m 0.8918  \u001b[0m | \u001b[0m 3.468   \u001b[0m | \u001b[0m 4.831   \u001b[0m | \u001b[0m 356.8   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7628  \u001b[0m | \u001b[0m 5.517   \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 3.791   \u001b[0m | \u001b[0m 2.181   \u001b[0m | \u001b[0m 350.0   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 7.694   \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 1.516   \u001b[0m | \u001b[0m 2.946   \u001b[0m | \u001b[0m 213.7   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 6.991   \u001b[0m | \u001b[0m 0.8658  \u001b[0m | \u001b[0m 4.953   \u001b[0m | \u001b[0m 2.306   \u001b[0m | \u001b[0m 144.0   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 4.129   \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 2.013   \u001b[0m | \u001b[0m 3.399   \u001b[0m | \u001b[0m 160.0   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7576  \u001b[0m | \u001b[0m 4.113   \u001b[0m | \u001b[0m 0.8166  \u001b[0m | \u001b[0m 3.625   \u001b[0m | \u001b[0m 2.415   \u001b[0m | \u001b[0m 138.5   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7625  \u001b[0m | \u001b[0m 5.581   \u001b[0m | \u001b[0m 0.9231  \u001b[0m | \u001b[0m 1.388   \u001b[0m | \u001b[0m 4.514   \u001b[0m | \u001b[0m 93.24   \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.7657  \u001b[0m | \u001b[95m 9.835   \u001b[0m | \u001b[95m 0.8703  \u001b[0m | \u001b[95m 4.907   \u001b[0m | \u001b[95m 3.815   \u001b[0m | \u001b[95m 382.7   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7526  \u001b[0m | \u001b[0m 3.274   \u001b[0m | \u001b[0m 0.8424  \u001b[0m | \u001b[0m 1.481   \u001b[0m | \u001b[0m 2.888   \u001b[0m | \u001b[0m 103.4   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 5.226   \u001b[0m | \u001b[0m 0.8621  \u001b[0m | \u001b[0m 1.257   \u001b[0m | \u001b[0m 4.077   \u001b[0m | \u001b[0m 305.0   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.761   \u001b[0m | \u001b[0m 4.858   \u001b[0m | \u001b[0m 0.8785  \u001b[0m | \u001b[0m 1.376   \u001b[0m | \u001b[0m 3.728   \u001b[0m | \u001b[0m 468.2   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 5.23    \u001b[0m | \u001b[0m 0.9001  \u001b[0m | \u001b[0m 1.527   \u001b[0m | \u001b[0m 4.149   \u001b[0m | \u001b[0m 180.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7576  \u001b[0m | \u001b[0m 4.282   \u001b[0m | \u001b[0m 0.888   \u001b[0m | \u001b[0m 1.08    \u001b[0m | \u001b[0m 4.487   \u001b[0m | \u001b[0m 52.11   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 7.745   \u001b[0m | \u001b[0m 0.8405  \u001b[0m | \u001b[0m 3.941   \u001b[0m | \u001b[0m 4.887   \u001b[0m | \u001b[0m 161.9   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.764   \u001b[0m | \u001b[0m 7.033   \u001b[0m | \u001b[0m 0.8888  \u001b[0m | \u001b[0m 3.289   \u001b[0m | \u001b[0m 2.669   \u001b[0m | \u001b[0m 478.7   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7626  \u001b[0m | \u001b[0m 6.13    \u001b[0m | \u001b[0m 0.927   \u001b[0m | \u001b[0m 3.798   \u001b[0m | \u001b[0m 2.892   \u001b[0m | \u001b[0m 416.2   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 5.776   \u001b[0m | \u001b[0m 0.9322  \u001b[0m | \u001b[0m 3.325   \u001b[0m | \u001b[0m 4.645   \u001b[0m | \u001b[0m 361.6   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 8.077   \u001b[0m | \u001b[0m 0.8752  \u001b[0m | \u001b[0m 4.824   \u001b[0m | \u001b[0m 3.932   \u001b[0m | \u001b[0m 240.7   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.764   \u001b[0m | \u001b[0m 7.245   \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 2.206   \u001b[0m | \u001b[0m 3.981   \u001b[0m | \u001b[0m 180.5   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 7.326   \u001b[0m | \u001b[0m 0.8643  \u001b[0m | \u001b[0m 1.542   \u001b[0m | \u001b[0m 2.895   \u001b[0m | \u001b[0m 306.5   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7641  \u001b[0m | \u001b[0m 7.136   \u001b[0m | \u001b[0m 0.8861  \u001b[0m | \u001b[0m 3.613   \u001b[0m | \u001b[0m 3.956   \u001b[0m | \u001b[0m 244.1   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 9.276   \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 2.743   \u001b[0m | \u001b[0m 4.676   \u001b[0m | \u001b[0m 412.8   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 7.927   \u001b[0m | \u001b[0m 0.815   \u001b[0m | \u001b[0m 4.678   \u001b[0m | \u001b[0m 4.143   \u001b[0m | \u001b[0m 499.5   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7573  \u001b[0m | \u001b[0m 4.046   \u001b[0m | \u001b[0m 0.9302  \u001b[0m | \u001b[0m 1.65    \u001b[0m | \u001b[0m 3.847   \u001b[0m | \u001b[0m 105.7   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 8.936   \u001b[0m | \u001b[0m 0.9211  \u001b[0m | \u001b[0m 3.276   \u001b[0m | \u001b[0m 3.222   \u001b[0m | \u001b[0m 81.13   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 7.882   \u001b[0m | \u001b[0m 0.868   \u001b[0m | \u001b[0m 3.888   \u001b[0m | \u001b[0m 4.599   \u001b[0m | \u001b[0m 489.0   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 8.991   \u001b[0m | \u001b[0m 0.8018  \u001b[0m | \u001b[0m 2.44    \u001b[0m | \u001b[0m 4.19    \u001b[0m | \u001b[0m 127.2   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 6.647   \u001b[0m | \u001b[0m 0.8082  \u001b[0m | \u001b[0m 1.8     \u001b[0m | \u001b[0m 2.056   \u001b[0m | \u001b[0m 407.2   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 4.567   \u001b[0m | \u001b[0m 0.8518  \u001b[0m | \u001b[0m 4.712   \u001b[0m | \u001b[0m 4.113   \u001b[0m | \u001b[0m 64.33   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 4.153   \u001b[0m | \u001b[0m 0.8932  \u001b[0m | \u001b[0m 3.309   \u001b[0m | \u001b[0m 2.714   \u001b[0m | \u001b[0m 470.4   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 7.298   \u001b[0m | \u001b[0m 0.8803  \u001b[0m | \u001b[0m 3.36    \u001b[0m | \u001b[0m 4.19    \u001b[0m | \u001b[0m 190.4   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 5.788   \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 1.745   \u001b[0m | \u001b[0m 4.833   \u001b[0m | \u001b[0m 382.8   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 6.433   \u001b[0m | \u001b[0m 0.8341  \u001b[0m | \u001b[0m 2.017   \u001b[0m | \u001b[0m 2.174   \u001b[0m | \u001b[0m 245.5   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 5.183   \u001b[0m | \u001b[0m 0.9045  \u001b[0m | \u001b[0m 2.511   \u001b[0m | \u001b[0m 2.539   \u001b[0m | \u001b[0m 61.11   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7533  \u001b[0m | \u001b[0m 3.471   \u001b[0m | \u001b[0m 0.9019  \u001b[0m | \u001b[0m 2.815   \u001b[0m | \u001b[0m 3.61    \u001b[0m | \u001b[0m 453.5   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 9.932   \u001b[0m | \u001b[0m 0.8325  \u001b[0m | \u001b[0m 3.652   \u001b[0m | \u001b[0m 2.79    \u001b[0m | \u001b[0m 59.29   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 8.309   \u001b[0m | \u001b[0m 0.848   \u001b[0m | \u001b[0m 2.534   \u001b[0m | \u001b[0m 3.765   \u001b[0m | \u001b[0m 424.0   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 0.9309  \u001b[0m | \u001b[0m 2.094   \u001b[0m | \u001b[0m 4.394   \u001b[0m | \u001b[0m 133.5   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 9.67    \u001b[0m | \u001b[0m 0.9031  \u001b[0m | \u001b[0m 1.862   \u001b[0m | \u001b[0m 4.842   \u001b[0m | \u001b[0m 378.9   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 4.778   \u001b[0m | \u001b[0m 0.832   \u001b[0m | \u001b[0m 3.073   \u001b[0m | \u001b[0m 2.077   \u001b[0m | \u001b[0m 143.4   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 5.973   \u001b[0m | \u001b[0m 0.8561  \u001b[0m | \u001b[0m 2.854   \u001b[0m | \u001b[0m 2.833   \u001b[0m | \u001b[0m 314.1   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 9.047   \u001b[0m | \u001b[0m 0.8176  \u001b[0m | \u001b[0m 3.07    \u001b[0m | \u001b[0m 2.396   \u001b[0m | \u001b[0m 372.6   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 5.772   \u001b[0m | \u001b[0m 0.8848  \u001b[0m | \u001b[0m 1.733   \u001b[0m | \u001b[0m 2.435   \u001b[0m | \u001b[0m 269.6   \u001b[0m |\n",
      "| \u001b[95m 51      \u001b[0m | \u001b[95m 0.7659  \u001b[0m | \u001b[95m 9.877   \u001b[0m | \u001b[95m 0.8739  \u001b[0m | \u001b[95m 4.78    \u001b[0m | \u001b[95m 3.078   \u001b[0m | \u001b[95m 377.4   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 4.853   \u001b[0m | \u001b[0m 0.921   \u001b[0m | \u001b[0m 4.158   \u001b[0m | \u001b[0m 3.199   \u001b[0m | \u001b[0m 375.6   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.949   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 408.8   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.46    \u001b[0m | \u001b[0m 183.3   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 166.1   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 9.831   \u001b[0m | \u001b[0m 0.8793  \u001b[0m | \u001b[0m 4.112   \u001b[0m | \u001b[0m 3.526   \u001b[0m | \u001b[0m 176.0   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 9.934   \u001b[0m | \u001b[0m 0.8258  \u001b[0m | \u001b[0m 1.258   \u001b[0m | \u001b[0m 4.424   \u001b[0m | \u001b[0m 169.7   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7532  \u001b[0m | \u001b[0m 3.015   \u001b[0m | \u001b[0m 0.9452  \u001b[0m | \u001b[0m 3.049   \u001b[0m | \u001b[0m 2.024   \u001b[0m | \u001b[0m 219.0   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 9.41    \u001b[0m | \u001b[0m 0.8887  \u001b[0m | \u001b[0m 4.616   \u001b[0m | \u001b[0m 4.766   \u001b[0m | \u001b[0m 228.0   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 6.465   \u001b[0m | \u001b[0m 0.9188  \u001b[0m | \u001b[0m 4.976   \u001b[0m | \u001b[0m 2.139   \u001b[0m | \u001b[0m 169.2   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 9.499   \u001b[0m | \u001b[0m 0.9433  \u001b[0m | \u001b[0m 2.333   \u001b[0m | \u001b[0m 3.969   \u001b[0m | \u001b[0m 208.7   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 9.998   \u001b[0m | \u001b[0m 0.8303  \u001b[0m | \u001b[0m 1.666   \u001b[0m | \u001b[0m 2.169   \u001b[0m | \u001b[0m 494.6   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.761   \u001b[0m | \u001b[0m 4.529   \u001b[0m | \u001b[0m 0.872   \u001b[0m | \u001b[0m 2.019   \u001b[0m | \u001b[0m 3.997   \u001b[0m | \u001b[0m 494.8   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 164.6   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.758   \u001b[0m | \u001b[0m 3.507   \u001b[0m | \u001b[0m 0.8818  \u001b[0m | \u001b[0m 4.032   \u001b[0m | \u001b[0m 4.514   \u001b[0m | \u001b[0m 126.1   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 9.393   \u001b[0m | \u001b[0m 0.9416  \u001b[0m | \u001b[0m 4.644   \u001b[0m | \u001b[0m 2.149   \u001b[0m | \u001b[0m 484.6   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7581  \u001b[0m | \u001b[0m 3.932   \u001b[0m | \u001b[0m 0.937   \u001b[0m | \u001b[0m 4.906   \u001b[0m | \u001b[0m 2.176   \u001b[0m | \u001b[0m 484.8   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 224.7   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 9.94    \u001b[0m | \u001b[0m 0.8085  \u001b[0m | \u001b[0m 1.033   \u001b[0m | \u001b[0m 2.579   \u001b[0m | \u001b[0m 486.8   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7532  \u001b[0m | \u001b[0m 3.089   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.103   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 80.47   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7648  \u001b[0m | \u001b[0m 9.687   \u001b[0m | \u001b[0m 0.8547  \u001b[0m | \u001b[0m 4.906   \u001b[0m | \u001b[0m 3.227   \u001b[0m | \u001b[0m 85.33   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 4.697   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 409.8   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 9.841   \u001b[0m | \u001b[0m 0.8821  \u001b[0m | \u001b[0m 1.574   \u001b[0m | \u001b[0m 4.989   \u001b[0m | \u001b[0m 185.5   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 9.772   \u001b[0m | \u001b[0m 0.8467  \u001b[0m | \u001b[0m 2.606   \u001b[0m | \u001b[0m 4.31    \u001b[0m | \u001b[0m 402.3   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 6.324   \u001b[0m | \u001b[0m 0.8523  \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 2.266   \u001b[0m | \u001b[0m 398.4   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 491.3   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 130.3   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 481.9   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 109.3   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 148.9   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 389.2   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 5.265   \u001b[0m | \u001b[0m 0.8162  \u001b[0m | \u001b[0m 1.057   \u001b[0m | \u001b[0m 2.515   \u001b[0m | \u001b[0m 203.5   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.758   \u001b[0m | \u001b[0m 4.471   \u001b[0m | \u001b[0m 0.8267  \u001b[0m | \u001b[0m 4.829   \u001b[0m | \u001b[0m 4.702   \u001b[0m | \u001b[0m 391.3   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 404.8   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7543  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 427.1   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 385.6   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 9.934   \u001b[0m | \u001b[0m 0.8642  \u001b[0m | \u001b[0m 1.588   \u001b[0m | \u001b[0m 4.591   \u001b[0m | \u001b[0m 420.0   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 213.4   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 3.232   \u001b[0m | \u001b[0m 118.0   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 9.028   \u001b[0m | \u001b[0m 0.8184  \u001b[0m | \u001b[0m 4.878   \u001b[0m | \u001b[0m 4.394   \u001b[0m | \u001b[0m 282.7   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.758   \u001b[0m | \u001b[0m 3.558   \u001b[0m | \u001b[0m 0.8304  \u001b[0m | \u001b[0m 1.04    \u001b[0m | \u001b[0m 2.594   \u001b[0m | \u001b[0m 282.6   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.9399  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 289.1   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 295.3   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7578  \u001b[0m | \u001b[0m 3.509   \u001b[0m | \u001b[0m 0.9139  \u001b[0m | \u001b[0m 4.481   \u001b[0m | \u001b[0m 4.534   \u001b[0m | \u001b[0m 293.0   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 9.53    \u001b[0m | \u001b[0m 0.8549  \u001b[0m | \u001b[0m 1.24    \u001b[0m | \u001b[0m 4.956   \u001b[0m | \u001b[0m 334.0   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 3.501   \u001b[0m | \u001b[0m 0.8295  \u001b[0m | \u001b[0m 2.464   \u001b[0m | \u001b[0m 2.232   \u001b[0m | \u001b[0m 332.3   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 9.975   \u001b[0m | \u001b[0m 0.9409  \u001b[0m | \u001b[0m 2.524   \u001b[0m | \u001b[0m 4.051   \u001b[0m | \u001b[0m 339.7   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 301.6   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 9.915   \u001b[0m | \u001b[0m 0.8374  \u001b[0m | \u001b[0m 4.765   \u001b[0m | \u001b[0m 4.713   \u001b[0m | \u001b[0m 276.6   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 8.721   \u001b[0m | \u001b[0m 0.8396  \u001b[0m | \u001b[0m 4.657   \u001b[0m | \u001b[0m 4.69    \u001b[0m | \u001b[0m 258.9   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_extra.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 10,\n",
       " 'max_features': 0.8739027312882421,\n",
       " 'min_samples_leaf': 5,\n",
       " 'min_samples_split': 3,\n",
       " 'n_estimators': 377}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_extra.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['min_samples_leaf'] = int(round(max_params['min_samples_leaf']))\n",
    "max_params['min_samples_split'] = int(round(max_params['min_samples_split']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76880292 0.76232182 0.76071851 0.77097248]\n",
      "최대성능: 0.7709724837281234\n",
      "평균성능: 0.7657039347613478\n"
     ]
    }
   ],
   "source": [
    "extra_clf = ExtraTreesClassifier(bootstrap = True, oob_score=True, **max_params)\n",
    "\n",
    "scores = cross_val_score(extra_clf, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\n",
    "\n",
    "BO_tuned_clfs.append((extra_clf.__class__.__name__, extra_clf, max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBM\n",
    "- GBM은 시간이 매우 오래 걸리지만, 성능은 그닥 좋지 않음. 스킵해도 무방."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"pbounds = { 'learning_rate': (0.05, 1.5),\\n            'n_estimators': (50, 500),\\n            'max_depth': (3,10),   \\n            'subsample': (0.8,0.95), \\n            'min_samples_split': (2,5),   \\n            'min_samples_leaf': (1,5)}\\n\\n\\ndef gbm_opt(learning_rate, n_estimators, max_depth, subsample, min_samples_split, min_samples_leaf):\\n\\n    params = {\\n        'learning_rate': learning_rate,\\n        'n_estimators' : int(round(n_estimators)),\\n        'max_depth' : int(round(max_depth)),\\n        'subsample': subsample,\\n        'min_samples_split' : int(round(min_samples_split)),\\n        'min_samples_leaf' : int(round(min_samples_leaf))\\n    }\\n    \\n    gbm = GradientBoostingClassifier(**params)\\n    \\n    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\\n\\n    score = cross_val_score(gbm, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\\n    \\n    return np.mean(score)\\n\\nBO_gbm = BayesianOptimization(f = gbm_opt, pbounds = pbounds, random_state=0)    \""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''pbounds = { 'learning_rate': (0.05, 1.5),\n",
    "            'n_estimators': (50, 500),\n",
    "            'max_depth': (3,10),   \n",
    "            'subsample': (0.8,0.95), \n",
    "            'min_samples_split': (2,5),   \n",
    "            'min_samples_leaf': (1,5)}\n",
    "\n",
    "\n",
    "def gbm_opt(learning_rate, n_estimators, max_depth, subsample, min_samples_split, min_samples_leaf):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth' : int(round(max_depth)),\n",
    "        'subsample': subsample,\n",
    "        'min_samples_split' : int(round(min_samples_split)),\n",
    "        'min_samples_leaf' : int(round(min_samples_leaf))\n",
    "    }\n",
    "    \n",
    "    gbm = GradientBoostingClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(gbm, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_gbm = BayesianOptimization(f = gbm_opt, pbounds = pbounds, random_state=0)    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'BO_gbm.maximize(init_points=50, n_iter=50)'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''BO_gbm.maximize(init_points=50, n_iter=50)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"max_params = BO_gbm.max['params']\\n\\nmax_params['n_estimators'] = int(round(max_params['n_estimators']))\\nmax_params['max_depth'] = int(round(max_params['max_depth']))\\nmax_params['min_samples_leaf'] = int(round(max_params['min_samples_leaf']))\\nmax_params['min_samples_split'] = int(round(max_params['min_samples_split']))\\n\\nmax_params\""
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''max_params = BO_gbm.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['min_samples_leaf'] = int(round(max_params['min_samples_leaf']))\n",
    "max_params['min_samples_split'] = int(round(max_params['min_samples_split']))\n",
    "\n",
    "max_params'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"gbm_clf = GradientBoostingClassifier(**max_params)\\n\\nscores = cross_val_score(gbm_clf, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\\n\\nprint(scores)\\nprint(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\\n\\nBO_tuned_clfs.append((gbm_clf.__class__.__name__, gbm_clf, max(scores)))\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''gbm_clf = GradientBoostingClassifier(**max_params)\n",
    "\n",
    "scores = cross_val_score(gbm_clf, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\n",
    "\n",
    "BO_tuned_clfs.append((gbm_clf.__class__.__name__, gbm_clf, max(scores)))'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = { 'learning_rate': (0.05, 1.5),\n",
    "            'n_estimators': (50, 500),\n",
    "}\n",
    "\n",
    "\n",
    "def ada_opt(learning_rate, n_estimators):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators))\n",
    "    }\n",
    "    \n",
    "    ada = AdaBoostClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(ada, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_ada = BayesianOptimization(f = ada_opt, pbounds = pbounds, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | n_esti... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 0.8458  \u001b[0m | \u001b[0m 371.8   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.924   \u001b[0m | \u001b[0m 295.2   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7587  \u001b[0m | \u001b[95m 0.6643  \u001b[0m | \u001b[95m 340.7   \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 0.6845  \u001b[0m | \u001b[0m 451.3   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7557  \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 222.5   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 1.198   \u001b[0m | \u001b[0m 288.0   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 0.8737  \u001b[0m | \u001b[0m 466.5   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7591  \u001b[0m | \u001b[95m 0.153   \u001b[0m | \u001b[95m 89.21   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.7607  \u001b[0m | \u001b[95m 0.07932 \u001b[0m | \u001b[95m 424.7   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 1.178   \u001b[0m | \u001b[0m 441.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7543  \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 409.6   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7581  \u001b[0m | \u001b[0m 0.7191  \u001b[0m | \u001b[0m 401.2   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 338.0   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7601  \u001b[0m | \u001b[0m 0.2579  \u001b[0m | \u001b[0m 475.1   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7588  \u001b[0m | \u001b[0m 0.8067  \u001b[0m | \u001b[0m 236.6   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 0.4336  \u001b[0m | \u001b[0m 398.4   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 305.8   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 0.07725 \u001b[0m | \u001b[0m 327.9   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7573  \u001b[0m | \u001b[0m 0.9375  \u001b[0m | \u001b[0m 327.6   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7558  \u001b[0m | \u001b[0m 1.418   \u001b[0m | \u001b[0m 356.8   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.5713  \u001b[0m | \u001b[0m 246.7   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 1.062   \u001b[0m | \u001b[0m 77.1    \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7576  \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 351.8   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.3551  \u001b[0m | \u001b[0m 108.0   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.76    \u001b[0m | \u001b[0m 0.5074  \u001b[0m | \u001b[0m 213.7   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 247.4   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7565  \u001b[0m | \u001b[0m 1.483   \u001b[0m | \u001b[0m 95.92   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7607  \u001b[0m | \u001b[0m 0.3529  \u001b[0m | \u001b[0m 122.6   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7588  \u001b[0m | \u001b[0m 0.997   \u001b[0m | \u001b[0m 164.0   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7598  \u001b[0m | \u001b[0m 0.7262  \u001b[0m | \u001b[0m 160.0   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7607  \u001b[0m | \u001b[0m 0.2805  \u001b[0m | \u001b[0m 99.67   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.759   \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 112.2   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.335   \u001b[0m | \u001b[0m 215.9   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7581  \u001b[0m | \u001b[0m 1.24    \u001b[0m | \u001b[0m 93.7    \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 1.265   \u001b[0m | \u001b[0m 93.24   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7561  \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 260.9   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7556  \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 322.2   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.759   \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 67.63   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.4601  \u001b[0m | \u001b[0m 104.1   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.4794  \u001b[0m | \u001b[0m 103.4   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7598  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 236.4   \u001b[0m |\n",
      "| \u001b[95m 42      \u001b[0m | \u001b[95m 0.7608  \u001b[0m | \u001b[95m 0.143   \u001b[0m | \u001b[95m 361.6   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7587  \u001b[0m | \u001b[0m 0.8716  \u001b[0m | \u001b[0m 169.4   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.8087  \u001b[0m | \u001b[0m 92.27   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 0.8851  \u001b[0m | \u001b[0m 468.2   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 0.5119  \u001b[0m | \u001b[0m 350.3   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 0.2411  \u001b[0m | \u001b[0m 372.3   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.4696  \u001b[0m | \u001b[0m 132.4   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 59.05   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7581  \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 52.11   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7586  \u001b[0m | \u001b[0m 0.659   \u001b[0m | \u001b[0m 362.1   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.07427 \u001b[0m | \u001b[0m 361.0   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 0.2191  \u001b[0m | \u001b[0m 215.0   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7575  \u001b[0m | \u001b[0m 1.229   \u001b[0m | \u001b[0m 215.3   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 0.7415  \u001b[0m | \u001b[0m 424.3   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7576  \u001b[0m | \u001b[0m 1.02    \u001b[0m | \u001b[0m 288.8   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7593  \u001b[0m | \u001b[0m 0.9026  \u001b[0m | \u001b[0m 122.2   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.1683  \u001b[0m | \u001b[0m 416.4   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.7575  \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 477.6   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7574  \u001b[0m | \u001b[0m 0.07535 \u001b[0m | \u001b[0m 123.2   \u001b[0m |\n",
      "| \u001b[95m 61      \u001b[0m | \u001b[95m 0.7608  \u001b[0m | \u001b[95m 0.1921  \u001b[0m | \u001b[95m 215.5   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 0.1847  \u001b[0m | \u001b[0m 300.9   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.7556  \u001b[0m | \u001b[0m 0.05946 \u001b[0m | \u001b[0m 122.0   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7599  \u001b[0m | \u001b[0m 0.3394  \u001b[0m | \u001b[0m 361.2   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7574  \u001b[0m | \u001b[0m 0.921   \u001b[0m | \u001b[0m 370.9   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.07449 \u001b[0m | \u001b[0m 397.7   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 0.6249  \u001b[0m | \u001b[0m 122.8   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7607  \u001b[0m | \u001b[0m 0.291   \u001b[0m | \u001b[0m 216.0   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7535  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 103.8   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.8122  \u001b[0m | \u001b[0m 414.2   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 0.4149  \u001b[0m | \u001b[0m 215.3   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.6627  \u001b[0m | \u001b[0m 177.0   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7595  \u001b[0m | \u001b[0m 0.8051  \u001b[0m | \u001b[0m 153.6   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7583  \u001b[0m | \u001b[0m 0.9166  \u001b[0m | \u001b[0m 222.1   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7541  \u001b[0m | \u001b[0m 1.485   \u001b[0m | \u001b[0m 470.6   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.1319  \u001b[0m | \u001b[0m 234.9   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7599  \u001b[0m | \u001b[0m 0.7951  \u001b[0m | \u001b[0m 103.4   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7569  \u001b[0m | \u001b[0m 0.9306  \u001b[0m | \u001b[0m 452.0   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.759   \u001b[0m | \u001b[0m 0.8423  \u001b[0m | \u001b[0m 192.4   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.1985  \u001b[0m | \u001b[0m 155.7   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.759   \u001b[0m | \u001b[0m 0.5456  \u001b[0m | \u001b[0m 379.5   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 0.8346  \u001b[0m | \u001b[0m 104.1   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.5779  \u001b[0m | \u001b[0m 104.5   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7586  \u001b[0m | \u001b[0m 1.151   \u001b[0m | \u001b[0m 62.71   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7584  \u001b[0m | \u001b[0m 1.208   \u001b[0m | \u001b[0m 57.1    \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7603  \u001b[0m | \u001b[0m 0.3294  \u001b[0m | \u001b[0m 301.2   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7595  \u001b[0m | \u001b[0m 0.5824  \u001b[0m | \u001b[0m 300.8   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.6269  \u001b[0m | \u001b[0m 99.83   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7606  \u001b[0m | \u001b[0m 0.1612  \u001b[0m | \u001b[0m 425.1   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7602  \u001b[0m | \u001b[0m 0.6856  \u001b[0m | \u001b[0m 99.27   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.1954  \u001b[0m | \u001b[0m 442.3   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7607  \u001b[0m | \u001b[0m 0.3206  \u001b[0m | \u001b[0m 100.2   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7595  \u001b[0m | \u001b[0m 0.5112  \u001b[0m | \u001b[0m 309.7   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7602  \u001b[0m | \u001b[0m 0.74    \u001b[0m | \u001b[0m 64.87   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.757   \u001b[0m | \u001b[0m 0.9667  \u001b[0m | \u001b[0m 444.9   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7598  \u001b[0m | \u001b[0m 0.6423  \u001b[0m | \u001b[0m 155.5   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7607  \u001b[0m | \u001b[0m 0.2982  \u001b[0m | \u001b[0m 214.5   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 0.646   \u001b[0m | \u001b[0m 214.2   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7605  \u001b[0m | \u001b[0m 0.1228  \u001b[0m | \u001b[0m 216.5   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7595  \u001b[0m | \u001b[0m 0.07367 \u001b[0m | \u001b[0m 214.0   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "BO_ada.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.192114100473329, 'n_estimators': 216}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_ada.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76034834 0.75942227 0.75634583 0.76710281]\n",
      "최대성능: 0.7671028143356372\n",
      "평균성능: 0.7608048133088864\n"
     ]
    }
   ],
   "source": [
    "ada_clf = AdaBoostClassifier(**max_params)\n",
    "\n",
    "scores = cross_val_score(ada_clf, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')\n",
    "\n",
    "BO_tuned_clfs.append((ada_clf.__class__.__name__, ada_clf, max(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stacking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimators = [(i[0], i[1]) for i in BO_tuned_clfs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting vecstack\n",
      "  Downloading vecstack-0.4.0.tar.gz (18 kB)\n",
      "Requirement already satisfied: numpy in d:\\anaconda\\lib\\site-packages (from vecstack) (1.19.1)\n",
      "Requirement already satisfied: scipy in d:\\anaconda\\lib\\site-packages (from vecstack) (1.5.2)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in d:\\anaconda\\lib\\site-packages (from vecstack) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.11 in d:\\anaconda\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (0.16.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\anaconda\\lib\\site-packages (from scikit-learn>=0.18->vecstack) (2.1.0)\n",
      "Building wheels for collected packages: vecstack\n",
      "  Building wheel for vecstack (setup.py): started\n",
      "  Building wheel for vecstack (setup.py): finished with status 'done'\n",
      "  Created wheel for vecstack: filename=vecstack-0.4.0-py3-none-any.whl size=19884 sha256=d00236b2e3ee78bd5e257e8696029db5f062005f6321f280951fda43c07ddbd9\n",
      "  Stored in directory: c:\\users\\administrator\\appdata\\local\\pip\\cache\\wheels\\28\\fe\\0c\\fe8e43660e3316d7ce204e59a79a72246c0ae9b6c5c79841c8\n",
      "Successfully built vecstack\n",
      "Installing collected packages: vecstack\n",
      "Successfully installed vecstack-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install vecstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:46:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:46:13] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[03:46:14] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from vecstack import StackingTransformer\n",
    "stack = StackingTransformer(estimators, regression=False, needs_proba=True, metric=None,\n",
    "                            n_folds=3, stratified=True, shuffle=True, random_state=0)\n",
    "stack = stack.fit(X_train, y_train)\n",
    "\n",
    "# Get your stacked features\n",
    "S_train = stack.transform(X_train)\n",
    "S_valid = stack.transform(X_valid)\n",
    "S_test = stack.transform(test_x_sel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for final ensemble\n",
    "df2_s_train = S_train.copy()\n",
    "df2_s_valid = S_valid.copy()\n",
    "df2_s_test =  S_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## meta model optimizing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta-lgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = { 'learning_rate': (0.01, 1.5),\n",
    "            'n_estimators': (50, 500),\n",
    "            'max_depth': (3,10),   \n",
    "            'subsample': (0.8,0.95), \n",
    "            'colsample_bytree': (0.75,0.9),   \n",
    "            'num_leaves': (2,10),\n",
    "            'min_child_weight': (1, 7)}\n",
    "\n",
    "\n",
    "def meta_opt(learning_rate, n_estimators, max_depth, subsample, colsample_bytree, num_leaves, min_child_weight):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth' : int(round(max_depth)),\n",
    "        'subsample': subsample,\n",
    "        'colsample_bytree' : colsample_bytree,\n",
    "        'num_leaves' : int(round(num_leaves)),\n",
    "        'min_child_weight' : min_child_weight,\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "    \n",
    "    meta_model = LGBMClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=True, random_state=1)\n",
    "\n",
    "    score = cross_val_score(meta_model, S_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_meta = BayesianOptimization(f = meta_opt, pbounds = pbounds, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsam... | learni... | max_depth | min_ch... | n_esti... | num_le... | subsample |\n",
      "-------------------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 0.8126  \u001b[0m | \u001b[0m 1.083   \u001b[0m | \u001b[0m 3.001   \u001b[0m | \u001b[0m 2.814   \u001b[0m | \u001b[0m 116.0   \u001b[0m | \u001b[0m 2.739   \u001b[0m | \u001b[0m 0.8279  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7467  \u001b[0m | \u001b[0m 0.8018  \u001b[0m | \u001b[0m 0.6012  \u001b[0m | \u001b[0m 6.772   \u001b[0m | \u001b[0m 3.515   \u001b[0m | \u001b[0m 358.3   \u001b[0m | \u001b[0m 3.636   \u001b[0m | \u001b[0m 0.9317  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.748   \u001b[0m | \u001b[0m 0.7541  \u001b[0m | \u001b[0m 1.009   \u001b[0m | \u001b[0m 5.921   \u001b[0m | \u001b[0m 4.352   \u001b[0m | \u001b[0m 113.2   \u001b[0m | \u001b[0m 3.585   \u001b[0m | \u001b[0m 0.9201  \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7558  \u001b[0m | \u001b[95m 0.8952  \u001b[0m | \u001b[95m 0.477   \u001b[0m | \u001b[95m 7.846   \u001b[0m | \u001b[95m 6.258   \u001b[0m | \u001b[95m 452.6   \u001b[0m | \u001b[95m 2.68    \u001b[0m | \u001b[95m 0.8059  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.699   \u001b[0m | \u001b[0m 0.7755  \u001b[0m | \u001b[0m 1.318   \u001b[0m | \u001b[0m 3.688   \u001b[0m | \u001b[0m 3.527   \u001b[0m | \u001b[0m 481.1   \u001b[0m | \u001b[0m 6.265   \u001b[0m | \u001b[0m 0.9038  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7016  \u001b[0m | \u001b[0m 0.7973  \u001b[0m | \u001b[0m 1.033   \u001b[0m | \u001b[0m 8.842   \u001b[0m | \u001b[0m 1.11    \u001b[0m | \u001b[0m 387.6   \u001b[0m | \u001b[0m 9.911   \u001b[0m | \u001b[0m 0.9122  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7221  \u001b[0m | \u001b[0m 0.7921  \u001b[0m | \u001b[0m 1.186   \u001b[0m | \u001b[0m 3.723   \u001b[0m | \u001b[0m 3.687   \u001b[0m | \u001b[0m 458.9   \u001b[0m | \u001b[0m 4.349   \u001b[0m | \u001b[0m 0.8432  \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7658  \u001b[0m | \u001b[95m 0.7695  \u001b[0m | \u001b[95m 0.03886 \u001b[0m | \u001b[95m 7.752   \u001b[0m | \u001b[95m 2.27    \u001b[0m | \u001b[95m 169.5   \u001b[0m | \u001b[95m 5.933   \u001b[0m | \u001b[95m 0.808   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.8361  \u001b[0m | \u001b[0m 0.2286  \u001b[0m | \u001b[0m 7.125   \u001b[0m | \u001b[0m 5.199   \u001b[0m | \u001b[0m 96.05   \u001b[0m | \u001b[0m 5.312   \u001b[0m | \u001b[0m 0.9042  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 0.8121  \u001b[0m | \u001b[0m 0.08443 \u001b[0m | \u001b[0m 6.751   \u001b[0m | \u001b[0m 4.983   \u001b[0m | \u001b[0m 281.7   \u001b[0m | \u001b[0m 9.557   \u001b[0m | \u001b[0m 0.888   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7634  \u001b[0m | \u001b[0m 0.8855  \u001b[0m | \u001b[0m 0.2148  \u001b[0m | \u001b[0m 3.975   \u001b[0m | \u001b[0m 5.844   \u001b[0m | \u001b[0m 229.0   \u001b[0m | \u001b[0m 3.323   \u001b[0m | \u001b[0m 0.9391  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7068  \u001b[0m | \u001b[0m 0.8022  \u001b[0m | \u001b[0m 1.129   \u001b[0m | \u001b[0m 8.082   \u001b[0m | \u001b[0m 6.3     \u001b[0m | \u001b[0m 330.7   \u001b[0m | \u001b[0m 8.008   \u001b[0m | \u001b[0m 0.8523  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7026  \u001b[0m | \u001b[0m 0.7905  \u001b[0m | \u001b[0m 1.345   \u001b[0m | \u001b[0m 5.997   \u001b[0m | \u001b[0m 6.789   \u001b[0m | \u001b[0m 348.5   \u001b[0m | \u001b[0m 6.974   \u001b[0m | \u001b[0m 0.8172  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7354  \u001b[0m | \u001b[0m 0.8924  \u001b[0m | \u001b[0m 0.6804  \u001b[0m | \u001b[0m 7.049   \u001b[0m | \u001b[0m 3.449   \u001b[0m | \u001b[0m 156.7   \u001b[0m | \u001b[0m 9.227   \u001b[0m | \u001b[0m 0.8861  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7194  \u001b[0m | \u001b[0m 0.7504  \u001b[0m | \u001b[0m 0.9295  \u001b[0m | \u001b[0m 5.287   \u001b[0m | \u001b[0m 4.162   \u001b[0m | \u001b[0m 448.7   \u001b[0m | \u001b[0m 4.858   \u001b[0m | \u001b[0m 0.9363  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.8435  \u001b[0m | \u001b[0m 0.03357 \u001b[0m | \u001b[0m 9.506   \u001b[0m | \u001b[0m 5.145   \u001b[0m | \u001b[0m 498.8   \u001b[0m | \u001b[0m 3.379   \u001b[0m | \u001b[0m 0.8206  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7136  \u001b[0m | \u001b[0m 0.8899  \u001b[0m | \u001b[0m 1.048   \u001b[0m | \u001b[0m 3.462   \u001b[0m | \u001b[0m 5.533   \u001b[0m | \u001b[0m 389.2   \u001b[0m | \u001b[0m 9.384   \u001b[0m | \u001b[0m 0.9067  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.7686  \u001b[0m | \u001b[0m 0.03962 \u001b[0m | \u001b[0m 3.183   \u001b[0m | \u001b[0m 1.17    \u001b[0m | \u001b[0m 160.8   \u001b[0m | \u001b[0m 8.88    \u001b[0m | \u001b[0m 0.8808  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 0.8329  \u001b[0m | \u001b[0m 1.265   \u001b[0m | \u001b[0m 3.869   \u001b[0m | \u001b[0m 2.675   \u001b[0m | \u001b[0m 313.6   \u001b[0m | \u001b[0m 9.757   \u001b[0m | \u001b[0m 0.8842  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7102  \u001b[0m | \u001b[0m 0.7528  \u001b[0m | \u001b[0m 1.203   \u001b[0m | \u001b[0m 4.631   \u001b[0m | \u001b[0m 5.843   \u001b[0m | \u001b[0m 224.5   \u001b[0m | \u001b[0m 8.908   \u001b[0m | \u001b[0m 0.9121  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7653  \u001b[0m | \u001b[0m 0.8334  \u001b[0m | \u001b[0m 0.2133  \u001b[0m | \u001b[0m 3.419   \u001b[0m | \u001b[0m 1.728   \u001b[0m | \u001b[0m 70.05   \u001b[0m | \u001b[0m 2.86    \u001b[0m | \u001b[0m 0.8339  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7172  \u001b[0m | \u001b[0m 0.8569  \u001b[0m | \u001b[0m 0.844   \u001b[0m | \u001b[0m 3.088   \u001b[0m | \u001b[0m 1.432   \u001b[0m | \u001b[0m 485.3   \u001b[0m | \u001b[0m 6.545   \u001b[0m | \u001b[0m 0.8305  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6982  \u001b[0m | \u001b[0m 0.7878  \u001b[0m | \u001b[0m 1.118   \u001b[0m | \u001b[0m 4.368   \u001b[0m | \u001b[0m 4.488   \u001b[0m | \u001b[0m 486.5   \u001b[0m | \u001b[0m 8.775   \u001b[0m | \u001b[0m 0.836   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7591  \u001b[0m | \u001b[0m 0.8241  \u001b[0m | \u001b[0m 0.9337  \u001b[0m | \u001b[0m 8.803   \u001b[0m | \u001b[0m 1.941   \u001b[0m | \u001b[0m 58.36   \u001b[0m | \u001b[0m 2.56    \u001b[0m | \u001b[0m 0.873   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7315  \u001b[0m | \u001b[0m 0.8409  \u001b[0m | \u001b[0m 0.8576  \u001b[0m | \u001b[0m 5.222   \u001b[0m | \u001b[0m 6.932   \u001b[0m | \u001b[0m 310.9   \u001b[0m | \u001b[0m 5.041   \u001b[0m | \u001b[0m 0.8826  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7182  \u001b[0m | \u001b[0m 0.8618  \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 4.854   \u001b[0m | \u001b[0m 1.398   \u001b[0m | \u001b[0m 216.5   \u001b[0m | \u001b[0m 7.038   \u001b[0m | \u001b[0m 0.8315  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 0.8629  \u001b[0m | \u001b[0m 0.1091  \u001b[0m | \u001b[0m 4.822   \u001b[0m | \u001b[0m 5.829   \u001b[0m | \u001b[0m 137.0   \u001b[0m | \u001b[0m 7.116   \u001b[0m | \u001b[0m 0.8787  \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7451  \u001b[0m | \u001b[0m 0.8887  \u001b[0m | \u001b[0m 0.4023  \u001b[0m | \u001b[0m 3.462   \u001b[0m | \u001b[0m 5.41    \u001b[0m | \u001b[0m 397.5   \u001b[0m | \u001b[0m 9.263   \u001b[0m | \u001b[0m 0.9398  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7445  \u001b[0m | \u001b[0m 0.7521  \u001b[0m | \u001b[0m 0.3592  \u001b[0m | \u001b[0m 7.317   \u001b[0m | \u001b[0m 6.694   \u001b[0m | \u001b[0m 477.6   \u001b[0m | \u001b[0m 6.453   \u001b[0m | \u001b[0m 0.9373  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7315  \u001b[0m | \u001b[0m 0.8462  \u001b[0m | \u001b[0m 0.5911  \u001b[0m | \u001b[0m 6.402   \u001b[0m | \u001b[0m 4.626   \u001b[0m | \u001b[0m 297.3   \u001b[0m | \u001b[0m 9.409   \u001b[0m | \u001b[0m 0.9378  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7275  \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 1.445   \u001b[0m | \u001b[0m 4.218   \u001b[0m | \u001b[0m 1.758   \u001b[0m | \u001b[0m 110.8   \u001b[0m | \u001b[0m 6.045   \u001b[0m | \u001b[0m 0.8032  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7461  \u001b[0m | \u001b[0m 0.8922  \u001b[0m | \u001b[0m 1.242   \u001b[0m | \u001b[0m 3.105   \u001b[0m | \u001b[0m 2.057   \u001b[0m | \u001b[0m 199.4   \u001b[0m | \u001b[0m 3.048   \u001b[0m | \u001b[0m 0.9214  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6887  \u001b[0m | \u001b[0m 0.8017  \u001b[0m | \u001b[0m 1.411   \u001b[0m | \u001b[0m 7.074   \u001b[0m | \u001b[0m 6.273   \u001b[0m | \u001b[0m 430.1   \u001b[0m | \u001b[0m 9.243   \u001b[0m | \u001b[0m 0.869   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7622  \u001b[0m | \u001b[0m 0.832   \u001b[0m | \u001b[0m 1.2     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 3.942   \u001b[0m | \u001b[0m 319.6   \u001b[0m | \u001b[0m 2.124   \u001b[0m | \u001b[0m 0.889   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7427  \u001b[0m | \u001b[0m 0.8151  \u001b[0m | \u001b[0m 1.213   \u001b[0m | \u001b[0m 5.207   \u001b[0m | \u001b[0m 6.357   \u001b[0m | \u001b[0m 310.0   \u001b[0m | \u001b[0m 3.472   \u001b[0m | \u001b[0m 0.9182  \u001b[0m |\n",
      "| \u001b[95m 36      \u001b[0m | \u001b[95m 0.7659  \u001b[0m | \u001b[95m 0.8418  \u001b[0m | \u001b[95m 0.09032 \u001b[0m | \u001b[95m 5.941   \u001b[0m | \u001b[95m 5.074   \u001b[0m | \u001b[95m 463.4   \u001b[0m | \u001b[95m 2.003   \u001b[0m | \u001b[95m 0.9465  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6971  \u001b[0m | \u001b[0m 0.8065  \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 7.233   \u001b[0m | \u001b[0m 5.973   \u001b[0m | \u001b[0m 308.6   \u001b[0m | \u001b[0m 7.025   \u001b[0m | \u001b[0m 0.8428  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7039  \u001b[0m | \u001b[0m 0.838   \u001b[0m | \u001b[0m 1.128   \u001b[0m | \u001b[0m 9.008   \u001b[0m | \u001b[0m 5.53    \u001b[0m | \u001b[0m 364.1   \u001b[0m | \u001b[0m 8.916   \u001b[0m | \u001b[0m 0.8484  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7431  \u001b[0m | \u001b[0m 0.8506  \u001b[0m | \u001b[0m 0.6818  \u001b[0m | \u001b[0m 5.675   \u001b[0m | \u001b[0m 3.465   \u001b[0m | \u001b[0m 230.7   \u001b[0m | \u001b[0m 4.539   \u001b[0m | \u001b[0m 0.8933  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7172  \u001b[0m | \u001b[0m 0.8145  \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 7.745   \u001b[0m | \u001b[0m 2.191   \u001b[0m | \u001b[0m 242.0   \u001b[0m | \u001b[0m 4.747   \u001b[0m | \u001b[0m 0.9196  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7083  \u001b[0m | \u001b[0m 0.882   \u001b[0m | \u001b[0m 1.357   \u001b[0m | \u001b[0m 7.639   \u001b[0m | \u001b[0m 2.621   \u001b[0m | \u001b[0m 163.6   \u001b[0m | \u001b[0m 8.839   \u001b[0m | \u001b[0m 0.8792  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7163  \u001b[0m | \u001b[0m 0.8703  \u001b[0m | \u001b[0m 0.863   \u001b[0m | \u001b[0m 8.132   \u001b[0m | \u001b[0m 4.114   \u001b[0m | \u001b[0m 396.9   \u001b[0m | \u001b[0m 6.551   \u001b[0m | \u001b[0m 0.8699  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.8014  \u001b[0m | \u001b[0m 0.1116  \u001b[0m | \u001b[0m 5.645   \u001b[0m | \u001b[0m 1.478   \u001b[0m | \u001b[0m 492.3   \u001b[0m | \u001b[0m 3.453   \u001b[0m | \u001b[0m 0.9218  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7272  \u001b[0m | \u001b[0m 0.8812  \u001b[0m | \u001b[0m 1.036   \u001b[0m | \u001b[0m 6.986   \u001b[0m | \u001b[0m 1.966   \u001b[0m | \u001b[0m 260.1   \u001b[0m | \u001b[0m 4.761   \u001b[0m | \u001b[0m 0.8338  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7604  \u001b[0m | \u001b[0m 0.8389  \u001b[0m | \u001b[0m 0.4753  \u001b[0m | \u001b[0m 9.414   \u001b[0m | \u001b[0m 6.458   \u001b[0m | \u001b[0m 165.7   \u001b[0m | \u001b[0m 2.887   \u001b[0m | \u001b[0m 0.8289  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7162  \u001b[0m | \u001b[0m 0.8249  \u001b[0m | \u001b[0m 1.096   \u001b[0m | \u001b[0m 4.457   \u001b[0m | \u001b[0m 2.488   \u001b[0m | \u001b[0m 433.3   \u001b[0m | \u001b[0m 5.327   \u001b[0m | \u001b[0m 0.8925  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 0.785   \u001b[0m | \u001b[0m 0.1619  \u001b[0m | \u001b[0m 6.611   \u001b[0m | \u001b[0m 3.863   \u001b[0m | \u001b[0m 118.7   \u001b[0m | \u001b[0m 6.974   \u001b[0m | \u001b[0m 0.8816  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7541  \u001b[0m | \u001b[0m 0.8481  \u001b[0m | \u001b[0m 0.2254  \u001b[0m | \u001b[0m 8.261   \u001b[0m | \u001b[0m 2.332   \u001b[0m | \u001b[0m 283.7   \u001b[0m | \u001b[0m 8.282   \u001b[0m | \u001b[0m 0.8033  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.6911  \u001b[0m | \u001b[0m 0.7987  \u001b[0m | \u001b[0m 1.311   \u001b[0m | \u001b[0m 8.913   \u001b[0m | \u001b[0m 4.231   \u001b[0m | \u001b[0m 440.0   \u001b[0m | \u001b[0m 9.598   \u001b[0m | \u001b[0m 0.924   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.8781  \u001b[0m | \u001b[0m 0.1571  \u001b[0m | \u001b[0m 7.559   \u001b[0m | \u001b[0m 5.221   \u001b[0m | \u001b[0m 324.6   \u001b[0m | \u001b[0m 8.397   \u001b[0m | \u001b[0m 0.8052  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7528  \u001b[0m | \u001b[0m 0.7743  \u001b[0m | \u001b[0m 0.5704  \u001b[0m | \u001b[0m 7.896   \u001b[0m | \u001b[0m 2.865   \u001b[0m | \u001b[0m 495.9   \u001b[0m | \u001b[0m 2.668   \u001b[0m | \u001b[0m 0.8072  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 8.355   \u001b[0m | \u001b[0m 4.548   \u001b[0m | \u001b[0m 170.1   \u001b[0m | \u001b[0m 2.402   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 0.8293  \u001b[0m | \u001b[0m 0.5212  \u001b[0m | \u001b[0m 5.661   \u001b[0m | \u001b[0m 1.838   \u001b[0m | \u001b[0m 65.17   \u001b[0m | \u001b[0m 2.758   \u001b[0m | \u001b[0m 0.8517  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.8841  \u001b[0m | \u001b[0m 0.6739  \u001b[0m | \u001b[0m 9.643   \u001b[0m | \u001b[0m 6.153   \u001b[0m | \u001b[0m 465.7   \u001b[0m | \u001b[0m 2.405   \u001b[0m | \u001b[0m 0.9186  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 0.8989  \u001b[0m | \u001b[0m 0.2903  \u001b[0m | \u001b[0m 4.817   \u001b[0m | \u001b[0m 6.497   \u001b[0m | \u001b[0m 467.9   \u001b[0m | \u001b[0m 2.241   \u001b[0m | \u001b[0m 0.8318  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.8876  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 7.202   \u001b[0m | \u001b[0m 1.423   \u001b[0m | \u001b[0m 467.5   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 7.462   \u001b[0m | \u001b[0m 4.457   \u001b[0m | \u001b[0m 468.2   \u001b[0m | \u001b[0m 7.275   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7425  \u001b[0m | \u001b[0m 0.8454  \u001b[0m | \u001b[0m 0.9991  \u001b[0m | \u001b[0m 3.012   \u001b[0m | \u001b[0m 1.485   \u001b[0m | \u001b[0m 170.8   \u001b[0m | \u001b[0m 3.948   \u001b[0m | \u001b[0m 0.932   \u001b[0m |\n",
      "| \u001b[95m 59      \u001b[0m | \u001b[95m 0.7659  \u001b[0m | \u001b[95m 0.75    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 3.306   \u001b[0m | \u001b[95m 174.4   \u001b[0m | \u001b[95m 7.222   \u001b[0m | \u001b[95m 0.8     \u001b[0m |\n",
      "| \u001b[95m 60      \u001b[0m | \u001b[95m 0.766   \u001b[0m | \u001b[95m 0.75    \u001b[0m | \u001b[95m 0.01    \u001b[0m | \u001b[95m 10.0    \u001b[0m | \u001b[95m 5.054   \u001b[0m | \u001b[95m 472.0   \u001b[0m | \u001b[95m 2.983   \u001b[0m | \u001b[95m 0.95    \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 0.7681  \u001b[0m | \u001b[0m 0.205   \u001b[0m | \u001b[0m 4.5     \u001b[0m | \u001b[0m 4.104   \u001b[0m | \u001b[0m 128.2   \u001b[0m | \u001b[0m 6.652   \u001b[0m | \u001b[0m 0.9279  \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 0.806   \u001b[0m | \u001b[0m 0.4785  \u001b[0m | \u001b[0m 6.656   \u001b[0m | \u001b[0m 6.826   \u001b[0m | \u001b[0m 122.5   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.7463  \u001b[0m | \u001b[0m 0.7775  \u001b[0m | \u001b[0m 1.089   \u001b[0m | \u001b[0m 9.867   \u001b[0m | \u001b[0m 1.287   \u001b[0m | \u001b[0m 124.4   \u001b[0m | \u001b[0m 4.232   \u001b[0m | \u001b[0m 0.9106  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7256  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 122.3   \u001b[0m | \u001b[0m 7.487   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7555  \u001b[0m | \u001b[0m 0.8894  \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 6.163   \u001b[0m | \u001b[0m 6.563   \u001b[0m | \u001b[0m 132.1   \u001b[0m | \u001b[0m 2.058   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 6.631   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 133.7   \u001b[0m | \u001b[0m 8.672   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 9.11    \u001b[0m | \u001b[0m 6.86    \u001b[0m | \u001b[0m 132.6   \u001b[0m | \u001b[0m 9.849   \u001b[0m | \u001b[0m 0.9405  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 158.8   \u001b[0m | \u001b[0m 2.632   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7511  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 117.9   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7643  \u001b[0m | \u001b[0m 0.8988  \u001b[0m | \u001b[0m 0.1787  \u001b[0m | \u001b[0m 3.594   \u001b[0m | \u001b[0m 4.849   \u001b[0m | \u001b[0m 67.6    \u001b[0m | \u001b[0m 8.804   \u001b[0m | \u001b[0m 0.9499  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7316  \u001b[0m | \u001b[0m 0.8692  \u001b[0m | \u001b[0m 1.306   \u001b[0m | \u001b[0m 9.047   \u001b[0m | \u001b[0m 2.417   \u001b[0m | \u001b[0m 70.03   \u001b[0m | \u001b[0m 6.735   \u001b[0m | \u001b[0m 0.8259  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 62.45   \u001b[0m | \u001b[0m 4.399   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 0.8875  \u001b[0m | \u001b[0m 0.03309 \u001b[0m | \u001b[0m 3.244   \u001b[0m | \u001b[0m 3.481   \u001b[0m | \u001b[0m 60.08   \u001b[0m | \u001b[0m 9.86    \u001b[0m | \u001b[0m 0.8512  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7265  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 8.824   \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 59.3    \u001b[0m | \u001b[0m 9.116   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.666   \u001b[0m | \u001b[0m 3.091   \u001b[0m | \u001b[0m 1.941   \u001b[0m | \u001b[0m 55.35   \u001b[0m | \u001b[0m 3.362   \u001b[0m | \u001b[0m 0.8624  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7508  \u001b[0m | \u001b[0m 0.8434  \u001b[0m | \u001b[0m 0.4188  \u001b[0m | \u001b[0m 9.591   \u001b[0m | \u001b[0m 1.956   \u001b[0m | \u001b[0m 141.4   \u001b[0m | \u001b[0m 9.006   \u001b[0m | \u001b[0m 0.8371  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 0.8304  \u001b[0m | \u001b[0m 0.1157  \u001b[0m | \u001b[0m 3.198   \u001b[0m | \u001b[0m 1.056   \u001b[0m | \u001b[0m 63.18   \u001b[0m | \u001b[0m 6.91    \u001b[0m | \u001b[0m 0.8236  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 4.327   \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 7.079   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.6869  \u001b[0m | \u001b[0m 0.7713  \u001b[0m | \u001b[0m 1.253   \u001b[0m | \u001b[0m 9.15    \u001b[0m | \u001b[0m 1.996   \u001b[0m | \u001b[0m 499.5   \u001b[0m | \u001b[0m 9.762   \u001b[0m | \u001b[0m 0.9131  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.734   \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 500.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7591  \u001b[0m | \u001b[0m 0.8555  \u001b[0m | \u001b[0m 0.8128  \u001b[0m | \u001b[0m 6.403   \u001b[0m | \u001b[0m 6.158   \u001b[0m | \u001b[0m 89.42   \u001b[0m | \u001b[0m 2.817   \u001b[0m | \u001b[0m 0.932   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7414  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 68.98   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7363  \u001b[0m | \u001b[0m 0.8959  \u001b[0m | \u001b[0m 0.9161  \u001b[0m | \u001b[0m 3.63    \u001b[0m | \u001b[0m 1.463   \u001b[0m | \u001b[0m 91.25   \u001b[0m | \u001b[0m 9.599   \u001b[0m | \u001b[0m 0.8599  \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7475  \u001b[0m | \u001b[0m 0.8123  \u001b[0m | \u001b[0m 1.49    \u001b[0m | \u001b[0m 9.948   \u001b[0m | \u001b[0m 1.241   \u001b[0m | \u001b[0m 93.52   \u001b[0m | \u001b[0m 3.389   \u001b[0m | \u001b[0m 0.8007  \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 494.0   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 52.52   \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 136.5   \u001b[0m | \u001b[0m 2.659   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.8675  \u001b[0m | \u001b[0m 0.305   \u001b[0m | \u001b[0m 3.41    \u001b[0m | \u001b[0m 3.766   \u001b[0m | \u001b[0m 145.1   \u001b[0m | \u001b[0m 2.351   \u001b[0m | \u001b[0m 0.8368  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7618  \u001b[0m | \u001b[0m 0.885   \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 8.67    \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 141.2   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 8.405   \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 50.0    \u001b[0m | \u001b[0m 4.693   \u001b[0m | \u001b[0m 0.9419  \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7619  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 136.7   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7618  \u001b[0m | \u001b[0m 0.8863  \u001b[0m | \u001b[0m 0.593   \u001b[0m | \u001b[0m 4.439   \u001b[0m | \u001b[0m 6.878   \u001b[0m | \u001b[0m 50.4    \u001b[0m | \u001b[0m 3.768   \u001b[0m | \u001b[0m 0.9091  \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.7726  \u001b[0m | \u001b[0m 0.06639 \u001b[0m | \u001b[0m 3.038   \u001b[0m | \u001b[0m 6.128   \u001b[0m | \u001b[0m 152.3   \u001b[0m | \u001b[0m 3.519   \u001b[0m | \u001b[0m 0.8284  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.765   \u001b[0m | \u001b[0m 0.7866  \u001b[0m | \u001b[0m 0.3691  \u001b[0m | \u001b[0m 8.902   \u001b[0m | \u001b[0m 1.488   \u001b[0m | \u001b[0m 148.7   \u001b[0m | \u001b[0m 2.11    \u001b[0m | \u001b[0m 0.8864  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7392  \u001b[0m | \u001b[0m 0.7765  \u001b[0m | \u001b[0m 0.7693  \u001b[0m | \u001b[0m 3.204   \u001b[0m | \u001b[0m 1.492   \u001b[0m | \u001b[0m 151.8   \u001b[0m | \u001b[0m 7.744   \u001b[0m | \u001b[0m 0.9092  \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 279.1   \u001b[0m | \u001b[0m 2.903   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7198  \u001b[0m | \u001b[0m 0.8871  \u001b[0m | \u001b[0m 0.9403  \u001b[0m | \u001b[0m 3.713   \u001b[0m | \u001b[0m 1.634   \u001b[0m | \u001b[0m 275.7   \u001b[0m | \u001b[0m 7.281   \u001b[0m | \u001b[0m 0.8144  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7608  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 159.6   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.7716  \u001b[0m | \u001b[0m 0.1808  \u001b[0m | \u001b[0m 3.209   \u001b[0m | \u001b[0m 5.81    \u001b[0m | \u001b[0m 285.8   \u001b[0m | \u001b[0m 3.295   \u001b[0m | \u001b[0m 0.9172  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7588  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.01    \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 7.0     \u001b[0m | \u001b[0m 150.3   \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "=============================================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_meta.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample_bytree': 0.75,\n",
       " 'learning_rate': 0.01,\n",
       " 'max_depth': 10,\n",
       " 'min_child_weight': 5.053612401427161,\n",
       " 'n_estimators': 472,\n",
       " 'num_leaves': 3,\n",
       " 'subsample': 0.95}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_meta.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75866854 0.75013918 0.75855817 0.76274653]\n",
      "최대성능: 0.762746528391972\n",
      "평균성능: 0.7575281045528965\n"
     ]
    }
   ],
   "source": [
    "meta_clf = LGBMClassifier(**max_params)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=4 , shuffle=True, random_state=1)\n",
    "\n",
    "scores = cross_val_score(meta_clf, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LGBMClassifier(colsample_bytree=0.75, learning_rate=0.01, max_depth=10,\n",
       "               min_child_weight=5.053612401427161, n_estimators=472,\n",
       "               num_leaves=3, subsample=0.95)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_clf.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LR-meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 범위\n",
    "\n",
    "pbounds = { 'C': (0.1,1),}\n",
    "\n",
    "\n",
    "def logreg_meta(C):\n",
    "    \n",
    "    params = {\n",
    "        'C' : C\n",
    "    }\n",
    "\n",
    "    logreg = LogisticRegression(**params, n_jobs=-1, random_state=50)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "    \n",
    "    score = cross_val_score(logreg, S_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "\n",
    "BO_logreg = BayesianOptimization(f = logreg_meta, pbounds = pbounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |     C     |\n",
      "-------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.5939  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7437  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6425  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.5904  \u001b[0m |\n",
      "| \u001b[95m 5       \u001b[0m | \u001b[95m 0.7662  \u001b[0m | \u001b[95m 0.4813  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6813  \u001b[0m |\n",
      "| \u001b[95m 7       \u001b[0m | \u001b[95m 0.7662  \u001b[0m | \u001b[95m 0.4938  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.9026  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.9673  \u001b[0m |\n",
      "| \u001b[95m 10      \u001b[0m | \u001b[95m 0.7662  \u001b[0m | \u001b[95m 0.4451  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.8126  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.576   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6112  \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.933   \u001b[0m |\n",
      "| \u001b[95m 15      \u001b[0m | \u001b[95m 0.7663  \u001b[0m | \u001b[95m 0.1639  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1784  \u001b[0m |\n",
      "| \u001b[95m 17      \u001b[0m | \u001b[95m 0.7663  \u001b[0m | \u001b[95m 0.1182  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.8494  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.8003  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.883   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.9808  \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.8192  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.5153  \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.8025  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.2064  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6759  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.229   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.9502  \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.5697  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.4732  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.3381  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7968  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.5105  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6116  \u001b[0m |\n",
      "| \u001b[95m 35      \u001b[0m | \u001b[95m 0.7663  \u001b[0m | \u001b[95m 0.1169  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6559  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6509  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6552  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.9494  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7136  \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.4236  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.4933  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7279  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1542  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7001  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7036  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.2893  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.216   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.3839  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.4273  \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.4273  \u001b[0m |\n",
      "| \u001b[95m 52      \u001b[0m | \u001b[95m 0.7663  \u001b[0m | \u001b[95m 0.103   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1354  \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1075  \u001b[0m |\n",
      "| \u001b[95m 55      \u001b[0m | \u001b[95m 0.7663  \u001b[0m | \u001b[95m 0.1002  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.2583  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1001  \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1002  \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1175  \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1035  \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.108   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1069  \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1062  \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1055  \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1046  \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1089  \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1097  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1106  \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1271  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1439  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1712  \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1878  \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1966  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.24    \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.3134  \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.5422  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.2721  \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.3594  \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7704  \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1489  \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.4034  \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 1.0     \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.123   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.326   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1114  \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.8662  \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.3011  \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.2489  \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.6272  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.459   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.3715  \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.834   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.9178  \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.3484  \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.556   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.2225  \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.5285  \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 0.1313  \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.7838  \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 0.757   \u001b[0m |\n",
      "=====================================\n"
     ]
    }
   ],
   "source": [
    "BO_logreg.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 0.1001800856967334}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_logreg.max['params']\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76079727 0.7596338  0.75603896 0.76846618]\n",
      "최대성능: 0.7684661796729919\n",
      "평균성능: 0.7612340509296085\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "logreg_meta = LogisticRegression(**max_params,  n_jobs=-1, random_state=50)\n",
    "\n",
    "scores = cross_val_score(logreg_meta, X_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1001800856967334, n_jobs=-1, random_state=50)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_meta.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### xgb-meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 범위\n",
    "\n",
    "pbounds = { 'learning_rate': (0.05, 1.5),\n",
    "            'n_estimators': (50, 100),\n",
    "            'max_depth': (5,15),   \n",
    "            'subsample': (0.8,0.95),  \n",
    "            'colsample': (0.75,0.95),   \n",
    "            'gamma': (0, 5)}\n",
    "\n",
    "def xgb_meta(learning_rate, n_estimators, max_depth, subsample, colsample, gamma):\n",
    "    \n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators)),\n",
    "        'max_depth' : int(round(max_depth)),\n",
    "        'subsample': subsample,\n",
    "        'colsample': colsample,   \n",
    "        'gamma': gamma,\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "    \n",
    "    xgb = XGBClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(xgb, S_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_xgb = BayesianOptimization(f = xgb_meta, pbounds = pbounds, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | colsample |   gamma   | learni... | max_depth | n_esti... | subsample |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6969  \u001b[0m | \u001b[0m 0.8598  \u001b[0m | \u001b[0m 3.576   \u001b[0m | \u001b[0m 0.924   \u001b[0m | \u001b[0m 10.45   \u001b[0m | \u001b[0m 71.18   \u001b[0m | \u001b[0m 0.8969  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6762  \u001b[0m | \u001b[0m 0.8375  \u001b[0m | \u001b[0m 4.459   \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 8.834   \u001b[0m | \u001b[0m 89.59   \u001b[0m | \u001b[0m 0.8793  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7622  \u001b[0m | \u001b[95m 0.8636  \u001b[0m | \u001b[95m 4.628   \u001b[0m | \u001b[95m 0.153   \u001b[0m | \u001b[95m 5.871   \u001b[0m | \u001b[95m 51.01   \u001b[0m | \u001b[95m 0.9249  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.6773  \u001b[0m | \u001b[0m 0.9056  \u001b[0m | \u001b[0m 4.35    \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 12.99   \u001b[0m | \u001b[0m 73.07   \u001b[0m | \u001b[0m 0.9171  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7351  \u001b[0m | \u001b[0m 0.7737  \u001b[0m | \u001b[0m 3.2     \u001b[0m | \u001b[0m 0.2579  \u001b[0m | \u001b[0m 14.45   \u001b[0m | \u001b[0m 76.09   \u001b[0m | \u001b[0m 0.8622  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7144  \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 3.871   \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 10.68   \u001b[0m | \u001b[0m 50.94   \u001b[0m | \u001b[0m 0.8926  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6746  \u001b[0m | \u001b[0m 0.8724  \u001b[0m | \u001b[0m 3.085   \u001b[0m | \u001b[0m 1.418   \u001b[0m | \u001b[0m 11.82   \u001b[0m | \u001b[0m 67.98   \u001b[0m | \u001b[0m 0.8656  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.694   \u001b[0m | \u001b[0m 0.8895  \u001b[0m | \u001b[0m 0.3011  \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 11.71   \u001b[0m | \u001b[0m 60.52   \u001b[0m | \u001b[0m 0.8193  \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.6949  \u001b[0m | \u001b[0m 0.8131  \u001b[0m | \u001b[0m 1.819   \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 9.386   \u001b[0m | \u001b[0m 99.42   \u001b[0m | \u001b[0m 0.8153  \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.693   \u001b[0m | \u001b[0m 0.7918  \u001b[0m | \u001b[0m 0.8065  \u001b[0m | \u001b[0m 0.997   \u001b[0m | \u001b[0m 7.533   \u001b[0m | \u001b[0m 73.32   \u001b[0m | \u001b[0m 0.8367  \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7083  \u001b[0m | \u001b[0m 0.7818  \u001b[0m | \u001b[0m 0.5519  \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 6.382   \u001b[0m | \u001b[0m 59.83   \u001b[0m | \u001b[0m 0.8553  \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.6906  \u001b[0m | \u001b[0m 0.9142  \u001b[0m | \u001b[0m 0.4855  \u001b[0m | \u001b[0m 1.265   \u001b[0m | \u001b[0m 5.961   \u001b[0m | \u001b[0m 98.82   \u001b[0m | \u001b[0m 0.8703  \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7082  \u001b[0m | \u001b[0m 0.9454  \u001b[0m | \u001b[0m 3.024   \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 5.392   \u001b[0m | \u001b[0m 64.14   \u001b[0m | \u001b[0m 0.818   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7259  \u001b[0m | \u001b[0m 0.8092  \u001b[0m | \u001b[0m 0.5936  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 9.143   \u001b[0m | \u001b[0m 53.21   \u001b[0m | \u001b[0m 0.9039  \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7154  \u001b[0m | \u001b[0m 0.8633  \u001b[0m | \u001b[0m 1.327   \u001b[0m | \u001b[0m 0.8087  \u001b[0m | \u001b[0m 5.939   \u001b[0m | \u001b[0m 78.8    \u001b[0m | \u001b[0m 0.9394  \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7399  \u001b[0m | \u001b[0m 0.8137  \u001b[0m | \u001b[0m 3.337   \u001b[0m | \u001b[0m 0.2411  \u001b[0m | \u001b[0m 12.16   \u001b[0m | \u001b[0m 64.47   \u001b[0m | \u001b[0m 0.8275  \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.6975  \u001b[0m | \u001b[0m 0.8673  \u001b[0m | \u001b[0m 0.1005  \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 5.047   \u001b[0m | \u001b[0m 83.89   \u001b[0m | \u001b[0m 0.8405  \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7353  \u001b[0m | \u001b[0m 0.897   \u001b[0m | \u001b[0m 4.811   \u001b[0m | \u001b[0m 0.4107  \u001b[0m | \u001b[0m 10.76   \u001b[0m | \u001b[0m 79.6    \u001b[0m | \u001b[0m 0.8858  \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7079  \u001b[0m | \u001b[0m 0.7946  \u001b[0m | \u001b[0m 4.764   \u001b[0m | \u001b[0m 0.6983  \u001b[0m | \u001b[0m 13.46   \u001b[0m | \u001b[0m 84.97   \u001b[0m | \u001b[0m 0.8446  \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.6815  \u001b[0m | \u001b[0m 0.9128  \u001b[0m | \u001b[0m 1.983   \u001b[0m | \u001b[0m 1.328   \u001b[0m | \u001b[0m 10.81   \u001b[0m | \u001b[0m 94.09   \u001b[0m | \u001b[0m 0.9039  \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.6767  \u001b[0m | \u001b[0m 0.8951  \u001b[0m | \u001b[0m 2.507   \u001b[0m | \u001b[0m 1.436   \u001b[0m | \u001b[0m 11.44   \u001b[0m | \u001b[0m 71.19   \u001b[0m | \u001b[0m 0.891   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.6949  \u001b[0m | \u001b[0m 0.7538  \u001b[0m | \u001b[0m 1.508   \u001b[0m | \u001b[0m 1.007   \u001b[0m | \u001b[0m 7.901   \u001b[0m | \u001b[0m 80.9    \u001b[0m | \u001b[0m 0.8643  \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.6997  \u001b[0m | \u001b[0m 0.7771  \u001b[0m | \u001b[0m 1.491   \u001b[0m | \u001b[0m 0.8764  \u001b[0m | \u001b[0m 10.91   \u001b[0m | \u001b[0m 78.72   \u001b[0m | \u001b[0m 0.898   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.6835  \u001b[0m | \u001b[0m 0.8804  \u001b[0m | \u001b[0m 2.157   \u001b[0m | \u001b[0m 1.35    \u001b[0m | \u001b[0m 8.676   \u001b[0m | \u001b[0m 71.79   \u001b[0m | \u001b[0m 0.9338  \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7419  \u001b[0m | \u001b[0m 0.9112  \u001b[0m | \u001b[0m 3.519   \u001b[0m | \u001b[0m 0.1953  \u001b[0m | \u001b[0m 14.19   \u001b[0m | \u001b[0m 85.71   \u001b[0m | \u001b[0m 0.9498  \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.746   \u001b[0m | \u001b[0m 0.7799  \u001b[0m | \u001b[0m 4.341   \u001b[0m | \u001b[0m 0.2856  \u001b[0m | \u001b[0m 11.16   \u001b[0m | \u001b[0m 56.19   \u001b[0m | \u001b[0m 0.9272  \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7259  \u001b[0m | \u001b[0m 0.9115  \u001b[0m | \u001b[0m 2.846   \u001b[0m | \u001b[0m 0.6404  \u001b[0m | \u001b[0m 5.692   \u001b[0m | \u001b[0m 84.87   \u001b[0m | \u001b[0m 0.868   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.6713  \u001b[0m | \u001b[0m 0.8944  \u001b[0m | \u001b[0m 4.332   \u001b[0m | \u001b[0m 1.465   \u001b[0m | \u001b[0m 13.56   \u001b[0m | \u001b[0m 50.59   \u001b[0m | \u001b[0m 0.854   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7164  \u001b[0m | \u001b[0m 0.896   \u001b[0m | \u001b[0m 0.8581  \u001b[0m | \u001b[0m 0.8055  \u001b[0m | \u001b[0m 5.543   \u001b[0m | \u001b[0m 60.0    \u001b[0m | \u001b[0m 0.8028  \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7097  \u001b[0m | \u001b[0m 0.9087  \u001b[0m | \u001b[0m 1.12    \u001b[0m | \u001b[0m 0.5508  \u001b[0m | \u001b[0m 14.28   \u001b[0m | \u001b[0m 85.22   \u001b[0m | \u001b[0m 0.8048  \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.705   \u001b[0m | \u001b[0m 0.7829  \u001b[0m | \u001b[0m 3.107   \u001b[0m | \u001b[0m 0.887   \u001b[0m | \u001b[0m 7.379   \u001b[0m | \u001b[0m 96.71   \u001b[0m | \u001b[0m 0.8921  \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.6902  \u001b[0m | \u001b[0m 0.8571  \u001b[0m | \u001b[0m 2.95    \u001b[0m | \u001b[0m 1.109   \u001b[0m | \u001b[0m 8.119   \u001b[0m | \u001b[0m 69.91   \u001b[0m | \u001b[0m 0.8315  \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.6963  \u001b[0m | \u001b[0m 0.7872  \u001b[0m | \u001b[0m 4.722   \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 9.905   \u001b[0m | \u001b[0m 61.37   \u001b[0m | \u001b[0m 0.8382  \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7138  \u001b[0m | \u001b[0m 0.7616  \u001b[0m | \u001b[0m 2.172   \u001b[0m | \u001b[0m 0.5021  \u001b[0m | \u001b[0m 11.96   \u001b[0m | \u001b[0m 68.89   \u001b[0m | \u001b[0m 0.8269  \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.699   \u001b[0m | \u001b[0m 0.7549  \u001b[0m | \u001b[0m 0.3362  \u001b[0m | \u001b[0m 1.035   \u001b[0m | \u001b[0m 9.537   \u001b[0m | \u001b[0m 76.83   \u001b[0m | \u001b[0m 0.9345  \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7031  \u001b[0m | \u001b[0m 0.9481  \u001b[0m | \u001b[0m 1.084   \u001b[0m | \u001b[0m 1.011   \u001b[0m | \u001b[0m 7.633   \u001b[0m | \u001b[0m 51.03   \u001b[0m | \u001b[0m 0.9138  \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.6974  \u001b[0m | \u001b[0m 0.814   \u001b[0m | \u001b[0m 1.917   \u001b[0m | \u001b[0m 0.9031  \u001b[0m | \u001b[0m 13.31   \u001b[0m | \u001b[0m 81.45   \u001b[0m | \u001b[0m 0.9309  \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7302  \u001b[0m | \u001b[0m 0.8047  \u001b[0m | \u001b[0m 3.99    \u001b[0m | \u001b[0m 0.3192  \u001b[0m | \u001b[0m 14.53   \u001b[0m | \u001b[0m 84.37   \u001b[0m | \u001b[0m 0.8323  \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7392  \u001b[0m | \u001b[0m 0.9395  \u001b[0m | \u001b[0m 3.654   \u001b[0m | \u001b[0m 0.4182  \u001b[0m | \u001b[0m 7.133   \u001b[0m | \u001b[0m 75.91   \u001b[0m | \u001b[0m 0.8038  \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7172  \u001b[0m | \u001b[0m 0.7915  \u001b[0m | \u001b[0m 2.123   \u001b[0m | \u001b[0m 0.5925  \u001b[0m | \u001b[0m 9.636   \u001b[0m | \u001b[0m 63.88   \u001b[0m | \u001b[0m 0.888   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7127  \u001b[0m | \u001b[0m 0.9228  \u001b[0m | \u001b[0m 0.5877  \u001b[0m | \u001b[0m 0.8002  \u001b[0m | \u001b[0m 6.321   \u001b[0m | \u001b[0m 85.84   \u001b[0m | \u001b[0m 0.8594  \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7441  \u001b[0m | \u001b[0m 0.8631  \u001b[0m | \u001b[0m 0.9164  \u001b[0m | \u001b[0m 0.26    \u001b[0m | \u001b[0m 9.881   \u001b[0m | \u001b[0m 67.78   \u001b[0m | \u001b[0m 0.9411  \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.6905  \u001b[0m | \u001b[0m 0.9031  \u001b[0m | \u001b[0m 3.743   \u001b[0m | \u001b[0m 1.36    \u001b[0m | \u001b[0m 5.834   \u001b[0m | \u001b[0m 77.61   \u001b[0m | \u001b[0m 0.8877  \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7455  \u001b[0m | \u001b[0m 0.9424  \u001b[0m | \u001b[0m 1.461   \u001b[0m | \u001b[0m 0.3992  \u001b[0m | \u001b[0m 6.003   \u001b[0m | \u001b[0m 50.82   \u001b[0m | \u001b[0m 0.9394  \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7337  \u001b[0m | \u001b[0m 0.884   \u001b[0m | \u001b[0m 3.926   \u001b[0m | \u001b[0m 0.4585  \u001b[0m | \u001b[0m 10.86   \u001b[0m | \u001b[0m 53.2    \u001b[0m | \u001b[0m 0.8728  \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7257  \u001b[0m | \u001b[0m 0.9455  \u001b[0m | \u001b[0m 4.383   \u001b[0m | \u001b[0m 0.5403  \u001b[0m | \u001b[0m 14.62   \u001b[0m | \u001b[0m 61.59   \u001b[0m | \u001b[0m 0.9424  \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7001  \u001b[0m | \u001b[0m 0.9383  \u001b[0m | \u001b[0m 3.996   \u001b[0m | \u001b[0m 0.9641  \u001b[0m | \u001b[0m 13.74   \u001b[0m | \u001b[0m 64.65   \u001b[0m | \u001b[0m 0.9273  \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7242  \u001b[0m | \u001b[0m 0.8736  \u001b[0m | \u001b[0m 0.06618 \u001b[0m | \u001b[0m 0.5535  \u001b[0m | \u001b[0m 6.481   \u001b[0m | \u001b[0m 99.09   \u001b[0m | \u001b[0m 0.8718  \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7276  \u001b[0m | \u001b[0m 0.8495  \u001b[0m | \u001b[0m 3.197   \u001b[0m | \u001b[0m 0.5844  \u001b[0m | \u001b[0m 6.369   \u001b[0m | \u001b[0m 91.11   \u001b[0m | \u001b[0m 0.8285  \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7381  \u001b[0m | \u001b[0m 0.8523  \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 0.1919  \u001b[0m | \u001b[0m 13.62   \u001b[0m | \u001b[0m 98.65   \u001b[0m | \u001b[0m 0.9441  \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7464  \u001b[0m | \u001b[0m 0.8231  \u001b[0m | \u001b[0m 4.215   \u001b[0m | \u001b[0m 0.5793  \u001b[0m | \u001b[0m 5.481   \u001b[0m | \u001b[0m 51.19   \u001b[0m | \u001b[0m 0.9097  \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7621  \u001b[0m | \u001b[0m 0.9157  \u001b[0m | \u001b[0m 4.034   \u001b[0m | \u001b[0m 0.1095  \u001b[0m | \u001b[0m 6.35    \u001b[0m | \u001b[0m 51.55   \u001b[0m | \u001b[0m 0.8345  \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.747   \u001b[0m | \u001b[0m 0.8699  \u001b[0m | \u001b[0m 4.907   \u001b[0m | \u001b[0m 0.4851  \u001b[0m | \u001b[0m 6.685   \u001b[0m | \u001b[0m 51.36   \u001b[0m | \u001b[0m 0.9486  \u001b[0m |\n",
      "| \u001b[95m 54      \u001b[0m | \u001b[95m 0.7635  \u001b[0m | \u001b[95m 0.7654  \u001b[0m | \u001b[95m 3.741   \u001b[0m | \u001b[95m 0.06911 \u001b[0m | \u001b[95m 6.371   \u001b[0m | \u001b[95m 50.41   \u001b[0m | \u001b[95m 0.9374  \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7571  \u001b[0m | \u001b[0m 0.932   \u001b[0m | \u001b[0m 2.569   \u001b[0m | \u001b[0m 0.2318  \u001b[0m | \u001b[0m 5.73    \u001b[0m | \u001b[0m 50.17   \u001b[0m | \u001b[0m 0.8894  \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7594  \u001b[0m | \u001b[0m 0.8649  \u001b[0m | \u001b[0m 2.173   \u001b[0m | \u001b[0m 0.2203  \u001b[0m | \u001b[0m 5.053   \u001b[0m | \u001b[0m 51.6    \u001b[0m | \u001b[0m 0.8928  \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7617  \u001b[0m | \u001b[0m 0.889   \u001b[0m | \u001b[0m 2.452   \u001b[0m | \u001b[0m 0.1301  \u001b[0m | \u001b[0m 6.219   \u001b[0m | \u001b[0m 52.93   \u001b[0m | \u001b[0m 0.9292  \u001b[0m |\n",
      "| \u001b[95m 58      \u001b[0m | \u001b[95m 0.7646  \u001b[0m | \u001b[95m 0.95    \u001b[0m | \u001b[95m 3.258   \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 53.4    \u001b[0m | \u001b[95m 0.8     \u001b[0m |\n",
      "| \u001b[95m 59      \u001b[0m | \u001b[95m 0.7646  \u001b[0m | \u001b[95m 0.95    \u001b[0m | \u001b[95m 1.533   \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 53.87   \u001b[0m | \u001b[95m 0.8     \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 2.833   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 6.081   \u001b[0m | \u001b[0m 55.1    \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 4.199   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 7.988   \u001b[0m | \u001b[0m 54.76   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.802   \u001b[0m | \u001b[0m 55.04   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.6911  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 4.66    \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 7.028   \u001b[0m | \u001b[0m 56.31   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 4.451   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 6.543   \u001b[0m | \u001b[0m 53.71   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 2.466   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 9.227   \u001b[0m | \u001b[0m 55.23   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7552  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 11.87   \u001b[0m | \u001b[0m 66.22   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7601  \u001b[0m | \u001b[0m 0.7778  \u001b[0m | \u001b[0m 0.3767  \u001b[0m | \u001b[0m 0.2059  \u001b[0m | \u001b[0m 5.037   \u001b[0m | \u001b[0m 56.17   \u001b[0m | \u001b[0m 0.9213  \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7619  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 6.914   \u001b[0m | \u001b[0m 55.22   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7045  \u001b[0m | \u001b[0m 0.8007  \u001b[0m | \u001b[0m 0.5583  \u001b[0m | \u001b[0m 1.481   \u001b[0m | \u001b[0m 5.135   \u001b[0m | \u001b[0m 54.62   \u001b[0m | \u001b[0m 0.9452  \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7596  \u001b[0m | \u001b[0m 0.8783  \u001b[0m | \u001b[0m 1.077   \u001b[0m | \u001b[0m 0.07096 \u001b[0m | \u001b[0m 7.764   \u001b[0m | \u001b[0m 56.56   \u001b[0m | \u001b[0m 0.9421  \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7485  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 14.67   \u001b[0m | \u001b[0m 67.48   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7541  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 4.517   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7092  \u001b[0m | \u001b[0m 0.771   \u001b[0m | \u001b[0m 4.429   \u001b[0m | \u001b[0m 0.6788  \u001b[0m | \u001b[0m 14.67   \u001b[0m | \u001b[0m 97.2    \u001b[0m | \u001b[0m 0.9032  \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 10.02   \u001b[0m | \u001b[0m 56.04   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7517  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.341   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 12.68   \u001b[0m | \u001b[0m 55.64   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7369  \u001b[0m | \u001b[0m 0.8407  \u001b[0m | \u001b[0m 4.573   \u001b[0m | \u001b[0m 0.2884  \u001b[0m | \u001b[0m 14.61   \u001b[0m | \u001b[0m 57.48   \u001b[0m | \u001b[0m 0.8105  \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.6885  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 55.81   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7528  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 3.798   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 88.66   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7481  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 14.71   \u001b[0m | \u001b[0m 64.51   \u001b[0m | \u001b[0m 0.947   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7485  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.7981  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 89.85   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7643  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 91.41   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7573  \u001b[0m | \u001b[0m 0.7974  \u001b[0m | \u001b[0m 0.4745  \u001b[0m | \u001b[0m 0.1616  \u001b[0m | \u001b[0m 5.528   \u001b[0m | \u001b[0m 93.85   \u001b[0m | \u001b[0m 0.9003  \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.6941  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 92.4    \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7643  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 89.38   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 6.904   \u001b[0m | \u001b[0m 90.51   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7643  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.537   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 90.23   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.6784  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 2.166   \u001b[0m | \u001b[0m 1.5     \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 7.34    \u001b[0m | \u001b[0m 93.1    \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7239  \u001b[0m | \u001b[0m 0.9417  \u001b[0m | \u001b[0m 3.509   \u001b[0m | \u001b[0m 0.4831  \u001b[0m | \u001b[0m 14.96   \u001b[0m | \u001b[0m 91.17   \u001b[0m | \u001b[0m 0.9393  \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 2.219   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 56.92   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7528  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 12.01   \u001b[0m | \u001b[0m 89.16   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7549  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 78.69   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.752   \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 2.143   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 13.24   \u001b[0m | \u001b[0m 88.38   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 6.992   \u001b[0m | \u001b[0m 95.33   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7598  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 9.587   \u001b[0m | \u001b[0m 76.2    \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7577  \u001b[0m | \u001b[0m 0.75    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 12.41   \u001b[0m | \u001b[0m 77.32   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7571  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 12.64   \u001b[0m | \u001b[0m 100.0   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7475  \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 0.0     \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 15.0    \u001b[0m | \u001b[0m 95.51   \u001b[0m | \u001b[0m 0.95    \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.764   \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 3.206   \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 93.84   \u001b[0m | \u001b[0m 0.8     \u001b[0m |\n",
      "| \u001b[95m 100     \u001b[0m | \u001b[95m 0.7647  \u001b[0m | \u001b[95m 0.75    \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 5.0     \u001b[0m | \u001b[95m 73.3    \u001b[0m | \u001b[95m 0.8     \u001b[0m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_xgb.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'colsample': 0.75,\n",
       " 'gamma': 5.0,\n",
       " 'learning_rate': 0.05,\n",
       " 'max_depth': 5,\n",
       " 'n_estimators': 73,\n",
       " 'subsample': 0.8}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_xgb.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.76749333 0.76453254 0.76000423 0.77208142]\n",
      "최대성능: 0.7720814177626609\n",
      "평균성능: 0.7660278770393196\n"
     ]
    }
   ],
   "source": [
    "xgb_meta = XGBClassifier(**max_params)\n",
    "\n",
    "scores = cross_val_score(xgb_meta, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:56:16] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample=0.75,\n",
       "              colsample_bylevel=1, colsample_bynode=1, colsample_bytree=1,\n",
       "              gamma=5.0, gpu_id=-1, importance_type='gain',\n",
       "              interaction_constraints='', learning_rate=0.05, max_delta_step=0,\n",
       "              max_depth=5, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=73, n_jobs=0,\n",
       "              num_parallel_tree=1, random_state=0, reg_alpha=0, reg_lambda=1,\n",
       "              scale_pos_weight=1, subsample=0.8, tree_method='exact',\n",
       "              validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_meta.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### extra-meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = { 'n_estimators': (50, 250),\n",
    "            'max_depth': (3,10),    \n",
    "            'max_features': (0.8,0.95),\n",
    "            'min_samples_split': (2, 5),\n",
    "            'min_samples_leaf': (1, 5)\n",
    "            }\n",
    "\n",
    "def extra_meta(n_estimators, max_depth, max_features, min_samples_split, min_samples_leaf):\n",
    "\n",
    "    params = {\n",
    "        'n_estimators': int(round(n_estimators)),\n",
    "        'max_depth': int(round(max_depth)),\n",
    "        'max_features' : max_features,\n",
    "        'min_samples_leaf': int(round(min_samples_leaf)),\n",
    "        'min_samples_split': int(round(min_samples_split)),\n",
    "        'n_jobs' : -1\n",
    "    }\n",
    "    \n",
    "    extra = ExtraTreesClassifier(bootstrap = True, oob_score=True, **params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(extra, S_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_extra = BayesianOptimization(f = extra_meta, pbounds = pbounds, random_state=0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | max_depth | max_fe... | min_sa... | min_sa... | n_esti... |\n",
      "-------------------------------------------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 6.842   \u001b[0m | \u001b[0m 0.9073  \u001b[0m | \u001b[0m 3.411   \u001b[0m | \u001b[0m 3.635   \u001b[0m | \u001b[0m 134.7   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 7.521   \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 4.567   \u001b[0m | \u001b[0m 4.891   \u001b[0m | \u001b[0m 126.7   \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 8.542   \u001b[0m | \u001b[0m 0.8793  \u001b[0m | \u001b[0m 3.272   \u001b[0m | \u001b[0m 4.777   \u001b[0m | \u001b[0m 64.21   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7662  \u001b[0m | \u001b[95m 3.61    \u001b[0m | \u001b[95m 0.803   \u001b[0m | \u001b[95m 4.33    \u001b[0m | \u001b[95m 4.334   \u001b[0m | \u001b[95m 224.0   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.764   \u001b[0m | \u001b[0m 9.85    \u001b[0m | \u001b[0m 0.9199  \u001b[0m | \u001b[0m 2.846   \u001b[0m | \u001b[0m 4.342   \u001b[0m | \u001b[0m 73.65   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 7.479   \u001b[0m | \u001b[0m 0.8215  \u001b[0m | \u001b[0m 4.779   \u001b[0m | \u001b[0m 3.566   \u001b[0m | \u001b[0m 132.9   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 4.852   \u001b[0m | \u001b[0m 0.9161  \u001b[0m | \u001b[0m 2.825   \u001b[0m | \u001b[0m 3.705   \u001b[0m | \u001b[0m 53.76   \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 7.323   \u001b[0m | \u001b[0m 0.8918  \u001b[0m | \u001b[0m 3.468   \u001b[0m | \u001b[0m 4.831   \u001b[0m | \u001b[0m 186.4   \u001b[0m |\n",
      "| \u001b[0m 9       \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 5.517   \u001b[0m | \u001b[0m 0.8656  \u001b[0m | \u001b[0m 3.791   \u001b[0m | \u001b[0m 2.181   \u001b[0m | \u001b[0m 183.4   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 7.694   \u001b[0m | \u001b[0m 0.8316  \u001b[0m | \u001b[0m 1.516   \u001b[0m | \u001b[0m 2.946   \u001b[0m | \u001b[0m 122.7   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 6.991   \u001b[0m | \u001b[0m 0.8658  \u001b[0m | \u001b[0m 4.953   \u001b[0m | \u001b[0m 2.306   \u001b[0m | \u001b[0m 91.78   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 4.129   \u001b[0m | \u001b[0m 0.898   \u001b[0m | \u001b[0m 2.013   \u001b[0m | \u001b[0m 3.399   \u001b[0m | \u001b[0m 98.89   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 4.113   \u001b[0m | \u001b[0m 0.8166  \u001b[0m | \u001b[0m 3.625   \u001b[0m | \u001b[0m 2.415   \u001b[0m | \u001b[0m 89.32   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 5.581   \u001b[0m | \u001b[0m 0.9231  \u001b[0m | \u001b[0m 1.388   \u001b[0m | \u001b[0m 4.514   \u001b[0m | \u001b[0m 69.22   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7644  \u001b[0m | \u001b[0m 9.835   \u001b[0m | \u001b[0m 0.8703  \u001b[0m | \u001b[0m 4.907   \u001b[0m | \u001b[0m 3.815   \u001b[0m | \u001b[0m 197.9   \u001b[0m |\n",
      "| \u001b[95m 16      \u001b[0m | \u001b[95m 0.7662  \u001b[0m | \u001b[95m 3.274   \u001b[0m | \u001b[95m 0.8424  \u001b[0m | \u001b[95m 1.481   \u001b[0m | \u001b[95m 2.888   \u001b[0m | \u001b[95m 73.75   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 5.226   \u001b[0m | \u001b[0m 0.8621  \u001b[0m | \u001b[0m 1.257   \u001b[0m | \u001b[0m 4.077   \u001b[0m | \u001b[0m 163.3   \u001b[0m |\n",
      "| \u001b[0m 18      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 4.858   \u001b[0m | \u001b[0m 0.8785  \u001b[0m | \u001b[0m 1.376   \u001b[0m | \u001b[0m 3.728   \u001b[0m | \u001b[0m 235.9   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 5.23    \u001b[0m | \u001b[0m 0.9001  \u001b[0m | \u001b[0m 1.527   \u001b[0m | \u001b[0m 4.149   \u001b[0m | \u001b[0m 107.9   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 4.282   \u001b[0m | \u001b[0m 0.888   \u001b[0m | \u001b[0m 1.08    \u001b[0m | \u001b[0m 4.487   \u001b[0m | \u001b[0m 50.94   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 7.745   \u001b[0m | \u001b[0m 0.8405  \u001b[0m | \u001b[0m 3.941   \u001b[0m | \u001b[0m 4.887   \u001b[0m | \u001b[0m 99.75   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 7.033   \u001b[0m | \u001b[0m 0.8888  \u001b[0m | \u001b[0m 3.289   \u001b[0m | \u001b[0m 2.669   \u001b[0m | \u001b[0m 240.5   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 6.13    \u001b[0m | \u001b[0m 0.927   \u001b[0m | \u001b[0m 3.798   \u001b[0m | \u001b[0m 2.892   \u001b[0m | \u001b[0m 212.8   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 5.776   \u001b[0m | \u001b[0m 0.9322  \u001b[0m | \u001b[0m 3.325   \u001b[0m | \u001b[0m 4.645   \u001b[0m | \u001b[0m 188.5   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 8.077   \u001b[0m | \u001b[0m 0.8752  \u001b[0m | \u001b[0m 4.824   \u001b[0m | \u001b[0m 3.932   \u001b[0m | \u001b[0m 134.8   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 7.245   \u001b[0m | \u001b[0m 0.8029  \u001b[0m | \u001b[0m 2.206   \u001b[0m | \u001b[0m 3.981   \u001b[0m | \u001b[0m 108.0   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 7.326   \u001b[0m | \u001b[0m 0.8643  \u001b[0m | \u001b[0m 1.542   \u001b[0m | \u001b[0m 2.895   \u001b[0m | \u001b[0m 164.0   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 7.136   \u001b[0m | \u001b[0m 0.8861  \u001b[0m | \u001b[0m 3.613   \u001b[0m | \u001b[0m 3.956   \u001b[0m | \u001b[0m 136.3   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 9.276   \u001b[0m | \u001b[0m 0.8551  \u001b[0m | \u001b[0m 2.743   \u001b[0m | \u001b[0m 4.676   \u001b[0m | \u001b[0m 211.2   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 7.927   \u001b[0m | \u001b[0m 0.815   \u001b[0m | \u001b[0m 4.678   \u001b[0m | \u001b[0m 4.143   \u001b[0m | \u001b[0m 249.8   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 4.046   \u001b[0m | \u001b[0m 0.9302  \u001b[0m | \u001b[0m 1.65    \u001b[0m | \u001b[0m 3.847   \u001b[0m | \u001b[0m 74.76   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7646  \u001b[0m | \u001b[0m 8.936   \u001b[0m | \u001b[0m 0.9211  \u001b[0m | \u001b[0m 3.276   \u001b[0m | \u001b[0m 3.222   \u001b[0m | \u001b[0m 63.83   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 7.882   \u001b[0m | \u001b[0m 0.868   \u001b[0m | \u001b[0m 3.888   \u001b[0m | \u001b[0m 4.599   \u001b[0m | \u001b[0m 245.1   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 8.991   \u001b[0m | \u001b[0m 0.8018  \u001b[0m | \u001b[0m 2.44    \u001b[0m | \u001b[0m 4.19    \u001b[0m | \u001b[0m 84.33   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 6.647   \u001b[0m | \u001b[0m 0.8082  \u001b[0m | \u001b[0m 1.8     \u001b[0m | \u001b[0m 2.056   \u001b[0m | \u001b[0m 208.7   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 4.567   \u001b[0m | \u001b[0m 0.8518  \u001b[0m | \u001b[0m 4.712   \u001b[0m | \u001b[0m 4.113   \u001b[0m | \u001b[0m 56.37   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 4.153   \u001b[0m | \u001b[0m 0.8932  \u001b[0m | \u001b[0m 3.309   \u001b[0m | \u001b[0m 2.714   \u001b[0m | \u001b[0m 236.8   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7658  \u001b[0m | \u001b[0m 7.298   \u001b[0m | \u001b[0m 0.8803  \u001b[0m | \u001b[0m 3.36    \u001b[0m | \u001b[0m 4.19    \u001b[0m | \u001b[0m 112.4   \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 5.788   \u001b[0m | \u001b[0m 0.8315  \u001b[0m | \u001b[0m 1.745   \u001b[0m | \u001b[0m 4.833   \u001b[0m | \u001b[0m 197.9   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7659  \u001b[0m | \u001b[0m 6.433   \u001b[0m | \u001b[0m 0.8341  \u001b[0m | \u001b[0m 2.017   \u001b[0m | \u001b[0m 2.174   \u001b[0m | \u001b[0m 136.9   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 5.183   \u001b[0m | \u001b[0m 0.9045  \u001b[0m | \u001b[0m 2.511   \u001b[0m | \u001b[0m 2.539   \u001b[0m | \u001b[0m 54.94   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.471   \u001b[0m | \u001b[0m 0.9019  \u001b[0m | \u001b[0m 2.815   \u001b[0m | \u001b[0m 3.61    \u001b[0m | \u001b[0m 229.3   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 9.932   \u001b[0m | \u001b[0m 0.8325  \u001b[0m | \u001b[0m 3.652   \u001b[0m | \u001b[0m 2.79    \u001b[0m | \u001b[0m 54.13   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 8.309   \u001b[0m | \u001b[0m 0.848   \u001b[0m | \u001b[0m 2.534   \u001b[0m | \u001b[0m 3.765   \u001b[0m | \u001b[0m 216.2   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 7.403   \u001b[0m | \u001b[0m 0.9309  \u001b[0m | \u001b[0m 2.094   \u001b[0m | \u001b[0m 4.394   \u001b[0m | \u001b[0m 87.13   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7645  \u001b[0m | \u001b[0m 9.67    \u001b[0m | \u001b[0m 0.9031  \u001b[0m | \u001b[0m 1.862   \u001b[0m | \u001b[0m 4.842   \u001b[0m | \u001b[0m 196.2   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 4.778   \u001b[0m | \u001b[0m 0.832   \u001b[0m | \u001b[0m 3.073   \u001b[0m | \u001b[0m 2.077   \u001b[0m | \u001b[0m 91.49   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 5.973   \u001b[0m | \u001b[0m 0.8561  \u001b[0m | \u001b[0m 2.854   \u001b[0m | \u001b[0m 2.833   \u001b[0m | \u001b[0m 167.4   \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 9.047   \u001b[0m | \u001b[0m 0.8176  \u001b[0m | \u001b[0m 3.07    \u001b[0m | \u001b[0m 2.396   \u001b[0m | \u001b[0m 193.4   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 5.772   \u001b[0m | \u001b[0m 0.8848  \u001b[0m | \u001b[0m 1.733   \u001b[0m | \u001b[0m 2.435   \u001b[0m | \u001b[0m 147.6   \u001b[0m |\n",
      "| \u001b[0m 51      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 202.0   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 9.664   \u001b[0m | \u001b[0m 0.81    \u001b[0m | \u001b[0m 4.943   \u001b[0m | \u001b[0m 2.341   \u001b[0m | \u001b[0m 229.4   \u001b[0m |\n",
      "| \u001b[95m 53      \u001b[0m | \u001b[95m 0.7664  \u001b[0m | \u001b[95m 3.0     \u001b[0m | \u001b[95m 0.8     \u001b[0m | \u001b[95m 1.0     \u001b[0m | \u001b[95m 2.0     \u001b[0m | \u001b[95m 196.8   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.9292  \u001b[0m | \u001b[0m 3.555   \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 155.8   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 162.0   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.285   \u001b[0m | \u001b[0m 0.9111  \u001b[0m | \u001b[0m 1.093   \u001b[0m | \u001b[0m 2.233   \u001b[0m | \u001b[0m 104.1   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.19    \u001b[0m | \u001b[0m 0.8508  \u001b[0m | \u001b[0m 1.324   \u001b[0m | \u001b[0m 4.633   \u001b[0m | \u001b[0m 174.3   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 4.723   \u001b[0m | \u001b[0m 57.51   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 7.24    \u001b[0m | \u001b[0m 0.9276  \u001b[0m | \u001b[0m 4.905   \u001b[0m | \u001b[0m 2.219   \u001b[0m | \u001b[0m 175.0   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 193.6   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7642  \u001b[0m | \u001b[0m 9.667   \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 153.6   \u001b[0m |\n",
      "| \u001b[0m 62      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.256   \u001b[0m | \u001b[0m 0.9156  \u001b[0m | \u001b[0m 2.594   \u001b[0m | \u001b[0m 4.775   \u001b[0m | \u001b[0m 143.3   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 112.4   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 219.8   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 10.0    \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 142.3   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.203   \u001b[0m | \u001b[0m 0.8904  \u001b[0m | \u001b[0m 4.838   \u001b[0m | \u001b[0m 3.502   \u001b[0m | \u001b[0m 148.4   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 139.4   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.169   \u001b[0m | \u001b[0m 0.8004  \u001b[0m | \u001b[0m 1.115   \u001b[0m | \u001b[0m 2.781   \u001b[0m | \u001b[0m 150.3   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 106.4   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 218.4   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 180.1   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8966  \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 205.9   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 190.0   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 224.5   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 197.6   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 187.0   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.766   \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 66.78   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 145.7   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 168.3   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 82.33   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 51.74   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 212.8   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 80.73   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 70.51   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 109.4   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.071   \u001b[0m | \u001b[0m 0.8526  \u001b[0m | \u001b[0m 1.201   \u001b[0m | \u001b[0m 3.887   \u001b[0m | \u001b[0m 240.8   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 159.2   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 86.16   \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 94.12   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 170.5   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 116.5   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 84.54   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7663  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 58.35   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 117.9   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.8     \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 177.9   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7661  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 70.68   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 76.8    \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 1.0     \u001b[0m | \u001b[0m 2.0     \u001b[0m | \u001b[0m 250.0   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 214.3   \u001b[0m |\n",
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7662  \u001b[0m | \u001b[0m 3.0     \u001b[0m | \u001b[0m 0.95    \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 5.0     \u001b[0m | \u001b[0m 185.2   \u001b[0m |\n",
      "=====================================================================================\n"
     ]
    }
   ],
   "source": [
    "BO_extra.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3,\n",
       " 'max_features': 0.8,\n",
       " 'min_samples_leaf': 1,\n",
       " 'min_samples_split': 2,\n",
       " 'n_estimators': 197}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_extra.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "max_params['max_depth'] = int(round(max_params['max_depth']))\n",
    "max_params['min_samples_leaf'] = int(round(max_params['min_samples_leaf']))\n",
    "max_params['min_samples_split'] = int(round(max_params['min_samples_split']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75496934 0.75109773 0.74859693 0.75864185]\n",
      "최대성능: 0.7586418453242003\n",
      "평균성능: 0.753326460467776\n"
     ]
    }
   ],
   "source": [
    "extra_meta = ExtraTreesClassifier(bootstrap = True, oob_score=True, **max_params)\n",
    "\n",
    "scores = cross_val_score(extra_meta, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ExtraTreesClassifier(bootstrap=True, max_depth=3, max_features=0.8,\n",
       "                     n_estimators=197, oob_score=True)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extra_meta.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### adaboost-meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "pbounds = { 'learning_rate': (0.05, 1.5),\n",
    "            'n_estimators': (50, 300),\n",
    "}\n",
    "\n",
    "\n",
    "def ada_meta(learning_rate, n_estimators):\n",
    "\n",
    "    params = {\n",
    "        'learning_rate': learning_rate,\n",
    "        'n_estimators' : int(round(n_estimators))\n",
    "    }\n",
    "    \n",
    "    ada = AdaBoostClassifier(**params)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=4 , shuffle=False, random_state=50)\n",
    "\n",
    "    score = cross_val_score(ada, S_train, y_train, scoring='roc_auc', cv=skf, n_jobs=-1)\n",
    "    \n",
    "    return np.mean(score)\n",
    "\n",
    "BO_ada = BayesianOptimization(f = ada_meta, pbounds = pbounds, random_state=0)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | learni... | n_esti... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 0.8458  \u001b[0m | \u001b[0m 228.8   \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.7628  \u001b[0m | \u001b[0m 0.924   \u001b[0m | \u001b[0m 186.2   \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.7631  \u001b[0m | \u001b[95m 0.6643  \u001b[0m | \u001b[95m 211.5   \u001b[0m |\n",
      "| \u001b[95m 4       \u001b[0m | \u001b[95m 0.7631  \u001b[0m | \u001b[95m 0.6845  \u001b[0m | \u001b[95m 272.9   \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 1.447   \u001b[0m | \u001b[0m 145.9   \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.7614  \u001b[0m | \u001b[0m 1.198   \u001b[0m | \u001b[0m 182.2   \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.7626  \u001b[0m | \u001b[0m 0.8737  \u001b[0m | \u001b[0m 281.4   \u001b[0m |\n",
      "| \u001b[95m 8       \u001b[0m | \u001b[95m 0.7655  \u001b[0m | \u001b[95m 0.153   \u001b[0m | \u001b[95m 71.78   \u001b[0m |\n",
      "| \u001b[95m 9       \u001b[0m | \u001b[95m 0.7655  \u001b[0m | \u001b[95m 0.07932 \u001b[0m | \u001b[95m 258.2   \u001b[0m |\n",
      "| \u001b[0m 10      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 1.178   \u001b[0m | \u001b[0m 267.5   \u001b[0m |\n",
      "| \u001b[0m 11      \u001b[0m | \u001b[0m 0.7597  \u001b[0m | \u001b[0m 1.469   \u001b[0m | \u001b[0m 249.8   \u001b[0m |\n",
      "| \u001b[0m 12      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 0.7191  \u001b[0m | \u001b[0m 245.1   \u001b[0m |\n",
      "| \u001b[0m 13      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 0.2215  \u001b[0m | \u001b[0m 210.0   \u001b[0m |\n",
      "| \u001b[0m 14      \u001b[0m | \u001b[0m 0.7647  \u001b[0m | \u001b[0m 0.2579  \u001b[0m | \u001b[0m 286.2   \u001b[0m |\n",
      "| \u001b[0m 15      \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.8067  \u001b[0m | \u001b[0m 153.7   \u001b[0m |\n",
      "| \u001b[0m 16      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.4336  \u001b[0m | \u001b[0m 243.6   \u001b[0m |\n",
      "| \u001b[0m 17      \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.7114  \u001b[0m | \u001b[0m 192.1   \u001b[0m |\n",
      "| \u001b[95m 18      \u001b[0m | \u001b[95m 0.7656  \u001b[0m | \u001b[95m 0.07725 \u001b[0m | \u001b[95m 204.4   \u001b[0m |\n",
      "| \u001b[0m 19      \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.9375  \u001b[0m | \u001b[0m 204.2   \u001b[0m |\n",
      "| \u001b[0m 20      \u001b[0m | \u001b[0m 0.7609  \u001b[0m | \u001b[0m 1.418   \u001b[0m | \u001b[0m 220.5   \u001b[0m |\n",
      "| \u001b[0m 21      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 0.5713  \u001b[0m | \u001b[0m 159.3   \u001b[0m |\n",
      "| \u001b[0m 22      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 1.062   \u001b[0m | \u001b[0m 65.06   \u001b[0m |\n",
      "| \u001b[0m 23      \u001b[0m | \u001b[0m 0.7619  \u001b[0m | \u001b[0m 1.017   \u001b[0m | \u001b[0m 217.7   \u001b[0m |\n",
      "| \u001b[0m 24      \u001b[0m | \u001b[0m 0.7634  \u001b[0m | \u001b[0m 0.3551  \u001b[0m | \u001b[0m 82.23   \u001b[0m |\n",
      "| \u001b[0m 25      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 0.5074  \u001b[0m | \u001b[0m 140.9   \u001b[0m |\n",
      "| \u001b[0m 26      \u001b[0m | \u001b[0m 0.7638  \u001b[0m | \u001b[0m 0.8768  \u001b[0m | \u001b[0m 159.7   \u001b[0m |\n",
      "| \u001b[0m 27      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 1.483   \u001b[0m | \u001b[0m 75.51   \u001b[0m |\n",
      "| \u001b[0m 28      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.3529  \u001b[0m | \u001b[0m 90.33   \u001b[0m |\n",
      "| \u001b[0m 29      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 0.997   \u001b[0m | \u001b[0m 113.3   \u001b[0m |\n",
      "| \u001b[0m 30      \u001b[0m | \u001b[0m 0.7629  \u001b[0m | \u001b[0m 0.7262  \u001b[0m | \u001b[0m 111.1   \u001b[0m |\n",
      "| \u001b[0m 31      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 0.2805  \u001b[0m | \u001b[0m 77.59   \u001b[0m |\n",
      "| \u001b[0m 32      \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 84.55   \u001b[0m |\n",
      "| \u001b[0m 33      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.335   \u001b[0m | \u001b[0m 142.2   \u001b[0m |\n",
      "| \u001b[0m 34      \u001b[0m | \u001b[0m 0.7616  \u001b[0m | \u001b[0m 1.24    \u001b[0m | \u001b[0m 74.28   \u001b[0m |\n",
      "| \u001b[0m 35      \u001b[0m | \u001b[0m 0.7613  \u001b[0m | \u001b[0m 1.265   \u001b[0m | \u001b[0m 74.02   \u001b[0m |\n",
      "| \u001b[0m 36      \u001b[0m | \u001b[0m 0.7599  \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 167.2   \u001b[0m |\n",
      "| \u001b[0m 37      \u001b[0m | \u001b[0m 0.7598  \u001b[0m | \u001b[0m 1.466   \u001b[0m | \u001b[0m 201.2   \u001b[0m |\n",
      "| \u001b[0m 38      \u001b[0m | \u001b[0m 0.7623  \u001b[0m | \u001b[0m 1.122   \u001b[0m | \u001b[0m 59.8    \u001b[0m |\n",
      "| \u001b[0m 39      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 0.4601  \u001b[0m | \u001b[0m 80.05   \u001b[0m |\n",
      "| \u001b[0m 40      \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.4794  \u001b[0m | \u001b[0m 79.68   \u001b[0m |\n",
      "| \u001b[0m 41      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.5111  \u001b[0m | \u001b[0m 153.6   \u001b[0m |\n",
      "| \u001b[0m 42      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.143   \u001b[0m | \u001b[0m 223.1   \u001b[0m |\n",
      "| \u001b[0m 43      \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 0.8716  \u001b[0m | \u001b[0m 116.3   \u001b[0m |\n",
      "| \u001b[0m 44      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 0.8087  \u001b[0m | \u001b[0m 73.49   \u001b[0m |\n",
      "| \u001b[0m 45      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 0.8851  \u001b[0m | \u001b[0m 282.3   \u001b[0m |\n",
      "| \u001b[0m 46      \u001b[0m | \u001b[0m 0.7637  \u001b[0m | \u001b[0m 0.5119  \u001b[0m | \u001b[0m 216.9   \u001b[0m |\n",
      "| \u001b[0m 47      \u001b[0m | \u001b[0m 0.7649  \u001b[0m | \u001b[0m 0.2411  \u001b[0m | \u001b[0m 229.1   \u001b[0m |\n",
      "| \u001b[0m 48      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.4696  \u001b[0m | \u001b[0m 95.8    \u001b[0m |\n",
      "| \u001b[0m 49      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 0.9004  \u001b[0m | \u001b[0m 55.03   \u001b[0m |\n",
      "| \u001b[0m 50      \u001b[0m | \u001b[0m 0.7616  \u001b[0m | \u001b[0m 1.252   \u001b[0m | \u001b[0m 51.17   \u001b[0m |\n",
      "| \u001b[95m 51      \u001b[0m | \u001b[95m 0.7657  \u001b[0m | \u001b[95m 0.05238 \u001b[0m | \u001b[95m 205.2   \u001b[0m |\n",
      "| \u001b[0m 52      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.1059  \u001b[0m | \u001b[0m 259.0   \u001b[0m |\n",
      "| \u001b[0m 53      \u001b[0m | \u001b[0m 0.7617  \u001b[0m | \u001b[0m 1.099   \u001b[0m | \u001b[0m 258.5   \u001b[0m |\n",
      "| \u001b[0m 54      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 1.002   \u001b[0m | \u001b[0m 71.85   \u001b[0m |\n",
      "| \u001b[0m 55      \u001b[0m | \u001b[0m 0.7639  \u001b[0m | \u001b[0m 0.3218  \u001b[0m | \u001b[0m 223.8   \u001b[0m |\n",
      "| \u001b[0m 56      \u001b[0m | \u001b[0m 0.7651  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 71.09   \u001b[0m |\n",
      "| \u001b[0m 57      \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 0.6909  \u001b[0m | \u001b[0m 222.6   \u001b[0m |\n",
      "| \u001b[0m 58      \u001b[0m | \u001b[0m 0.7634  \u001b[0m | \u001b[0m 0.4742  \u001b[0m | \u001b[0m 205.0   \u001b[0m |\n",
      "| \u001b[0m 59      \u001b[0m | \u001b[0m 0.7625  \u001b[0m | \u001b[0m 0.7984  \u001b[0m | \u001b[0m 287.5   \u001b[0m |\n",
      "| \u001b[0m 60      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.1368  \u001b[0m | \u001b[0m 205.9   \u001b[0m |\n",
      "| \u001b[0m 61      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.1486  \u001b[0m | \u001b[0m 203.9   \u001b[0m |\n",
      "| \u001b[95m 62      \u001b[0m | \u001b[95m 0.7657  \u001b[0m | \u001b[95m 0.05    \u001b[0m | \u001b[95m 229.8   \u001b[0m |\n",
      "| \u001b[0m 63      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 0.7183  \u001b[0m | \u001b[0m 230.0   \u001b[0m |\n",
      "| \u001b[0m 64      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.06646 \u001b[0m | \u001b[0m 259.8   \u001b[0m |\n",
      "| \u001b[0m 65      \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 0.6431  \u001b[0m | \u001b[0m 260.3   \u001b[0m |\n",
      "| \u001b[0m 66      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.08925 \u001b[0m | \u001b[0m 257.4   \u001b[0m |\n",
      "| \u001b[0m 67      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.07668 \u001b[0m | \u001b[0m 256.5   \u001b[0m |\n",
      "| \u001b[0m 68      \u001b[0m | \u001b[0m 0.7623  \u001b[0m | \u001b[0m 0.8351  \u001b[0m | \u001b[0m 256.5   \u001b[0m |\n",
      "| \u001b[0m 69      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.08618 \u001b[0m | \u001b[0m 255.7   \u001b[0m |\n",
      "| \u001b[0m 70      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 254.8   \u001b[0m |\n",
      "| \u001b[0m 71      \u001b[0m | \u001b[0m 0.7627  \u001b[0m | \u001b[0m 0.789   \u001b[0m | \u001b[0m 254.8   \u001b[0m |\n",
      "| \u001b[0m 72      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 72.55   \u001b[0m |\n",
      "| \u001b[0m 73      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.1166  \u001b[0m | \u001b[0m 253.9   \u001b[0m |\n",
      "| \u001b[0m 74      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.09622 \u001b[0m | \u001b[0m 253.0   \u001b[0m |\n",
      "| \u001b[0m 75      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 0.8765  \u001b[0m | \u001b[0m 253.0   \u001b[0m |\n",
      "| \u001b[0m 76      \u001b[0m | \u001b[0m 0.7636  \u001b[0m | \u001b[0m 0.4202  \u001b[0m | \u001b[0m 208.9   \u001b[0m |\n",
      "| \u001b[0m 77      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.06252 \u001b[0m | \u001b[0m 252.3   \u001b[0m |\n",
      "| \u001b[0m 78      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.1088  \u001b[0m | \u001b[0m 285.1   \u001b[0m |\n",
      "| \u001b[0m 79      \u001b[0m | \u001b[0m 0.7617  \u001b[0m | \u001b[0m 1.037   \u001b[0m | \u001b[0m 285.2   \u001b[0m |\n",
      "| \u001b[0m 80      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.05837 \u001b[0m | \u001b[0m 284.2   \u001b[0m |\n",
      "| \u001b[0m 81      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.07704 \u001b[0m | \u001b[0m 251.4   \u001b[0m |\n",
      "| \u001b[0m 82      \u001b[0m | \u001b[0m 0.7628  \u001b[0m | \u001b[0m 0.7195  \u001b[0m | \u001b[0m 251.7   \u001b[0m |\n",
      "| \u001b[0m 83      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.1371  \u001b[0m | \u001b[0m 283.4   \u001b[0m |\n",
      "| \u001b[0m 84      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.1253  \u001b[0m | \u001b[0m 69.74   \u001b[0m |\n",
      "| \u001b[0m 85      \u001b[0m | \u001b[0m 0.763   \u001b[0m | \u001b[0m 0.9828  \u001b[0m | \u001b[0m 69.39   \u001b[0m |\n",
      "| \u001b[0m 86      \u001b[0m | \u001b[0m 0.7618  \u001b[0m | \u001b[0m 1.296   \u001b[0m | \u001b[0m 77.94   \u001b[0m |\n",
      "| \u001b[0m 87      \u001b[0m | \u001b[0m 0.7652  \u001b[0m | \u001b[0m 0.2111  \u001b[0m | \u001b[0m 70.36   \u001b[0m |\n",
      "| \u001b[0m 88      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.1336  \u001b[0m | \u001b[0m 76.8    \u001b[0m |\n",
      "| \u001b[0m 89      \u001b[0m | \u001b[0m 0.7655  \u001b[0m | \u001b[0m 0.105   \u001b[0m | \u001b[0m 207.0   \u001b[0m |\n",
      "| \u001b[0m 90      \u001b[0m | \u001b[0m 0.7633  \u001b[0m | \u001b[0m 0.9527  \u001b[0m | \u001b[0m 207.0   \u001b[0m |\n",
      "| \u001b[0m 91      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 215.3   \u001b[0m |\n",
      "| \u001b[0m 92      \u001b[0m | \u001b[0m 0.7632  \u001b[0m | \u001b[0m 0.8469  \u001b[0m | \u001b[0m 214.9   \u001b[0m |\n",
      "| \u001b[0m 93      \u001b[0m | \u001b[0m 0.7654  \u001b[0m | \u001b[0m 0.1388  \u001b[0m | \u001b[0m 215.9   \u001b[0m |\n",
      "| \u001b[0m 94      \u001b[0m | \u001b[0m 0.7612  \u001b[0m | \u001b[0m 1.394   \u001b[0m | \u001b[0m 210.1   \u001b[0m |\n",
      "| \u001b[0m 95      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.05    \u001b[0m | \u001b[0m 207.8   \u001b[0m |\n",
      "| \u001b[0m 96      \u001b[0m | \u001b[0m 0.7656  \u001b[0m | \u001b[0m 0.1153  \u001b[0m | \u001b[0m 151.8   \u001b[0m |\n",
      "| \u001b[0m 97      \u001b[0m | \u001b[0m 0.7631  \u001b[0m | \u001b[0m 0.5865  \u001b[0m | \u001b[0m 150.9   \u001b[0m |\n",
      "| \u001b[0m 98      \u001b[0m | \u001b[0m 0.7657  \u001b[0m | \u001b[0m 0.06274 \u001b[0m | \u001b[0m 152.5   \u001b[0m |\n",
      "| \u001b[0m 99      \u001b[0m | \u001b[0m 0.7635  \u001b[0m | \u001b[0m 0.7579  \u001b[0m | \u001b[0m 152.3   \u001b[0m |\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| \u001b[0m 100     \u001b[0m | \u001b[0m 0.7615  \u001b[0m | \u001b[0m 1.436   \u001b[0m | \u001b[0m 161.5   \u001b[0m |\n",
      "=================================================\n"
     ]
    }
   ],
   "source": [
    "BO_ada.maximize(init_points=50, n_iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'learning_rate': 0.05, 'n_estimators': 230}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_params = BO_ada.max['params']\n",
    "\n",
    "max_params['n_estimators'] = int(round(max_params['n_estimators']))\n",
    "\n",
    "max_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.75781976 0.75753374 0.7534179  0.76502325]\n",
      "최대성능: 0.7650232531651209\n",
      "평균성능: 0.7584486621763111\n"
     ]
    }
   ],
   "source": [
    "ada_meta = AdaBoostClassifier(**max_params)\n",
    "\n",
    "scores = cross_val_score(ada_meta, X_train, y_train, scoring='roc_auc', cv=4, n_jobs=-1)\n",
    "\n",
    "print(scores)\n",
    "print(f'최대성능: {max(scores)}\\n평균성능: {np.mean(scores)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostClassifier(learning_rate=0.05, n_estimators=230)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_meta.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### meta voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:10:11] WARNING: C:\\Users\\Administrator\\workspace\\xgboost-win64_release_1.2.0\\src\\learner.cc:516: \n",
      "Parameters: { colsample } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('meta_ADA',\n",
       "                              AdaBoostClassifier(learning_rate=0.05,\n",
       "                                                 n_estimators=230)),\n",
       "                             ('meta_LR',\n",
       "                              LogisticRegression(C=0.1001800856967334,\n",
       "                                                 n_jobs=-1, random_state=50)),\n",
       "                             ('meta_EXTRA',\n",
       "                              ExtraTreesClassifier(bootstrap=True, max_depth=3,\n",
       "                                                   max_features=0.8,\n",
       "                                                   n_estimators=197,\n",
       "                                                   oob_score=True)),\n",
       "                             ('meta_LGBM',\n",
       "                              LGBMClassifier(colsample_bytree=0.75,\n",
       "                                             learning_r...\n",
       "                                            gpu_id=-1, importance_type='gain',\n",
       "                                            interaction_constraints='',\n",
       "                                            learning_rate=0.05,\n",
       "                                            max_delta_step=0, max_depth=5,\n",
       "                                            min_child_weight=1, missing=nan,\n",
       "                                            monotone_constraints='()',\n",
       "                                            n_estimators=73, n_jobs=0,\n",
       "                                            num_parallel_tree=1, random_state=0,\n",
       "                                            reg_alpha=0, reg_lambda=1,\n",
       "                                            scale_pos_weight=1, subsample=0.8,\n",
       "                                            tree_method='exact',\n",
       "                                            validate_parameters=1,\n",
       "                                            verbosity=None))],\n",
       "                 voting='soft')"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "meta_voting = VotingClassifier(estimators = [('meta_ADA', ada_meta),('meta_LR',logreg_meta ), ('meta_EXTRA', extra_meta), ('meta_LGBM', meta_clf), ('meta_XGB', xgb_meta)], voting='soft')\n",
    "meta_voting.fit(S_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.76583503, 0.77110945, 0.7679754 , 0.767928  ])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(meta_voting, S_valid, y_valid, scoring='roc_auc', cv=4, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict & submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_y = meta_voting.predict_proba(S_test)[:, 0] + meta_voting.predict_proba(S_test)[:, 1] * 2\n",
    "submission['voted']=pred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "submission.to_csv(f'submission_{str(datetime.datetime.now().date())}.csv', index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
